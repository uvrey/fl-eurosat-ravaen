{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omnWjd7NRKFq"
   },
   "source": [
    "# Training Demo\n",
    "\n",
    "In this notebook we will run training script for the work [*Unsupervised Change Detection of Extreme Events Using ML On-Board*](http://arxiv.org/abs/2111.02995). This work was conducted at the [FDL Europe 2021](https://fdleurope.org/fdl-europe-2021) research accelerator program. \n",
    "\n",
    "**These instructions are meant to work on your local machine** (we don't use the Google Colab environment)\n",
    "\n",
    "*Note that in practice this takes long time, so this should serve only as an orientational demo.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o93G2PiIRKFt"
   },
   "source": [
    "## 1 Preparation\n",
    "\n",
    "- Get the dataset (for this demo we also provide a tiny training dataset subset - see below)\n",
    "\n",
    "- For better visualizations log into weights and biases with: wandb init\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofzitDKwRKFt"
   },
   "source": [
    "## 2 Libraries\n",
    "\n",
    "**Run these:**\n",
    "\n",
    "```\n",
    "make requirements\n",
    "conda activate ravaen_env\n",
    "conda install nb_conda\n",
    "jupyter notebook\n",
    "# start this notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GGNRwsr8SKVj"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "p3RyYqyzRKFu",
    "outputId": "d9feb9bc-f0a6-4b1e-c5ca-7b5ba73538ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     active environment : ravaen_env\r\n"
     ]
    }
   ],
   "source": [
    "!conda info | grep 'active environment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gg1167yWRKFx",
    "outputId": "32651f09-03ac-4c6e-dba0-e932a6c91262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jan  6 12:46:24 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 545.29.04              Driver Version: 546.17       CUDA Version: 12.3     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3060 ...    On  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| N/A   42C    P5              14W /  25W |    278MiB /  6144MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OS17PWKWSMpV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1rl3Clf0c7HlXnlPXO837Pjr2iCjwak0Y\n",
      "From (redirected): https://drive.google.com/uc?id=1rl3Clf0c7HlXnlPXO837Pjr2iCjwak0Y&confirm=t&uuid=d37337b2-4d62-4e13-9a2d-8a23a97a6fbe\n",
      "To: /home/lucap/l46/l46-project/RaVAEn-master/notebooks/train_minisubset.zip\n",
      "100%|████████████████████████████████████████| 658M/658M [00:31<00:00, 20.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "# The official training dataset is much larger, for the purpose of the demo, we provide a small subset:\n",
    "!gdown https://drive.google.com/uc?id=1rl3Clf0c7HlXnlPXO837Pjr2iCjwak0Y -O train_minisubset.zip\n",
    "!unzip -q train_minisubset.zip\n",
    "!rm train_minisubset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwc457wzRKFx"
   },
   "source": [
    "**Edit the paths in config/config.yaml**\n",
    "\n",
    "```\n",
    "log_dir: \"/home/<USER>/results\"\n",
    "cache_dir: \"/home/<USER>/cache\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "633WMEtkRKFy",
    "outputId": "f375b444-7d01-44a5-eb18-1df41db51107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\r\n",
      "entity: \"mlpayloads\"\r\n",
      "\r\n",
      "log_dir: \"/home/lucap/l46/l46-project/RaVAEn-master/outputs/results\"\r\n",
      "cache_dir: \"/home/lucap/l46/l46-project/RaVAEn-master/outputs/cache\"\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../config/config.yaml\n",
    "\"\"\"\n",
    "Fill in:\n",
    "log_dir: \"/home/<USER>/results\"\n",
    "cache_dir: \"/home/<USER>/cache\"\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lucap/l46/l46-project/RaVAEn-master/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lucap/l46/l46-project/RaVAEn-master\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EaNE7JUlRKFy",
    "outputId": "d714853b-442f-4a60-b856-376f011c4cf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "\n",
      "LATENT SPACE size: 128\n",
      "Datamodule created!\n",
      "Training set length: 12190\n",
      "Test set length: 726\n"
     ]
    }
   ],
   "source": [
    "# ===== Parameters to adjust =====\n",
    "epochs = 100\n",
    "dataset_root_folder = \"/home/lucap/l46/l46-project/RaVAEn-master/notebooks/train_minisubset\"\n",
    "dataset=\"alpha_multiscene_tiny\" # for the demo, for the full training dataset we would use: dataset=\"alpha_multiscene\"\n",
    "\n",
    "name=\"VAE_128small\" # note \"small\" uses these settings > module.model_cls_args.latent_dim=128 module.model_cls_args.extra_depth_on_scale=0 module.model_cls_args.hidden_channels=[16,32,64]\n",
    "\n",
    "# ===== Parameters to keep the same ======\n",
    "training=\"simple_vae\"\n",
    "module=\"deeper_vae\"\n",
    "\n",
    "# ========================================\n",
    "\n",
    "#python3 -m scripts.train_model +dataset=alpha_multiscene_tiny ++dataset.root_folder=\"/home/lucap/l46/l46-project/RaVAEn-master/notebooks/train_minisubset\" +normalisation=log_scale +channels=high_res +training=simple_vae +module=deeper_vae +project=train_VAE_128small +name=\"VAE_128small\" module.model_cls_args.latent_dim=128 module.model_cls_args.extra_depth_on_scale=0 module.model_cls_args.hidden_channels=[16,32,64] training.epochs=100\n",
    "\n",
    "!python3 -m scripts.train_model +dataset=$dataset ++dataset.root_folder=\"{dataset_root_folder}\" \\\n",
    "         +normalisation=log_scale +channels=high_res +training=$training +module=$module +project=train_VAE_128small +name=\"{name}\" \\\n",
    "         module.model_cls_args.latent_dim=128 module.model_cls_args.extra_depth_on_scale=0 module.model_cls_args.hidden_channels=[16,32,64] \\\n",
    "         training.epochs=$epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "\n",
      "Preprocessing dataset...\n",
      "Extracted latent_dim=128 from config.yaml\n",
      "Extracted vis_channels=[2, 1, 0] from config.yaml\n",
      "\n",
      "Datamodule created!\n",
      "Partitioned 12180 of 12190 training set entries into 20 partitions of length 609\n",
      "Training set length: 12180\n",
      "Sum of partitions: 12180\n",
      "\n",
      "FedRaVAEn dataset loaded!\n",
      "Number of training loaders: 20, Number of Validation Loaders: 20\n",
      "Length of each partition's dataset: 549 (training), 60 (validation)\n",
      "Length of test dataset: 726\n",
      "\n",
      "Generating clients...\n",
      "INFO flwr 2024-01-06 16:39:09,643 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
      "[2024-01-06 16:39:09,643][flwr][INFO] - Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
      "2024-01-06 16:39:12,587\tINFO worker.py:1724 -- Started a local Ray instance.\n",
      "INFO flwr 2024-01-06 16:39:13,165 | app.py:180 | Flower VCE: Ray initialized with resources: {'CPU': 16.0, 'node:172.21.136.41': 1.0, 'memory': 3908896359.0, 'object_store_memory': 1954448179.0, 'GPU': 1.0, 'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0}\n",
      "[2024-01-06 16:39:13,165][flwr][INFO] - Flower VCE: Ray initialized with resources: {'CPU': 16.0, 'node:172.21.136.41': 1.0, 'memory': 3908896359.0, 'object_store_memory': 1954448179.0, 'GPU': 1.0, 'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0}\n",
      "INFO flwr 2024-01-06 16:39:13,165 | server.py:86 | Initializing global parameters\n",
      "[2024-01-06 16:39:13,165][flwr][INFO] - Initializing global parameters\n",
      "INFO flwr 2024-01-06 16:39:13,165 | server.py:273 | Requesting initial parameters from one random client\n",
      "[2024-01-06 16:39:13,165][flwr][INFO] - Requesting initial parameters from one random client\n",
      "ERROR flwr 2024-01-06 16:39:13,581 | ray_client_proxy.py:72 | \u001b[36mray::launch_and_get_parameters()\u001b[39m (pid=64803, ip=172.21.136.41)\n",
      "  At least one of the input arguments for this task could not be computed:\n",
      "ray.exceptions.RaySystemError: System error: No module named 'src'\n",
      "traceback: Traceback (most recent call last):\n",
      "ModuleNotFoundError: No module named 'src'\n",
      "[2024-01-06 16:39:13,581][flwr][ERROR] - \u001b[36mray::launch_and_get_parameters()\u001b[39m (pid=64803, ip=172.21.136.41)\n",
      "  At least one of the input arguments for this task could not be computed:\n",
      "ray.exceptions.RaySystemError: System error: No module named 'src'\n",
      "traceback: Traceback (most recent call last):\n",
      "ModuleNotFoundError: No module named 'src'\n",
      "Error executing job with overrides: ['+dataset=alpha_multiscene_tiny', '++dataset.root_folder=/home/lucap/l46/l46-project/RaVAEn-master/notebooks/train_minisubset', '+training=simple_vae', '+module=deeper_vae', '+normalisation=log_scale', '+channels=high_res', '+name=VAE_128small', 'module.model_cls_args.latent_dim=128']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/lucap/l46/l46-project/RaVAEn-master/scripts/main.py\", line 95, in <module>\n",
      "    main()\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/hydra/main.py\", line 49, in decorated_main\n",
      "    _run_hydra(\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/hydra/_internal/utils.py\", line 367, in _run_hydra\n",
      "    run_and_report(\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/hydra/_internal/utils.py\", line 214, in run_and_report\n",
      "    raise ex\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/hydra/_internal/utils.py\", line 211, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/hydra/_internal/utils.py\", line 368, in <lambda>\n",
      "    lambda: hydra.run(\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/hydra/_internal/hydra.py\", line 110, in run\n",
      "    _ = ret.return_value\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/hydra/core/utils.py\", line 233, in return_value\n",
      "    raise self._return_value\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/hydra/core/utils.py\", line 160, in run_job\n",
      "    ret.return_value = task_function(task_cfg)\n",
      "  File \"/home/lucap/l46/l46-project/RaVAEn-master/scripts/main.py\", line 85, in main\n",
      "    history = fl.simulation.start_simulation(client_fn=client_fn,\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/flwr/simulation/app.py\", line 197, in start_simulation\n",
      "    hist = _fl(\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/flwr/server/app.py\", line 217, in _fl\n",
      "    hist = server.fit(num_rounds=config.num_rounds, timeout=config.round_timeout)\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/flwr/server/server.py\", line 87, in fit\n",
      "    self.parameters = self._get_initial_parameters(timeout=timeout)\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/flwr/server/server.py\", line 276, in _get_initial_parameters\n",
      "    get_parameters_res = random_client.get_parameters(ins=ins, timeout=timeout)\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 73, in get_parameters\n",
      "    raise ex\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 70, in get_parameters\n",
      "    res = ray.get(future_paramseters_res, timeout=timeout)\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/ray/_private/worker.py\", line 2624, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RaySystemError): \u001b[36mray::launch_and_get_parameters()\u001b[39m (pid=64803, ip=172.21.136.41)\n",
      "  At least one of the input arguments for this task could not be computed:\n",
      "ray.exceptions.RaySystemError: System error: No module named 'src'\n",
      "traceback: Traceback (most recent call last):\n",
      "ModuleNotFoundError: No module named 'src'\n",
      "\u001b[36m(launch_and_get_parameters pid=64803)\u001b[0m No module named 'src'\n",
      "\u001b[36m(launch_and_get_parameters pid=64803)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(launch_and_get_parameters pid=64803)\u001b[0m   File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/ray/_private/serialization.py\", line 404, in deserialize_objects\n",
      "\u001b[36m(launch_and_get_parameters pid=64803)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\n",
      "\u001b[36m(launch_and_get_parameters pid=64803)\u001b[0m   File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/ray/_private/serialization.py\", line 270, in _deserialize_object\n",
      "\u001b[36m(launch_and_get_parameters pid=64803)\u001b[0m     return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "\u001b[36m(launch_and_get_parameters pid=64803)\u001b[0m   File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_msgpack_data\n",
      "\u001b[36m(launch_and_get_parameters pid=64803)\u001b[0m     python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "\u001b[36m(launch_and_get_parameters pid=64803)\u001b[0m   File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/ray/_private/serialization.py\", line 215, in _deserialize_pickle5_data\n",
      "\u001b[36m(launch_and_get_parameters pid=64803)\u001b[0m     obj = pickle.loads(in_band)\n",
      "\u001b[36m(launch_and_get_parameters pid=64803)\u001b[0m ModuleNotFoundError: No module named 'src'\n"
     ]
    }
   ],
   "source": [
    "# ===== Parameters to adjust =====\n",
    "epochs = 100\n",
    "dataset_root_folder = \"/home/lucap/l46/l46-project/RaVAEn-master/notebooks/train_minisubset\"\n",
    "dataset=\"alpha_multiscene_tiny\" # for the demo, for the full training dataset we would use: dataset=\"alpha_multiscene\"\n",
    "\n",
    "# note \"small\" uses these setting:\n",
    "# module.model_cls_args.latent_dim=128 \n",
    "# module.model_cls_args.extra_depth_on_scale=0 \n",
    "# module.model_cls_args.hidden_channels=[16,32,64]\n",
    "name=\"VAE_128small\" \n",
    "\n",
    "# ===== Parameters to keep the same ======\n",
    "training=\"simple_vae\"\n",
    "module=\"deeper_vae\"\n",
    "\n",
    "# ========================================\n",
    "\n",
    "!HYDRA_FULL_ERROR=1 python -m scripts.main +dataset=$dataset ++dataset.root_folder=\"{dataset_root_folder}\" +training=$training \\\n",
    "        +module=$module +normalisation=log_scale +channels=high_res +name=\"{name}\" module.model_cls_args.latent_dim=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lucap/l46/l46-project/RaVAEn-master\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing job with overrides: ['+dataset=alpha_multiscene_tiny', '++dataset.root_folder=/home/lucap/l46/l46-project/RaVAEn-master/notebooks/train_minisubset']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lucap/l46/l46-project/RaVAEn-master/scripts/make_datamodule.py\", line 14, in main\n",
      "    cfg = deepconvert(cfg)\n",
      "  File \"/home/lucap/l46/l46-project/RaVAEn-master/src/utils.py\", line 26, in deepconvert\n",
      "    not_omega_conf.update({k: deepconvert(v)})\n",
      "  File \"/home/lucap/l46/l46-project/RaVAEn-master/src/utils.py\", line 26, in deepconvert\n",
      "    not_omega_conf.update({k: deepconvert(v)})\n",
      "  File \"/home/lucap/l46/l46-project/RaVAEn-master/src/utils.py\", line 25, in deepconvert\n",
      "    for k, v in omega_conf.items():\n",
      "omegaconf.errors.InterpolationKeyError: Interpolation key 'training.batch_size_train' not found\n",
      "    full_key: dataset.train.batch_size\n",
      "    object_type=dict\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    }
   ],
   "source": [
    "dataset_root_folder = \"/home/lucap/l46/l46-project/RaVAEn-master/notebooks/train_minisubset\"\n",
    "dataset=\"alpha_multiscene_tiny\" # for the demo, for the full training dataset we would use: dataset=\"alpha_multiscene\"\n",
    "\n",
    "!python3 -m scripts.make_datamodule +dataset=$dataset ++dataset.root_folder=\"{dataset_root_folder}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbYzpJwXRKFz"
   },
   "source": [
    "### More advanced settings:\n",
    "\n",
    "See the possible options using --help and then looking at the individual configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgxa-F3zRKF0",
    "outputId": "e7314858-d5d3-4c2d-9ab5-dd76538031e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model is powered by Hydra.\r\n",
      "\r\n",
      "== Configuration groups ==\r\n",
      "Compose your configuration from those groups (group=option)\r\n",
      "\r\n",
      "channels: all, high_res, high_res_phisat2overlap, rgb, rgb_nir, rgb_nir_b11, rgb_nir_b11_b12_landsat, rgb_nir_b12\r\n",
      "dataset: alpha_multiscene, alpha_multiscene_tiny, alpha_singlescene, dataloader_test, eval, fire, fires, floods_evaluation, hurricanes, landslides, landslides_2, oilspills, preliminary, preliminary_da, preliminary_multiscene, preliminary_sequential, preliminary_sequential_bigger, preliminary_sequential_bigger_9k, preliminary_sequential_bigger_multiEval, preliminary_sequential_bigger_multiEval_Germany, samples_for_gui, temporal_analysis, volcanos\r\n",
      "evaluation: ae_base, ae_fewer, vae_base, vae_da, vae_da_8px, vae_fewer, vae_paper\r\n",
      "module: deeper_ae, deeper_ae_bigger_latent, deeper_vae, grx, simple_ae, simple_ae_with_linear, simple_vae\r\n",
      "normalisation: log_scale, none\r\n",
      "training: da, simple_ae, simple_vae\r\n",
      "transform: eval_da, eval_da_8px, eval_nda, eval_nda_8px, none, random, random_1px, random_4px, random_6px, simple\r\n",
      "\r\n",
      "\r\n",
      "== Config ==\r\n",
      "Override anything in the config (foo.bar=value)\r\n",
      "\r\n",
      "entity: mlpayloads\r\n",
      "log_dir: /home/vitek/fdl_tmp/results\r\n",
      "cache_dir: /home/vitek/fdl_tmp/cache\r\n",
      "\r\n",
      "\r\n",
      "Powered by Hydra (https://hydra.cc)\r\n",
      "Use --hydra-help to view Hydra specific help\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m scripts.train_model --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_cDsLxHRKF1",
    "outputId": "21b4ec6b-3ca7-4382-cf57-c2f3adc98ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\r\n",
      "gpus: -1\r\n",
      "epochs: 400\r\n",
      "grad_batches: 1\r\n",
      "distr_backend: 'dp'\r\n",
      "use_amp: true # ... true = 16 precision / false = 32 precision\r\n",
      "\r\n",
      "# The check_val_every_n_epoch and val_check_interval settings overlap, see:\r\n",
      "#     https://github.com/PyTorchLightning/pytorch-lightning/issues/6385\r\n",
      "val_check_interval: 0.2  # either in to check after that many batches or float to check that fraction of epoch\r\n",
      "check_val_every_n_epoch: 1 \r\n",
      "\r\n",
      "fast_dev_run: false\r\n",
      "\r\n",
      "num_workers: 16\r\n",
      "\r\n",
      "batch_size_train: 256\r\n",
      "batch_size_valid: 256\r\n",
      "batch_size_test: 256\r\n",
      "\r\n",
      "lr: 0.001\r\n",
      "weight_decay: 0.0\r\n",
      "# scheduler_gamma: 0.95\r\n",
      "\r\n",
      "# auto_batch_size: 'binsearch'\r\n",
      "#auto_lr: 'lr'\r\n"
     ]
    }
   ],
   "source": [
    "# to see the detiled options for \"training: da, simple_ae, simple_vae\"\n",
    "!cat config/training/simple_vae.yaml\n",
    "# for example we would then set epochs with adding this to the main command:\n",
    "# training.epochs=1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "training_demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
