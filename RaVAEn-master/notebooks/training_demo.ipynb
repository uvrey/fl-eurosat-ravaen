{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omnWjd7NRKFq"
   },
   "source": [
    "# Training Demo\n",
    "\n",
    "In this notebook we will run training script for the work [*Unsupervised Change Detection of Extreme Events Using ML On-Board*](http://arxiv.org/abs/2111.02995). This work was conducted at the [FDL Europe 2021](https://fdleurope.org/fdl-europe-2021) research accelerator program. \n",
    "\n",
    "**These instructions are meant to work on your local machine** (we don't use the Google Colab environment)\n",
    "\n",
    "*Note that in practice this takes long time, so this should serve only as an orientational demo.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o93G2PiIRKFt"
   },
   "source": [
    "## 1 Preparation\n",
    "\n",
    "- Get the dataset (for this demo we also provide a tiny training dataset subset - see below)\n",
    "\n",
    "- For better visualizations log into weights and biases with: wandb init\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lucap/l46/l46-project/RaVAEn-master\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofzitDKwRKFt"
   },
   "source": [
    "## 2 Libraries\n",
    "\n",
    "**Run these:**\n",
    "\n",
    "```\n",
    "make requirements\n",
    "conda activate ravaen_env\n",
    "conda install nb_conda\n",
    "jupyter notebook\n",
    "# start this notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GGNRwsr8SKVj"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "p3RyYqyzRKFu",
    "outputId": "d9feb9bc-f0a6-4b1e-c5ca-7b5ba73538ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     active environment : ravaen_env\r\n"
     ]
    }
   ],
   "source": [
    "!conda info | grep 'active environment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gg1167yWRKFx",
    "outputId": "32651f09-03ac-4c6e-dba0-e932a6c91262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 24 13:45:12 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 545.29.04              Driver Version: 546.17       CUDA Version: 12.3     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3060 ...    On  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| N/A   37C    P8              10W /  80W |    494MiB /  6144MiB |      1%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OS17PWKWSMpV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1rl3Clf0c7HlXnlPXO837Pjr2iCjwak0Y\n",
      "From (redirected): https://drive.google.com/uc?id=1rl3Clf0c7HlXnlPXO837Pjr2iCjwak0Y&confirm=t&uuid=8b072281-51b9-4cfd-86b2-ea2bf201629d\n",
      "To: /home/lucap/l46/l46-project/RaVAEn-master/notebooks/train_minisubset.zip\n",
      "100%|████████████████████████████████████████| 658M/658M [00:30<00:00, 21.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "# The official training dataset is much larger, for the purpose of the demo, we provide a small subset:\n",
    "!gdown https://drive.google.com/uc?id=1rl3Clf0c7HlXnlPXO837Pjr2iCjwak0Y -O train_minisubset.zip\n",
    "!unzip -q train_minisubset.zip\n",
    "!rm train_minisubset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change working directory to RaVAEn-master**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/lucap/l46/l46-project/RaVAEn-master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwc457wzRKFx"
   },
   "source": [
    "**Edit the paths in config/config.yaml**\n",
    "\n",
    "```\n",
    "log_dir: \"/home/<USER>/results\"\n",
    "cache_dir: \"/home/<USER>/cache\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "633WMEtkRKFy",
    "outputId": "f375b444-7d01-44a5-eb18-1df41db51107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\r\n",
      "entity: \"mlpayloads\"\r\n",
      "\r\n",
      "log_dir: \"/home/lucap/l46/l46-project/RaVAEn-master/outputs/results\"\r\n",
      "cache_dir: \"/home/lucap/l46/l46-project/RaVAEn-master/outputs/cache\"\r\n"
     ]
    }
   ],
   "source": [
    "!cat config/config.yaml\n",
    "\"\"\"\n",
    "Fill in:\n",
    "log_dir: \"/home/<USER>/results\"\n",
    "cache_dir: \"/home/<USER>/cache\"\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "EaNE7JUlRKFy",
    "outputId": "d714853b-442f-4a60-b856-376f011c4cf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "\n",
      "LATENT SPACE size: 128\n",
      "/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:338: UserWarning: ModelCheckpoint(save_last=True, save_top_k=None, monitor=None) is a redundant configuration. You can save the last checkpoint with ModelCheckpoint(save_top_k=None, monitor=None).\n",
      "  rank_zero_warn(\n",
      "ModelCheckpoint(save_last=True, save_top_k=-1, monitor=None) will duplicate the last checkpoint saved.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/torch/cuda/__init__.py:106: UserWarning: \n",
      "NVIDIA GeForce RTX 3060 Laptop GPU with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.\n",
      "If you want to use the NVIDIA GeForce RTX 3060 Laptop GPU GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: ^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/lucap/l46/l46-project/RaVAEn-master/scripts/train_model.py\", line 76, in <module>\n",
      "    main()\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/hydra/main.py\", line 49, in decorated_main\n",
      "    _run_hydra(\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/hydra/_internal/utils.py\", line 367, in _run_hydra\n",
      "    run_and_report(\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/hydra/_internal/utils.py\", line 211, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/hydra/_internal/utils.py\", line 368, in <lambda>\n",
      "    lambda: hydra.run(\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/hydra/_internal/hydra.py\", line 97, in run\n",
      "    ret = run_job(\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/hydra/core/utils.py\", line 160, in run_job\n",
      "    ret.return_value = task_function(task_cfg)\n",
      "  File \"/home/lucap/l46/l46-project/RaVAEn-master/scripts/train_model.py\", line 72, in main\n",
      "    trainer.fit(module, data_module)\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 460, in fit\n",
      "    self._run(model)\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 755, in _run\n",
      "    self.pre_dispatch()\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 785, in pre_dispatch\n",
      "    self.logger.log_hyperparams(self.lightning_module.hparams_initial)\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py\", line 49, in wrapped_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py\", line 190, in log_hyperparams\n",
      "    self.experiment.config.update(params, allow_val_change=True)\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/pytorch_lightning/loggers/base.py\", line 41, in experiment\n",
      "    return get_experiment() or DummyExperiment()\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py\", line 49, in wrapped_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/pytorch_lightning/loggers/base.py\", line 39, in get_experiment\n",
      "    return fn(self)\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py\", line 169, in experiment\n",
      "    self._experiment = wandb.init(**self._wandb_init) if wandb.run is None else wandb.run\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 973, in init\n",
      "    raise e\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 948, in init\n",
      "    wi.setup(kwargs)\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
      "    wandb_login._login(\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/wandb/sdk/wandb_login.py\", line 284, in _login\n",
      "    wlogin.prompt_api_key()\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/wandb/sdk/wandb_login.py\", line 212, in prompt_api_key\n",
      "    key, status = self._prompt_api_key()\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/wandb/sdk/wandb_login.py\", line 192, in _prompt_api_key\n",
      "    key = apikey.prompt_api_key(\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/wandb/sdk/lib/apikey.py\", line 93, in prompt_api_key\n",
      "    result = prompt_choices(\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/wandb/util.py\", line 1090, in prompt_choices\n",
      "    choice = _prompt_choice(input_timeout=input_timeout, jupyter=jupyter)\n",
      "  File \"/home/lucap/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/wandb/util.py\", line 1075, in _prompt_choice\n",
      "    choice = input_fn(text)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# ===== Parameters to adjust =====\n",
    "epochs = 100\n",
    "dataset_root_folder = \"/home/lucap/l46/l46-project/RaVAEn-master/notebooks/train_minisubset\"\n",
    "dataset=\"alpha_multiscene_tiny\" # for the demo, for the full training dataset we would use: dataset=\"alpha_multiscene\"\n",
    "\n",
    "name=\"VAE_128small\" # note \"small\" uses these settings > module.model_cls_args.latent_dim=128 module.model_cls_args.extra_depth_on_scale=0 module.model_cls_args.hidden_channels=[16,32,64]\n",
    "\n",
    "# ===== Parameters to keep the same ======\n",
    "training=\"simple_vae\"\n",
    "module=\"deeper_vae\"\n",
    "\n",
    "# ========================================\n",
    "\n",
    "!python3 -m scripts.train_model +dataset=$dataset ++dataset.root_folder=\"{dataset_root_folder}\" \\\n",
    "         +normalisation=log_scale +channels=high_res +training=$training +module=$module +project=train_VAE_128small +name=\"{name}\" \\\n",
    "         module.model_cls_args.latent_dim=128 module.model_cls_args.extra_depth_on_scale=0 module.model_cls_args.hidden_channels=[16,32,64] \\\n",
    "         training.epochs=$epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 -m scripts.train_model +dataset=\"alpha_multiscene_tiny\" ++dataset.root_folder=\"/home/lucap/l46/l46-project/RaVAEn-master/notebooks/train_minisubset\" +normalisation=log_scale +channels=high_res +training=\"simple_vae\" +module=\"deeper_vae\" +project=train_VAE_128small +name=\"VAE_128small\" module.model_cls_args.latent_dim=128 module.model_cls_args.extra_depth_on_scale=0 module.model_cls_args.hidden_channels=[16,32,64] training.epochs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbYzpJwXRKFz"
   },
   "source": [
    "### More advanced settings:\n",
    "\n",
    "See the possible options using --help and then looking at the individual configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qgxa-F3zRKF0",
    "outputId": "e7314858-d5d3-4c2d-9ab5-dd76538031e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lucap/anaconda3/envs/ravaen_env/bin/python3: Error while finding module specification for 'scripts.train_model' (ModuleNotFoundError: No module named 'scripts')\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m scripts.train_model --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_cDsLxHRKF1",
    "outputId": "21b4ec6b-3ca7-4382-cf57-c2f3adc98ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\r\n",
      "gpus: -1\r\n",
      "epochs: 400\r\n",
      "grad_batches: 1\r\n",
      "distr_backend: 'dp'\r\n",
      "use_amp: true # ... true = 16 precision / false = 32 precision\r\n",
      "\r\n",
      "# The check_val_every_n_epoch and val_check_interval settings overlap, see:\r\n",
      "#     https://github.com/PyTorchLightning/pytorch-lightning/issues/6385\r\n",
      "val_check_interval: 0.2  # either in to check after that many batches or float to check that fraction of epoch\r\n",
      "check_val_every_n_epoch: 1 \r\n",
      "\r\n",
      "fast_dev_run: false\r\n",
      "\r\n",
      "num_workers: 16\r\n",
      "\r\n",
      "batch_size_train: 256\r\n",
      "batch_size_valid: 256\r\n",
      "batch_size_test: 256\r\n",
      "\r\n",
      "lr: 0.001\r\n",
      "weight_decay: 0.0\r\n",
      "# scheduler_gamma: 0.95\r\n",
      "\r\n",
      "# auto_batch_size: 'binsearch'\r\n",
      "#auto_lr: 'lr'\r\n"
     ]
    }
   ],
   "source": [
    "# to see the detiled options for \"training: da, simple_ae, simple_vae\"\n",
    "!cat config/training/simple_vae.yaml\n",
    "# for example we would then set epochs with adding this to the main command:\n",
    "# training.epochs=1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "training_demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
