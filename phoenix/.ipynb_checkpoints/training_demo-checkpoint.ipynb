{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omnWjd7NRKFq"
   },
   "source": [
    "# FedRaVAEn Data Processing\n",
    "\n",
    "In this notebook we will run training script for the work [*Unsupervised Change Detection of Extreme Events Using ML On-Board*](http://arxiv.org/abs/2111.02995). This work was conducted at the [FDL Europe 2021](https://fdleurope.org/fdl-europe-2021) research accelerator program. \n",
    "\n",
    "**These instructions are meant to work on your local machine** (we don't use the Google Colab environment)\n",
    "\n",
    "*Note that in practice this takes long time, so this should serve only as an orientational demo.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o93G2PiIRKFt"
   },
   "source": [
    "## 1 Preparation\n",
    "\n",
    "- Get the dataset (for this demo we also provide a tiny training dataset subset - see below)\n",
    "\n",
    "- For better visualizations log into weights and biases with: wandb init\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofzitDKwRKFt"
   },
   "source": [
    "## 2 Libraries\n",
    "\n",
    "**Run these:**\n",
    "\n",
    "```\n",
    "make requirements\n",
    "conda activate ravaen_env\n",
    "conda install nb_conda\n",
    "jupyter notebook\n",
    "# start this notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GGNRwsr8SKVj"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "p3RyYqyzRKFu",
    "outputId": "d9feb9bc-f0a6-4b1e-c5ca-7b5ba73538ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     active environment : ravaen_env\r\n"
     ]
    }
   ],
   "source": [
    "!conda info | grep 'active environment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gg1167yWRKFx",
    "outputId": "32651f09-03ac-4c6e-dba0-e932a6c91262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan  7 13:44:31 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 545.23.05              Driver Version: 545.84       CUDA Version: 12.3     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3050 ...    On  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   48C    P0              12W /  44W |      0MiB /  4096MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OS17PWKWSMpV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1rl3Clf0c7HlXnlPXO837Pjr2iCjwak0Y\n",
      "From (redirected): https://drive.google.com/uc?id=1rl3Clf0c7HlXnlPXO837Pjr2iCjwak0Y&confirm=t&uuid=d37337b2-4d62-4e13-9a2d-8a23a97a6fbe\n",
      "To: /home/lucap/l46/l46-project/RaVAEn-master/notebooks/train_minisubset.zip\n",
      "100%|████████████████████████████████████████| 658M/658M [00:31<00:00, 20.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "# The official training dataset is much larger, for the purpose of the demo, we provide a small subset:\n",
    "!gdown https://drive.google.com/uc?id=1rl3Clf0c7HlXnlPXO837Pjr2iCjwak0Y -O train_minisubset.zip\n",
    "!unzip -q train_minisubset.zip\n",
    "!rm train_minisubset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwc457wzRKFx"
   },
   "source": [
    "**Edit the paths in config/config.yaml**\n",
    "\n",
    "```\n",
    "log_dir: \"/home/<USER>/results\"\n",
    "cache_dir: \"/home/<USER>/cache\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "633WMEtkRKFy",
    "outputId": "f375b444-7d01-44a5-eb18-1df41db51107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: ../config/config.yaml: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../config/config.yaml\n",
    "\"\"\"\n",
    "Fill in:\n",
    "log_dir: \"/home/<USER>/results\"\n",
    "cache_dir: \"/home/<USER>/cache\"\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/josie/l46/l46-project/phoenix\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/home/josie/l46/l46-project/phoenix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/josie/l46/l46-project/phoenix\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "EaNE7JUlRKFy",
    "outputId": "d714853b-442f-4a60-b856-376f011c4cf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/josie/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/scipy/__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.21.1)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/josie/l46/l46-project/RaVAEn-master/scripts/train_model.py:14: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path='../config', config_name='config.yaml')\n",
      "/home/josie/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "Global seed set to 42\n",
      "Error executing job with overrides: ['+dataset=alpha_multiscene_tiny', '++dataset.root_folder=/home/lucap/l46/l46-project/RaVAEn-master/notebooks/train_minisubset', '+normalisation=log_scale', '+channels=high_res', '+training=simple_vae', '+module=deeper_vae', '+project=train_VAE_128small', '+name=VAE_128small', 'module.model_cls_args.latent_dim=128', 'module.model_cls_args.extra_depth_on_scale=0', 'module.model_cls_args.hidden_channels=[16,32,64]', 'training.epochs=100']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/josie/l46/l46-project/RaVAEn-master/scripts/train_model.py\", line 21, in main\n",
      "    data_module = ParsedDataModule.load_or_create(cfg['dataset'],\n",
      "  File \"/home/josie/l46/l46-project/RaVAEn-master/src/data/datamodule.py\", line 181, in load_or_create\n",
      "    datamodule = ParsedDataModule(cfg)\n",
      "  File \"/home/josie/l46/l46-project/RaVAEn-master/src/data/datamodule.py\", line 30, in __init__\n",
      "    self.train_ds = self.create_dataset(self.root_folder, self.train,\n",
      "  File \"/home/josie/l46/l46-project/RaVAEn-master/src/data/datamodule.py\", line 60, in create_dataset\n",
      "    return MyConcatDataset(datasets)\n",
      "  File \"/home/josie/l46/l46-project/RaVAEn-master/src/data/datamodule.py\", line 220, in __init__\n",
      "    super().__init__(datasets)\n",
      "  File \"/home/josie/anaconda3/envs/ravaen_env/lib/python3.9/site-packages/torch/utils/data/dataset.py\", line 238, in __init__\n",
      "    assert len(datasets) > 0, 'datasets should not be an empty iterable'  # type: ignore[arg-type]\n",
      "AssertionError: datasets should not be an empty iterable\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    }
   ],
   "source": [
    "# ===== Parameters to adjust =====\n",
    "epochs = 100\n",
    "dataset_root_folder = \"/home/lucap/l46/l46-project/RaVAEn-master/notebooks/train_minisubset\"\n",
    "dataset=\"alpha_multiscene_tiny\" # for the demo, for the full training dataset we would use: dataset=\"alpha_multiscene\"\n",
    "\n",
    "name=\"VAE_128small\" # note \"small\" uses these settings > module.model_cls_args.latent_dim=128 module.model_cls_args.extra_depth_on_scale=0 module.model_cls_args.hidden_channels=[16,32,64]\n",
    "\n",
    "# ===== Parameters to keep the same ======\n",
    "training=\"simple_vae\"\n",
    "module=\"deeper_vae\"\n",
    "\n",
    "# ========================================\n",
    "\n",
    "#python3 -m scripts.train_model +dataset=alpha_multiscene_tiny ++dataset.root_folder=\"/home/lucap/l46/l46-project/RaVAEn-master/notebooks/train_minisubset\" +normalisation=log_scale +channels=high_res +training=simple_vae +module=deeper_vae +project=train_VAE_128small +name=\"VAE_128small\" module.model_cls_args.latent_dim=128 module.model_cls_args.extra_depth_on_scale=0 module.model_cls_args.hidden_channels=[16,32,64] training.epochs=100\n",
    "\n",
    "!python3 -m scripts.train_model +dataset=$dataset ++dataset.root_folder=\"{dataset_root_folder}\" \\\n",
    "         +normalisation=log_scale +channels=high_res +training=$training +module=$module +project=train_VAE_128small +name=\"{name}\" \\\n",
    "         module.model_cls_args.latent_dim=128 module.model_cls_args.extra_depth_on_scale=0 module.model_cls_args.hidden_channels=[16,32,64] \\\n",
    "         training.epochs=$epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  data.py  flutils\tmodel.py  training_demo.ipynb  utils.py\r\n"
     ]
    }
   ],
   "source": [
    "## Check file contents\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/josie/anaconda3/envs/ravaen_env/bin/python: Error while finding module specification for 'scripts.data' (ModuleNotFoundError: No module named 'scripts')\r\n"
     ]
    }
   ],
   "source": [
    "## MAIN\n",
    "# ===== Parameters to adjust =====\n",
    "epochs = 100\n",
    "dataset_root_folder = \"/home/josie/l46/l46-project/RaVAEn-master/notebooks/train_minisubset\"\n",
    "dataset=\"alpha_multiscene_tiny\" # for the demo, for the full training dataset we would use: dataset=\"alpha_multiscene\"\n",
    "\n",
    "# note \"small\" uses these setting:\n",
    "# module.model_cls_args.latent_dim=128 \n",
    "# module.model_cls_args.extra_depth_on_scale=0 \n",
    "# module.model_cls_args.hidden_channels=[16,32,64]\n",
    "name=\"VAE_128small\" \n",
    "\n",
    "# ===== Parameters to keep the same ======\n",
    "training=\"simple_vae\"\n",
    "module=\"deeper_vae\"\n",
    "\n",
    "# ========================================\n",
    "\n",
    "!HYDRA_FULL_ERROR=1 python -m scripts.data +dataset=$dataset ++dataset.root_folder=\"{dataset_root_folder}\" +training=$training \\\n",
    "        +module=$module +normalisation=log_scale +channels=high_res +name=\"{name}\" module.model_cls_args.latent_dim=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lucap/l46/l46-project/RaVAEn-master\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing job with overrides: ['+dataset=alpha_multiscene_tiny', '++dataset.root_folder=/home/lucap/l46/l46-project/RaVAEn-master/notebooks/train_minisubset']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lucap/l46/l46-project/RaVAEn-master/scripts/make_datamodule.py\", line 14, in main\n",
      "    cfg = deepconvert(cfg)\n",
      "  File \"/home/lucap/l46/l46-project/RaVAEn-master/src/utils.py\", line 26, in deepconvert\n",
      "    not_omega_conf.update({k: deepconvert(v)})\n",
      "  File \"/home/lucap/l46/l46-project/RaVAEn-master/src/utils.py\", line 26, in deepconvert\n",
      "    not_omega_conf.update({k: deepconvert(v)})\n",
      "  File \"/home/lucap/l46/l46-project/RaVAEn-master/src/utils.py\", line 25, in deepconvert\n",
      "    for k, v in omega_conf.items():\n",
      "omegaconf.errors.InterpolationKeyError: Interpolation key 'training.batch_size_train' not found\n",
      "    full_key: dataset.train.batch_size\n",
      "    object_type=dict\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    }
   ],
   "source": [
    "dataset_root_folder = \"/home/lucap/l46/l46-project/RaVAEn-master/notebooks/train_minisubset\"\n",
    "dataset=\"alpha_multiscene_tiny\" # for the demo, for the full training dataset we would use: dataset=\"alpha_multiscene\"\n",
    "\n",
    "!python3 -m scripts.make_datamodule +dataset=$dataset ++dataset.root_folder=\"{dataset_root_folder}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbYzpJwXRKFz"
   },
   "source": [
    "### More advanced settings:\n",
    "\n",
    "See the possible options using --help and then looking at the individual configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgxa-F3zRKF0",
    "outputId": "e7314858-d5d3-4c2d-9ab5-dd76538031e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model is powered by Hydra.\r\n",
      "\r\n",
      "== Configuration groups ==\r\n",
      "Compose your configuration from those groups (group=option)\r\n",
      "\r\n",
      "channels: all, high_res, high_res_phisat2overlap, rgb, rgb_nir, rgb_nir_b11, rgb_nir_b11_b12_landsat, rgb_nir_b12\r\n",
      "dataset: alpha_multiscene, alpha_multiscene_tiny, alpha_singlescene, dataloader_test, eval, fire, fires, floods_evaluation, hurricanes, landslides, landslides_2, oilspills, preliminary, preliminary_da, preliminary_multiscene, preliminary_sequential, preliminary_sequential_bigger, preliminary_sequential_bigger_9k, preliminary_sequential_bigger_multiEval, preliminary_sequential_bigger_multiEval_Germany, samples_for_gui, temporal_analysis, volcanos\r\n",
      "evaluation: ae_base, ae_fewer, vae_base, vae_da, vae_da_8px, vae_fewer, vae_paper\r\n",
      "module: deeper_ae, deeper_ae_bigger_latent, deeper_vae, grx, simple_ae, simple_ae_with_linear, simple_vae\r\n",
      "normalisation: log_scale, none\r\n",
      "training: da, simple_ae, simple_vae\r\n",
      "transform: eval_da, eval_da_8px, eval_nda, eval_nda_8px, none, random, random_1px, random_4px, random_6px, simple\r\n",
      "\r\n",
      "\r\n",
      "== Config ==\r\n",
      "Override anything in the config (foo.bar=value)\r\n",
      "\r\n",
      "entity: mlpayloads\r\n",
      "log_dir: /home/vitek/fdl_tmp/results\r\n",
      "cache_dir: /home/vitek/fdl_tmp/cache\r\n",
      "\r\n",
      "\r\n",
      "Powered by Hydra (https://hydra.cc)\r\n",
      "Use --hydra-help to view Hydra specific help\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m scripts.train_model --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_cDsLxHRKF1",
    "outputId": "21b4ec6b-3ca7-4382-cf57-c2f3adc98ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\r\n",
      "gpus: -1\r\n",
      "epochs: 400\r\n",
      "grad_batches: 1\r\n",
      "distr_backend: 'dp'\r\n",
      "use_amp: true # ... true = 16 precision / false = 32 precision\r\n",
      "\r\n",
      "# The check_val_every_n_epoch and val_check_interval settings overlap, see:\r\n",
      "#     https://github.com/PyTorchLightning/pytorch-lightning/issues/6385\r\n",
      "val_check_interval: 0.2  # either in to check after that many batches or float to check that fraction of epoch\r\n",
      "check_val_every_n_epoch: 1 \r\n",
      "\r\n",
      "fast_dev_run: false\r\n",
      "\r\n",
      "num_workers: 16\r\n",
      "\r\n",
      "batch_size_train: 256\r\n",
      "batch_size_valid: 256\r\n",
      "batch_size_test: 256\r\n",
      "\r\n",
      "lr: 0.001\r\n",
      "weight_decay: 0.0\r\n",
      "# scheduler_gamma: 0.95\r\n",
      "\r\n",
      "# auto_batch_size: 'binsearch'\r\n",
      "#auto_lr: 'lr'\r\n"
     ]
    }
   ],
   "source": [
    "# to see the detiled options for \"training: da, simple_ae, simple_vae\"\n",
    "!cat config/training/simple_vae.yaml\n",
    "# for example we would then set epochs with adding this to the main command:\n",
    "# training.epochs=1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "training_demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
