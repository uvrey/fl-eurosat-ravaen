{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "collapsed_sections": [
        "zyCcomBROAYG",
        "ZULdbkZKXMkH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Download Flower"
      ],
      "metadata": {
        "id": "sI8c3-OiNm6p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdNUrletNgVl"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install flwr[simulation]==1.0.0\n",
        "# wrote our own version of dataset_utils.py\n",
        "#!wget https://raw.githubusercontent.com/adap/flower/v1.0.0/examples/simulation_pytorch/dataset_utils.py\n",
        "!wget https://raw.githubusercontent.com/adap/flower/v1.0.0/baselines/flwr_baselines/dataset/utils/common.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataset_utils.py\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import shutil\n",
        "from PIL import Image\n",
        "from torchvision.datasets import VisionDataset\n",
        "from typing import Callable, Optional, Tuple, Any\n",
        "from common import create_lda_partitions\n",
        "import os\n",
        "\n",
        "def get_dataset(path_to_data: Path, cid: str, partition: str):\n",
        "\n",
        "    # generate path to cid's data\n",
        "    path_to_data = path_to_data / cid / (partition + \".pt\")\n",
        "\n",
        "    return TorchVision_FL(path_to_data, transform=eurosatTransformation())\n",
        "\n",
        "\n",
        "def get_dataloader(\n",
        "    path_to_data: str, cid: str, is_train: bool, batch_size: int, workers: int\n",
        "):\n",
        "    \"\"\"Generates trainset/valset object and returns appropiate dataloader.\"\"\"\n",
        "\n",
        "    partition = \"train\" if is_train else \"val\"\n",
        "    dataset = get_dataset(Path(path_to_data), cid, partition)\n",
        "\n",
        "    # we use as number of workers all the cpu cores assigned to this actor\n",
        "    kwargs = {\"num_workers\": workers, \"pin_memory\": True, \"drop_last\": False}\n",
        "    return DataLoader(dataset, batch_size=batch_size, **kwargs)\n",
        "\n",
        "\n",
        "def get_random_id_splits(total: int, val_ratio: float, shuffle: bool = True):\n",
        "    \"\"\"splits a list of length `total` into two following a\n",
        "    (1-val_ratio):val_ratio partitioning.\n",
        "\n",
        "    By default the indices are shuffled before creating the split and\n",
        "    returning.\n",
        "    \"\"\"\n",
        "\n",
        "    if isinstance(total, int):\n",
        "        indices = list(range(total))\n",
        "    else:\n",
        "        indices = total\n",
        "\n",
        "    split = int(np.floor(val_ratio * len(indices)))\n",
        "    # print(f\"Users left out for validation (ratio={val_ratio}) = {split} \")\n",
        "    if shuffle:\n",
        "        np.random.shuffle(indices)\n",
        "    return indices[split:], indices[:split]\n",
        "\n",
        "\n",
        "def do_fl_partitioning(path_to_dataset, pool_size, alpha, num_classes, val_ratio=0.0):\n",
        "    \"\"\"Torchvision (e.g. CIFAR-10) datasets using LDA.\"\"\"\n",
        "\n",
        "    images, labels = torch.load(path_to_dataset)\n",
        "\n",
        "    idx = np.array(range(len(images)))\n",
        "    dataset = [idx, labels]\n",
        "\n",
        "    # get the indices of the items for each partition using LDA\n",
        "    partitions, _ = create_lda_partitions(\n",
        "        dataset, num_partitions=pool_size, concentration=alpha, accept_imbalanced=True\n",
        "    )\n",
        "\n",
        "    # Show label distribution for first partition (purely informative)\n",
        "    partition_zero = partitions[0][1]\n",
        "    hist, _ = np.histogram(partition_zero, bins=list(range(num_classes + 1)))\n",
        "    print(\n",
        "        f\"Class histogram for 0-th partition (alpha={alpha}, {num_classes} classes): {hist}\"\n",
        "    )\n",
        "\n",
        "    # now save partitioned dataset to disk\n",
        "    # first delete dir containing splits (if exists), then create it\n",
        "    splits_dir = path_to_dataset.parent / \"federated\"\n",
        "    if splits_dir.exists():\n",
        "        shutil.rmtree(splits_dir)\n",
        "    Path.mkdir(splits_dir, parents=True)\n",
        "\n",
        "    for p in range(pool_size):\n",
        "\n",
        "        labels = partitions[p][1]\n",
        "        image_idx = partitions[p][0]\n",
        "        imgs = images[image_idx]\n",
        "\n",
        "        # create dir\n",
        "        Path.mkdir(splits_dir / str(p))\n",
        "\n",
        "        if val_ratio > 0.0:\n",
        "            # split data according to val_ratio\n",
        "            train_idx, val_idx = get_random_id_splits(len(labels), val_ratio)\n",
        "            val_imgs = imgs[val_idx]\n",
        "            val_labels = labels[val_idx]\n",
        "\n",
        "            with open(splits_dir / str(p) / \"val.pt\", \"wb\") as f:\n",
        "                torch.save([val_imgs, val_labels], f)\n",
        "\n",
        "            # remaining images for training\n",
        "            imgs = imgs[train_idx]\n",
        "            labels = labels[train_idx]\n",
        "\n",
        "        with open(splits_dir / str(p) / \"train.pt\", \"wb\") as f:\n",
        "            torch.save([imgs, labels], f)\n",
        "\n",
        "    return splits_dir\n",
        "\n",
        "\n",
        "def cifar10Transformation():\n",
        "\n",
        "    return transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "def eurosatTransformation():\n",
        "\n",
        "    return transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.3444, 0.3803, 0.4078), (0.2027, 0.1369, 0.1156)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "class TorchVision_FL(VisionDataset):\n",
        "    \"\"\"This is just a trimmed down version of torchvision.datasets.MNIST.\n",
        "\n",
        "    Use this class by either passing a path to a torch file (.pt)\n",
        "    containing (data, targets) or pass the data, targets directly\n",
        "    instead.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_to_data=None,\n",
        "        data=None,\n",
        "        targets=None,\n",
        "        transform: Optional[Callable] = None,\n",
        "    ) -> None:\n",
        "        path = path_to_data.parent if path_to_data else None\n",
        "        super(TorchVision_FL, self).__init__(path, transform=transform)\n",
        "        self.transform = transform\n",
        "\n",
        "        if path_to_data:\n",
        "            # load data and targets (path_to_data points to an specific .pt file)\n",
        "            self.data, self.targets = torch.load(path_to_data)\n",
        "        else:\n",
        "            self.data = data\n",
        "            self.targets = targets\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
        "        img, target = self.data[index], int(self.targets[index])\n",
        "\n",
        "        # doing this so that it is consistent with all other datasets\n",
        "        # to return a PIL Image\n",
        "        if not isinstance(img, Image.Image):  # if not PIL image\n",
        "            if not isinstance(img, np.ndarray):  # if torch tensor\n",
        "                img = img.numpy()\n",
        "\n",
        "            img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def get_cifar_10(path_to_data=\"./data\"):\n",
        "    \"\"\"Downloads CIFAR10 dataset and generates a unified training set (it will\n",
        "    be partitioned later using the LDA partitioning mechanism.\"\"\"\n",
        "\n",
        "    # download dataset and load train set\n",
        "    train_set = datasets.CIFAR10(root=path_to_data, train=True, download=True)\n",
        "\n",
        "    # fuse all data splits into a single \"training.pt\"\n",
        "    data_loc = Path(path_to_data) / \"cifar-10-batches-py\"\n",
        "    training_data = data_loc / \"training.pt\"\n",
        "    print(\"Generating unified CIFAR dataset\")\n",
        "    torch.save([train_set.data, np.array(train_set.targets)], training_data)\n",
        "\n",
        "    test_set = datasets.CIFAR10(\n",
        "        root=path_to_data, train=False, transform=cifar10Transformation()\n",
        "    )\n",
        "\n",
        "    # returns path where training data is and testset\n",
        "    return training_data, test_set\n",
        "\n",
        "def get_eurosat(path_to_data=\"./eurosat_data\"):\n",
        "\n",
        "    # download and split dataset into train and test sets\n",
        "    eurosat_dataset = datasets.EuroSAT(\"./eurosat_data\", download=True, transform=eurosatTransformation())\n",
        "\n",
        "    train_set, test_set = random_split(eurosat_dataset, [24000, 3000], torch.Generator().manual_seed(42))\n",
        "\n",
        "    # load all of the training images so we can combine them into a single PyTorch file (.pt)\n",
        "    train_set_data: Any = []\n",
        "\n",
        "    base_folder = \"eurosat/2750\"\n",
        "    path_list = [\"AnnualCrop\", \"Forest\", \"HerbaceousVegetation\", \"Highway\", \"Industrial\", \"Pasture\", \"PermanentCrop\", \"Residential\", \"River\", \"SeaLake\"]\n",
        "\n",
        "    for folder in path_list:\n",
        "        folder_path = os.path.join(path_to_data, base_folder, folder)\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            img = np.array(Image.open(file_path))\n",
        "            train_set_data.append(img)\n",
        "\n",
        "    train_set_data = np.array(train_set_data) # convert into numpy array of shape (N, H, W, C)\n",
        "\n",
        "    # fuse all data splits into a single dataset named \"training.pt\"\n",
        "    data_loc = Path(path_to_data) / \"eurosat\"\n",
        "    training_data_path = data_loc / \"training.pt\"\n",
        "    torch.save([train_set_data, np.array(train_set.dataset.targets)], training_data_path)\n",
        "\n",
        "    return training_data_path, test_set\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajv1d5ueGRF2",
        "outputId": "aff52f19-2803-49ea-fe96-f85ebb959498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataset_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile fedavg.py\n",
        "\n",
        "from logging import WARNING\n",
        "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "from flwr.common import (\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    MetricsAggregationFn,\n",
        "    NDArrays,\n",
        "    Parameters,\n",
        "    Scalar,\n",
        "    ndarrays_to_parameters,\n",
        "    parameters_to_ndarrays,\n",
        ")\n",
        "from flwr.common.logger import log\n",
        "from flwr.server.client_manager import ClientManager\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "\n",
        "from numpy import random\n",
        "\n",
        "from aggregate import aggregate, aggregate_inplace, weighted_loss_avg\n",
        "from strategy import Strategy\n",
        "\n",
        "WARNING_MIN_AVAILABLE_CLIENTS_TOO_LOW = \"\"\"\n",
        "Setting `min_available_clients` lower than `min_fit_clients` or\n",
        "`min_evaluate_clients` can cause the server to fail when there are too few clients\n",
        "connected to the server. `min_available_clients` must be set to a value larger\n",
        "than or equal to the values of `min_fit_clients` and `min_evaluate_clients`.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# pylint: disable=line-too-long\n",
        "class FedAvg(Strategy):\n",
        "    \"\"\"Federated Averaging strategy.\n",
        "\n",
        "    Implementation based on https://arxiv.org/abs/1602.05629\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    fraction_fit : float, optional\n",
        "        Fraction of clients used during training. In case `min_fit_clients`\n",
        "        is larger than `fraction_fit * available_clients`, `min_fit_clients`\n",
        "        will still be sampled. Defaults to 1.0.\n",
        "    fraction_evaluate : float, optional\n",
        "        Fraction of clients used during validation. In case `min_evaluate_clients`\n",
        "        is larger than `fraction_evaluate * available_clients`,\n",
        "        `min_evaluate_clients` will still be sampled. Defaults to 1.0.\n",
        "    min_fit_clients : int, optional\n",
        "        Minimum number of clients used during training. Defaults to 2.\n",
        "    min_evaluate_clients : int, optional\n",
        "        Minimum number of clients used during validation. Defaults to 2.\n",
        "    min_available_clients : int, optional\n",
        "        Minimum number of total clients in the system. Defaults to 2.\n",
        "    evaluate_fn : Optional[Callable[[int, NDArrays, Dict[str, Scalar]],Optional[Tuple[float, Dict[str, Scalar]]]]]\n",
        "        Optional function used for validation. Defaults to None.\n",
        "    on_fit_config_fn : Callable[[int], Dict[str, Scalar]], optional\n",
        "        Function used to configure training. Defaults to None.\n",
        "    on_evaluate_config_fn : Callable[[int], Dict[str, Scalar]], optional\n",
        "        Function used to configure validation. Defaults to None.\n",
        "    accept_failures : bool, optional\n",
        "        Whether or not accept rounds containing failures. Defaults to True.\n",
        "    initial_parameters : Parameters, optional\n",
        "        Initial global model parameters.\n",
        "    fit_metrics_aggregation_fn : Optional[MetricsAggregationFn]\n",
        "        Metrics aggregation function, optional.\n",
        "    evaluate_metrics_aggregation_fn : Optional[MetricsAggregationFn]\n",
        "        Metrics aggregation function, optional.\n",
        "    \"\"\"\n",
        "\n",
        "    # pylint: disable=too-many-arguments,too-many-instance-attributes, line-too-long\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        fraction_fit: float = 1.0,\n",
        "        fraction_evaluate: float = 1.0,\n",
        "        min_fit_clients: int = 2,\n",
        "        min_evaluate_clients: int = 2,\n",
        "        min_available_clients: int = 2,\n",
        "        evaluate_fn: Optional[\n",
        "            Callable[\n",
        "                [int, NDArrays, Dict[str, Scalar]],\n",
        "                Optional[Tuple[float, Dict[str, Scalar]]],\n",
        "            ]\n",
        "        ] = None,\n",
        "        on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        accept_failures: bool = True,\n",
        "        initial_parameters: Optional[Parameters] = None,\n",
        "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        inplace: bool = True,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        if (\n",
        "            min_fit_clients > min_available_clients\n",
        "            or min_evaluate_clients > min_available_clients\n",
        "        ):\n",
        "            log(WARNING, WARNING_MIN_AVAILABLE_CLIENTS_TOO_LOW)\n",
        "\n",
        "        self.fraction_fit = fraction_fit\n",
        "        self.fraction_evaluate = fraction_evaluate\n",
        "        self.min_fit_clients = min_fit_clients\n",
        "        self.min_evaluate_clients = min_evaluate_clients\n",
        "        self.min_available_clients = min_available_clients\n",
        "        self.evaluate_fn = evaluate_fn\n",
        "        self.on_fit_config_fn = on_fit_config_fn\n",
        "        self.on_evaluate_config_fn = on_evaluate_config_fn\n",
        "        self.accept_failures = accept_failures\n",
        "        self.initial_parameters = initial_parameters\n",
        "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
        "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
        "        self.inplace = inplace\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        \"\"\"Compute a string representation of the strategy.\"\"\"\n",
        "        rep = f\"FedAvg(accept_failures={self.accept_failures})\"\n",
        "        return rep\n",
        "\n",
        "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
        "        \"\"\"Return the sample size and the required number of available clients.\"\"\"\n",
        "        modded_fraction_fit = random.randint(30, 100) / 100 # changed this to get random numbers of clients per round\n",
        "        num_clients = int(num_available_clients * modded_fraction_fit)\n",
        "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
        "\n",
        "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
        "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
        "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
        "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
        "\n",
        "    def initialize_parameters(\n",
        "        self, client_manager: ClientManager\n",
        "    ) -> Optional[Parameters]:\n",
        "        \"\"\"Initialize global model parameters.\"\"\"\n",
        "        initial_parameters = self.initial_parameters\n",
        "        self.initial_parameters = None  # Don't keep initial parameters in memory\n",
        "        return initial_parameters\n",
        "\n",
        "    def evaluate(\n",
        "        self, server_round: int, parameters: Parameters\n",
        "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
        "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
        "        if self.evaluate_fn is None:\n",
        "            # No evaluation function provided\n",
        "            return None\n",
        "        parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
        "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
        "        if eval_res is None:\n",
        "            return None\n",
        "        loss, metrics = eval_res\n",
        "        return loss, metrics\n",
        "\n",
        "    def configure_fit(\n",
        "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
        "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
        "        \"\"\"Configure the next round of training.\"\"\"\n",
        "        config = {}\n",
        "        if self.on_fit_config_fn is not None:\n",
        "            # Custom fit config function provided\n",
        "            config = self.on_fit_config_fn(server_round)\n",
        "        fit_ins = FitIns(parameters, config)\n",
        "\n",
        "        # Sample clients\n",
        "        sample_size, min_num_clients = self.num_fit_clients(\n",
        "            client_manager.num_available()\n",
        "        )\n",
        "        clients = client_manager.sample(\n",
        "            num_clients=sample_size, min_num_clients=min_num_clients\n",
        "        )\n",
        "\n",
        "        # Return client/config pairs\n",
        "        return [(client, fit_ins) for client in clients]\n",
        "\n",
        "    def configure_evaluate(\n",
        "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
        "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
        "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
        "        # Do not configure federated evaluation if fraction eval is 0.\n",
        "        if self.fraction_evaluate == 0.0:\n",
        "            return []\n",
        "\n",
        "        # Parameters and config\n",
        "        config = {}\n",
        "        if self.on_evaluate_config_fn is not None:\n",
        "            # Custom evaluation config function provided\n",
        "            config = self.on_evaluate_config_fn(server_round)\n",
        "        evaluate_ins = EvaluateIns(parameters, config)\n",
        "\n",
        "        # Sample clients\n",
        "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
        "            client_manager.num_available()\n",
        "        )\n",
        "        clients = client_manager.sample(\n",
        "            num_clients=sample_size, min_num_clients=min_num_clients\n",
        "        )\n",
        "\n",
        "        # Return client/config pairs\n",
        "        return [(client, evaluate_ins) for client in clients]\n",
        "\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
        "        if not results:\n",
        "            return None, {}\n",
        "        # Do not aggregate if there are failures and failures are not accepted\n",
        "        if not self.accept_failures and failures:\n",
        "            return None, {}\n",
        "\n",
        "        if self.inplace:\n",
        "            # Does in-place weighted average of results\n",
        "            aggregated_ndarrays = aggregate_inplace(results)\n",
        "        else:\n",
        "            # Convert results\n",
        "            weights_results = [\n",
        "                (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
        "                for _, fit_res in results\n",
        "            ]\n",
        "            aggregated_ndarrays = aggregate(weights_results)\n",
        "\n",
        "        parameters_aggregated = ndarrays_to_parameters(aggregated_ndarrays)\n",
        "\n",
        "        # Aggregate custom metrics if aggregation fn was provided\n",
        "        metrics_aggregated = {}\n",
        "        if self.fit_metrics_aggregation_fn:\n",
        "            fit_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
        "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
        "        elif server_round == 1:  # Only log this warning once\n",
        "            log(WARNING, \"No fit_metrics_aggregation_fn provided\")\n",
        "\n",
        "        return parameters_aggregated, metrics_aggregated\n",
        "\n",
        "    def aggregate_evaluate(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
        "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
        "        if not results:\n",
        "            return None, {}\n",
        "        # Do not aggregate if there are failures and failures are not accepted\n",
        "        if not self.accept_failures and failures:\n",
        "            return None, {}\n",
        "\n",
        "        # Aggregate loss\n",
        "        loss_aggregated = weighted_loss_avg(\n",
        "            [\n",
        "                (evaluate_res.num_examples, evaluate_res.loss)\n",
        "                for _, evaluate_res in results\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Aggregate custom metrics if aggregation fn was provided\n",
        "        metrics_aggregated = {}\n",
        "        if self.evaluate_metrics_aggregation_fn:\n",
        "            eval_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
        "            metrics_aggregated = self.evaluate_metrics_aggregation_fn(eval_metrics)\n",
        "        elif server_round == 1:  # Only log this warning once\n",
        "            log(WARNING, \"No evaluate_metrics_aggregation_fn provided\")\n",
        "\n",
        "        return loss_aggregated, metrics_aggregated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL-Du5lZRffc",
        "outputId": "2799c4b9-c237-4a75-b74f-191d2518c736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing fedavg.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile strategy.py\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Dict, List, Optional, Tuple, Union\n",
        "\n",
        "from flwr.common import EvaluateIns, EvaluateRes, FitIns, FitRes, Parameters, Scalar\n",
        "from flwr.server.client_manager import ClientManager\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "\n",
        "\n",
        "class Strategy(ABC):\n",
        "    \"\"\"Abstract base class for server strategy implementations.\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def initialize_parameters(\n",
        "        self, client_manager: ClientManager\n",
        "    ) -> Optional[Parameters]:\n",
        "        \"\"\"Initialize the (global) model parameters.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        client_manager : ClientManager\n",
        "            The client manager which holds all currently connected clients.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        parameters : Optional[Parameters]\n",
        "            If parameters are returned, then the server will treat these as the\n",
        "            initial global model parameters.\n",
        "        \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def configure_fit(\n",
        "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
        "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
        "        \"\"\"Configure the next round of training.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        server_round : int\n",
        "            The current round of federated learning.\n",
        "        parameters : Parameters\n",
        "            The current (global) model parameters.\n",
        "        client_manager : ClientManager\n",
        "            The client manager which holds all currently connected clients.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        fit_configuration : List[Tuple[ClientProxy, FitIns]]\n",
        "            A list of tuples. Each tuple in the list identifies a `ClientProxy` and the\n",
        "            `FitIns` for this particular `ClientProxy`. If a particular `ClientProxy`\n",
        "            is not included in this list, it means that this `ClientProxy`\n",
        "            will not participate in the next round of federated learning.\n",
        "        \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate training results.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        server_round : int\n",
        "            The current round of federated learning.\n",
        "        results : List[Tuple[ClientProxy, FitRes]]\n",
        "            Successful updates from the previously selected and configured\n",
        "            clients. Each pair of `(ClientProxy, FitRes)` constitutes a\n",
        "            successful update from one of the previously selected clients. Not\n",
        "            that not all previously selected clients are necessarily included in\n",
        "            this list: a client might drop out and not submit a result. For each\n",
        "            client that did not submit an update, there should be an `Exception`\n",
        "            in `failures`.\n",
        "        failures : List[Union[Tuple[ClientProxy, FitRes], BaseException]]\n",
        "            Exceptions that occurred while the server was waiting for client\n",
        "            updates.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        parameters : Tuple[Optional[Parameters], Dict[str, Scalar]]\n",
        "            If parameters are returned, then the server will treat these as the\n",
        "            new global model parameters (i.e., it will replace the previous\n",
        "            parameters with the ones returned from this method). If `None` is\n",
        "            returned (e.g., because there were only failures and no viable\n",
        "            results) then the server will no update the previous model\n",
        "            parameters, the updates received in this round are discarded, and\n",
        "            the global model parameters remain the same.\n",
        "        \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def configure_evaluate(\n",
        "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
        "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
        "        \"\"\"Configure the next round of evaluation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        server_round : int\n",
        "            The current round of federated learning.\n",
        "        parameters : Parameters\n",
        "            The current (global) model parameters.\n",
        "        client_manager : ClientManager\n",
        "            The client manager which holds all currently connected clients.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        evaluate_configuration : List[Tuple[ClientProxy, EvaluateIns]]\n",
        "            A list of tuples. Each tuple in the list identifies a `ClientProxy` and the\n",
        "            `EvaluateIns` for this particular `ClientProxy`. If a particular\n",
        "            `ClientProxy` is not included in this list, it means that this\n",
        "            `ClientProxy` will not participate in the next round of federated\n",
        "            evaluation.\n",
        "        \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def aggregate_evaluate(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
        "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate evaluation results.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        server_round : int\n",
        "            The current round of federated learning.\n",
        "        results : List[Tuple[ClientProxy, FitRes]]\n",
        "            Successful updates from the\n",
        "            previously selected and configured clients. Each pair of\n",
        "            `(ClientProxy, FitRes` constitutes a successful update from one of the\n",
        "            previously selected clients. Not that not all previously selected\n",
        "            clients are necessarily included in this list: a client might drop out\n",
        "            and not submit a result. For each client that did not submit an update,\n",
        "            there should be an `Exception` in `failures`.\n",
        "        failures : List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]]\n",
        "            Exceptions that occurred while the server was waiting for client updates.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        aggregation_result : Tuple[Optional[float], Dict[str, Scalar]]\n",
        "            The aggregated evaluation result. Aggregation typically uses some variant\n",
        "            of a weighted average.\n",
        "        \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def evaluate(\n",
        "        self, server_round: int, parameters: Parameters\n",
        "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
        "        \"\"\"Evaluate the current model parameters.\n",
        "\n",
        "        This function can be used to perform centralized (i.e., server-side) evaluation\n",
        "        of model parameters.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        server_round : int\n",
        "            The current round of federated learning.\n",
        "        parameters: Parameters\n",
        "            The current (global) model parameters.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        evaluation_result : Optional[Tuple[float, Dict[str, Scalar]]]\n",
        "            The evaluation result, usually a Tuple containing loss and a\n",
        "            dictionary containing task-specific metrics (e.g., accuracy).\n",
        "        \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ9ivfgUCSEm",
        "outputId": "63c2e59a-c851-4c69-b622-482ce64ed661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing strategy.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile aggregate.py\n",
        "\n",
        "from functools import reduce\n",
        "from typing import Any, Callable, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from flwr.common import FitRes, NDArray, NDArrays, parameters_to_ndarrays\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "\n",
        "\n",
        "def aggregate(results: List[Tuple[NDArrays, int]]) -> NDArrays:\n",
        "    \"\"\"Compute weighted average.\"\"\"\n",
        "    # Calculate the total number of examples used during training\n",
        "    num_examples_total = sum([num_examples for _, num_examples in results])\n",
        "\n",
        "    # Create a list of weights, each multiplied by the related number of examples\n",
        "    weighted_weights = [\n",
        "        [layer * num_examples for layer in weights] for weights, num_examples in results\n",
        "    ]\n",
        "\n",
        "    # Compute average weights of each layer\n",
        "    weights_prime: NDArrays = [\n",
        "        reduce(np.add, layer_updates) / num_examples_total\n",
        "        for layer_updates in zip(*weighted_weights)\n",
        "    ]\n",
        "    return weights_prime\n",
        "\n",
        "\n",
        "def aggregate_inplace(results: List[Tuple[ClientProxy, FitRes]]) -> NDArrays:\n",
        "    \"\"\"Compute in-place weighted average.\"\"\"\n",
        "    # Count total examples\n",
        "    num_examples_total = sum([fit_res.num_examples for _, fit_res in results])\n",
        "\n",
        "    # Compute scaling factors for each result\n",
        "    scaling_factors = [\n",
        "        fit_res.num_examples / num_examples_total for _, fit_res in results\n",
        "    ]\n",
        "\n",
        "    # Let's do in-place aggregation\n",
        "    # Get first result, then add up each other\n",
        "    params = [\n",
        "        scaling_factors[0] * x for x in parameters_to_ndarrays(results[0][1].parameters)\n",
        "    ]\n",
        "    for i, (_, fit_res) in enumerate(results[1:]):\n",
        "        res = (\n",
        "            scaling_factors[i + 1] * x\n",
        "            for x in parameters_to_ndarrays(fit_res.parameters)\n",
        "        )\n",
        "        params = [reduce(np.add, layer_updates) for layer_updates in zip(params, res)]\n",
        "\n",
        "    return params\n",
        "\n",
        "\n",
        "def aggregate_median(results: List[Tuple[NDArrays, int]]) -> NDArrays:\n",
        "    \"\"\"Compute median.\"\"\"\n",
        "    # Create a list of weights and ignore the number of examples\n",
        "    weights = [weights for weights, _ in results]\n",
        "\n",
        "    # Compute median weight of each layer\n",
        "    median_w: NDArrays = [\n",
        "        np.median(np.asarray(layer), axis=0) for layer in zip(*weights)\n",
        "    ]\n",
        "    return median_w\n",
        "\n",
        "\n",
        "def aggregate_krum(\n",
        "    results: List[Tuple[NDArrays, int]], num_malicious: int, to_keep: int\n",
        ") -> NDArrays:\n",
        "    \"\"\"Choose one parameter vector according to the Krum function.\n",
        "\n",
        "    If to_keep is not None, then MultiKrum is applied.\n",
        "    \"\"\"\n",
        "    # Create a list of weights and ignore the number of examples\n",
        "    weights = [weights for weights, _ in results]\n",
        "\n",
        "    # Compute distances between vectors\n",
        "    distance_matrix = _compute_distances(weights)\n",
        "\n",
        "    # For each client, take the n-f-2 closest parameters vectors\n",
        "    num_closest = max(1, len(weights) - num_malicious - 2)\n",
        "    closest_indices = []\n",
        "    for i, _ in enumerate(distance_matrix):\n",
        "        closest_indices.append(\n",
        "            np.argsort(distance_matrix[i])[1 : num_closest + 1].tolist()  # noqa: E203\n",
        "        )\n",
        "\n",
        "    # Compute the score for each client, that is the sum of the distances\n",
        "    # of the n-f-2 closest parameters vectors\n",
        "    scores = [\n",
        "        np.sum(distance_matrix[i, closest_indices[i]])\n",
        "        for i in range(len(distance_matrix))\n",
        "    ]\n",
        "\n",
        "    if to_keep > 0:\n",
        "        # Choose to_keep clients and return their average (MultiKrum)\n",
        "        best_indices = np.argsort(scores)[::-1][len(scores) - to_keep :]  # noqa: E203\n",
        "        best_results = [results[i] for i in best_indices]\n",
        "        return aggregate(best_results)\n",
        "\n",
        "    # Return the model parameters that minimize the score (Krum)\n",
        "    return weights[np.argmin(scores)]\n",
        "\n",
        "\n",
        "# pylint: disable=too-many-locals\n",
        "def aggregate_bulyan(\n",
        "    results: List[Tuple[NDArrays, int]],\n",
        "    num_malicious: int,\n",
        "    aggregation_rule: Callable,  # type: ignore\n",
        "    **aggregation_rule_kwargs: Any,\n",
        ") -> NDArrays:\n",
        "    \"\"\"Perform Bulyan aggregation.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    results: List[Tuple[NDArrays, int]]\n",
        "        Weights and number of samples for each of the client.\n",
        "    num_malicious: int\n",
        "        The maximum number of malicious clients.\n",
        "    aggregation_rule: Callable\n",
        "        Byzantine resilient aggregation rule used as the first step of the Bulyan\n",
        "    aggregation_rule_kwargs: Any\n",
        "        The arguments to the aggregation rule.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    aggregated_parameters: NDArrays\n",
        "        Aggregated parameters according to the Bulyan strategy.\n",
        "    \"\"\"\n",
        "    byzantine_resilient_single_ret_model_aggregation = [aggregate_krum]\n",
        "    # also GeoMed (but not implemented yet)\n",
        "    byzantine_resilient_many_return_models_aggregation = []  # type: ignore\n",
        "    # Brute, Medoid (but not implemented yet)\n",
        "\n",
        "    num_clients = len(results)\n",
        "    if num_clients < 4 * num_malicious + 3:\n",
        "        raise ValueError(\n",
        "            \"The Bulyan aggregation requires then number of clients to be greater or \"\n",
        "            \"equal to the 4 * num_malicious + 3. This is the assumption of this method.\"\n",
        "            \"It is needed to ensure that the method reduces the attacker's leeway to \"\n",
        "            \"the one proved in the paper.\"\n",
        "        )\n",
        "    selected_models_set: List[Tuple[NDArrays, int]] = []\n",
        "\n",
        "    theta = len(results) - 2 * num_malicious\n",
        "    beta = theta - 2 * num_malicious\n",
        "\n",
        "    for _ in range(theta):\n",
        "        best_model = aggregation_rule(\n",
        "            results=results, num_malicious=num_malicious, **aggregation_rule_kwargs\n",
        "        )\n",
        "        list_of_weights = [weights for weights, num_samples in results]\n",
        "        # This group gives exact result\n",
        "        if aggregation_rule in byzantine_resilient_single_ret_model_aggregation:\n",
        "            best_idx = _find_reference_weights(best_model, list_of_weights)\n",
        "        # This group requires finding the closest model to the returned one\n",
        "        # (weights distance wise)\n",
        "        elif aggregation_rule in byzantine_resilient_many_return_models_aggregation:\n",
        "            # when different aggregation strategies available\n",
        "            # write a function to find the closest model\n",
        "            raise NotImplementedError(\n",
        "                \"aggregate_bulyan currently does not support the aggregation rules that\"\n",
        "                \" return many models as results. \"\n",
        "                \"Such aggregation rules are currently not available in Flower.\"\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"The given aggregation rule is not added as Byzantine resilient. \"\n",
        "                \"Please choose from Byzantine resilient rules.\"\n",
        "            )\n",
        "\n",
        "        selected_models_set.append(results[best_idx])\n",
        "\n",
        "        # remove idx from tracker and weights_results\n",
        "        results.pop(best_idx)\n",
        "\n",
        "    # Compute median parameter vector across selected_models_set\n",
        "    median_vect = aggregate_median(selected_models_set)\n",
        "\n",
        "    # Take the averaged beta parameters of the closest distance to the median\n",
        "    # (coordinate-wise)\n",
        "    parameters_aggregated = _aggregate_n_closest_weights(\n",
        "        median_vect, selected_models_set, beta_closest=beta\n",
        "    )\n",
        "    return parameters_aggregated\n",
        "\n",
        "\n",
        "def weighted_loss_avg(results: List[Tuple[int, float]]) -> float:\n",
        "    \"\"\"Aggregate evaluation results obtained from multiple clients.\"\"\"\n",
        "    num_total_evaluation_examples = sum([num_examples for num_examples, _ in results])\n",
        "    weighted_losses = [num_examples * loss for num_examples, loss in results]\n",
        "    return sum(weighted_losses) / num_total_evaluation_examples\n",
        "\n",
        "\n",
        "def aggregate_qffl(\n",
        "    parameters: NDArrays, deltas: List[NDArrays], hs_fll: List[NDArrays]\n",
        ") -> NDArrays:\n",
        "    \"\"\"Compute weighted average based on Q-FFL paper.\"\"\"\n",
        "    demominator: float = np.sum(np.asarray(hs_fll))\n",
        "    scaled_deltas = []\n",
        "    for client_delta in deltas:\n",
        "        scaled_deltas.append([layer * 1.0 / demominator for layer in client_delta])\n",
        "    updates = []\n",
        "    for i in range(len(deltas[0])):\n",
        "        tmp = scaled_deltas[0][i]\n",
        "        for j in range(1, len(deltas)):\n",
        "            tmp += scaled_deltas[j][i]\n",
        "        updates.append(tmp)\n",
        "    new_parameters = [(u - v) * 1.0 for u, v in zip(parameters, updates)]\n",
        "    return new_parameters\n",
        "\n",
        "\n",
        "def _compute_distances(weights: List[NDArrays]) -> NDArray:\n",
        "    \"\"\"Compute distances between vectors.\n",
        "\n",
        "    Input: weights - list of weights vectors\n",
        "    Output: distances - matrix distance_matrix of squared distances between the vectors\n",
        "    \"\"\"\n",
        "    flat_w = np.array([np.concatenate(p, axis=None).ravel() for p in weights])\n",
        "    distance_matrix = np.zeros((len(weights), len(weights)))\n",
        "    for i, _ in enumerate(flat_w):\n",
        "        for j, _ in enumerate(flat_w):\n",
        "            delta = flat_w[i] - flat_w[j]\n",
        "            norm = np.linalg.norm(delta)\n",
        "            distance_matrix[i, j] = norm**2\n",
        "    return distance_matrix\n",
        "\n",
        "\n",
        "def _trim_mean(array: NDArray, proportiontocut: float) -> NDArray:\n",
        "    \"\"\"Compute trimmed mean along axis=0.\n",
        "\n",
        "    It is based on the scipy implementation.\n",
        "\n",
        "    https://docs.scipy.org/doc/scipy/reference/generated/\n",
        "    scipy.stats.trim_mean.html.\n",
        "    \"\"\"\n",
        "    axis = 0\n",
        "    nobs = array.shape[axis]\n",
        "    lowercut = int(proportiontocut * nobs)\n",
        "    uppercut = nobs - lowercut\n",
        "    if lowercut > uppercut:\n",
        "        raise ValueError(\"Proportion too big.\")\n",
        "\n",
        "    atmp = np.partition(array, (lowercut, uppercut - 1), axis)\n",
        "\n",
        "    slice_list = [slice(None)] * atmp.ndim\n",
        "    slice_list[axis] = slice(lowercut, uppercut)\n",
        "    result: NDArray = np.mean(atmp[tuple(slice_list)], axis=axis)\n",
        "    return result\n",
        "\n",
        "\n",
        "def aggregate_trimmed_avg(\n",
        "    results: List[Tuple[NDArrays, int]], proportiontocut: float\n",
        ") -> NDArrays:\n",
        "    \"\"\"Compute trimmed average.\"\"\"\n",
        "    # Create a list of weights and ignore the number of examples\n",
        "    weights = [weights for weights, _ in results]\n",
        "\n",
        "    trimmed_w: NDArrays = [\n",
        "        _trim_mean(np.asarray(layer), proportiontocut=proportiontocut)\n",
        "        for layer in zip(*weights)\n",
        "    ]\n",
        "\n",
        "    return trimmed_w\n",
        "\n",
        "\n",
        "def _check_weights_equality(weights1: NDArrays, weights2: NDArrays) -> bool:\n",
        "    \"\"\"Check if weights are the same.\"\"\"\n",
        "    if len(weights1) != len(weights2):\n",
        "        return False\n",
        "    return all(\n",
        "        np.array_equal(layer_weights1, layer_weights2)\n",
        "        for layer_weights1, layer_weights2 in zip(weights1, weights2)\n",
        "    )\n",
        "\n",
        "\n",
        "def _find_reference_weights(\n",
        "    reference_weights: NDArrays, list_of_weights: List[NDArrays]\n",
        ") -> int:\n",
        "    \"\"\"Find the reference weights by looping through the `list_of_weights`.\n",
        "\n",
        "    Raise Error if the reference weights is not found.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    reference_weights: NDArrays\n",
        "        Weights that will be searched for.\n",
        "    list_of_weights: List[NDArrays]\n",
        "        List of weights that will be searched through.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    index: int\n",
        "        The index of `reference_weights` in the `list_of_weights`.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    ValueError\n",
        "        If `reference_weights` is not found in `list_of_weights`.\n",
        "    \"\"\"\n",
        "    for idx, weights in enumerate(list_of_weights):\n",
        "        if _check_weights_equality(reference_weights, weights):\n",
        "            return idx\n",
        "    raise ValueError(\"The reference weights not found in list_of_weights.\")\n",
        "\n",
        "\n",
        "def _aggregate_n_closest_weights(\n",
        "    reference_weights: NDArrays, results: List[Tuple[NDArrays, int]], beta_closest: int\n",
        ") -> NDArrays:\n",
        "    \"\"\"Calculate element-wise mean of the `N` closest values.\n",
        "\n",
        "    Note, each i-th coordinate of the result weight is the average of the beta_closest\n",
        "    -ith coordinates to the reference weights\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    reference_weights: NDArrays\n",
        "        The weights from which the distances will be computed\n",
        "    results: List[Tuple[NDArrays, int]]\n",
        "        The weights from models\n",
        "    beta_closest: int\n",
        "        The number of the closest distance weights that will be averaged\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    aggregated_weights: NDArrays\n",
        "        Averaged (element-wise) beta weights that have the closest distance to\n",
        "         reference weights\n",
        "    \"\"\"\n",
        "    list_of_weights = [weights for weights, num_examples in results]\n",
        "    aggregated_weights = []\n",
        "\n",
        "    for layer_id, layer_weights in enumerate(reference_weights):\n",
        "        other_weights_layer_list = []\n",
        "        for other_w in list_of_weights:\n",
        "            other_weights_layer = other_w[layer_id]\n",
        "            other_weights_layer_list.append(other_weights_layer)\n",
        "        other_weights_layer_np = np.array(other_weights_layer_list)\n",
        "        diff_np = np.abs(layer_weights - other_weights_layer_np)\n",
        "        # Create indices of the smallest differences\n",
        "        # We do not need the exact order but just the beta closest weights\n",
        "        # therefore np.argpartition is used instead of np.argsort\n",
        "        indices = np.argpartition(diff_np, kth=beta_closest - 1, axis=0)\n",
        "        # Take the weights (coordinate-wise) corresponding to the beta of the\n",
        "        # closest distances\n",
        "        beta_closest_weights = np.take_along_axis(\n",
        "            other_weights_layer_np, indices=indices, axis=0\n",
        "        )[:beta_closest]\n",
        "        aggregated_weights.append(np.mean(beta_closest_weights, axis=0))\n",
        "    return aggregated_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah5oDG3eB_BX",
        "outputId": "eb207293-fafa-4748-fd95-d8fee0a7db79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing aggregate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile simple_cnn.py\n",
        "\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "from typing import Optional\n",
        "\n",
        "import flwr as fl\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "    \"\"\"Simple CNN adapted from 'PyTorch: A 60 Minute Blitz'.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(2704, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 2704) # change to match the dimension of prev layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def get_weights(self) -> fl.common.NDArrays:\n",
        "        \"\"\"Get model weights as a list of NumPy ndarrays.\"\"\"\n",
        "        return [val.cpu().numpy() for _, val in self.state_dict().items()]\n",
        "\n",
        "    def set_weights(self, weights: fl.common.NDArrays) -> None:\n",
        "        \"\"\"Set model weight s from a list of NumPy ndarrays.\"\"\"\n",
        "        state_dict = OrderedDict(\n",
        "            {k: torch.Tensor(v) for k, v in zip(self.state_dict().keys(), weights)}\n",
        "        )\n",
        "        self.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "def train(\n",
        "    net: Net,\n",
        "    trainloader: DataLoader,\n",
        "    device: torch.device,\n",
        "    num_iterations: int,\n",
        "    log_progress: bool = True,\n",
        "    optim='SGD'):\n",
        "\n",
        "    # Define loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    if optim == 'SGD':\n",
        "      optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "    elif optim == 'Adam':\n",
        "      optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "    def cycle(iterable):\n",
        "        \"\"\"Repeats the contents of the train loader, in case it gets exhausted in 'num_iterations'.\"\"\"\n",
        "        while True:\n",
        "            for x in iterable:\n",
        "                yield x\n",
        "\n",
        "    # Train the network\n",
        "    net.train()\n",
        "    total_loss, total_correct, n_samples = 0.0, 0.0, 0\n",
        "    pbar = tqdm(iter(cycle(trainloader)), total=num_iterations, desc=f'TRAIN') if log_progress else iter(cycle(trainloader))\n",
        "\n",
        "    # Unusually, this training is formulated in terms of number of updates/iterations/batches processed\n",
        "    # by the network. This will be helpful later on, when partitioning the data across clients: resulting\n",
        "    # in differences between dataset sizes and hence inconsistent numbers of updates per 'epoch'.\n",
        "    for i, data in zip(range(num_iterations), pbar):\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Collected training loss and accuracy statistics\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        if log_progress:\n",
        "            pbar.set_postfix({\n",
        "                \"train_loss\": total_loss/n_samples,\n",
        "                \"train_acc\": total_correct/n_samples\n",
        "            })\n",
        "    if log_progress:\n",
        "        print(\"\\n\")\n",
        "\n",
        "    return total_loss/n_samples, total_correct/n_samples, n_samples\n",
        "\n",
        "def test(\n",
        "    net: Net,\n",
        "    testloader: DataLoader,\n",
        "    device: torch.device,\n",
        "    log_progress: bool = True):\n",
        "    \"\"\"Evaluates the network on test data.\"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    num_classes = 10\n",
        "    total_loss, total_correct, n_samples = 0.0, 0.0, 0\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    # for calculating precision and recall metrics\n",
        "    total_true = np.zeros(num_classes) # array to store total instances of each class\n",
        "    total_pred = np.zeros(num_classes) # array to store total predictions of each class\n",
        "    total_tp = np.zeros(num_classes) # array to store total true positives of each class\n",
        "\n",
        "    len_testset = len(testloader.dataset)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(testloader, desc=\"TEST\") if log_progress else testloader\n",
        "        for data in pbar:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = net(images)\n",
        "\n",
        "            # Collected testing loss and accuracy statistics\n",
        "            total_loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            n_samples += labels.size(0)\n",
        "            total_correct += (predicted == labels).sum().item() # number of true positives\n",
        "\n",
        "            # count instances of actual, predicted and the true positives for each class\n",
        "            where_correct = (predicted == labels)\n",
        "            true_positives = predicted[where_correct]\n",
        "            for cls_idx in range(num_classes):\n",
        "                total_true[cls_idx] += (labels == cls_idx).sum().item() # total true (actual) instances of current class\n",
        "                total_pred[cls_idx] += (predicted == cls_idx).sum().item() # total predicted instances of current class\n",
        "                total_tp[cls_idx] += (true_positives == cls_idx).sum().item() # true positive predictions of current class\n",
        "\n",
        "    precisions = total_tp / total_pred\n",
        "    recalls = total_tp / total_true\n",
        "    proportions = total_true / len_testset\n",
        "\n",
        "    if log_progress:\n",
        "        print(\"\\n\")\n",
        "\n",
        "    return total_loss/n_samples, total_correct/n_samples, n_samples, precisions, recalls, proportions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CFcw5R4Rq3n",
        "outputId": "213f1283-62c2-4d64-f647-86afc13a2ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing simple_cnn.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile client.py\n",
        "\n",
        "from typing import Optional\n",
        "from pathlib import Path\n",
        "\n",
        "import flwr as fl\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from flwr.common import EvaluateIns, EvaluateRes, FitIns, FitRes, GetPropertiesIns, GetPropertiesRes, GetParametersIns, \\\n",
        "    GetParametersRes, Status, Code, parameters_to_ndarrays, ndarrays_to_parameters\n",
        "\n",
        "from simple_cnn import Net, train, test\n",
        "from dataset_utils import get_dataset\n",
        "\n",
        "\n",
        "def get_dataloader(path_to_data: str, cid: str, partition: str, batch_size: int):\n",
        "    \"\"\"Generates trainset/valset object and returns appropiate dataloader.\"\"\"\n",
        "    dataset = get_dataset(Path(path_to_data), cid, partition)\n",
        "    return DataLoader(dataset, batch_size=batch_size, pin_memory=True,\n",
        "                      shuffle=(partition == \"train\"))\n",
        "\n",
        "\n",
        "class EuroSATClient(fl.client.Client):\n",
        "    def __init__(self, cid: str, fed_data_dir: str, log_progress: bool = False):\n",
        "        \"\"\"\n",
        "        Creates a client for training `network.Net` on CIFAR-10.\n",
        "\n",
        "        Args:\n",
        "            cid: A unique ID given to the client (typically a number)\n",
        "            fed_data_dir: A path to a partitioned dataset\n",
        "            log_progress: Controls whether clients log their progress\n",
        "        \"\"\"\n",
        "        self.cid = cid\n",
        "        self.data_dir = fed_data_dir\n",
        "        self.properties = {\"tensor_type\": \"numpy.ndarray\"}\n",
        "        self.log_progress = log_progress\n",
        "        # Initilise the `net`` variable to `None`\n",
        "        self.net = None\n",
        "\n",
        "        # determine device\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def get_properties(self, ins: GetPropertiesIns):\n",
        "        return GetPropertiesRes(properties=self.properties)\n",
        "\n",
        "    def get_parameters(self, ins: GetParametersIns):\n",
        "        if self.net is None:\n",
        "            self.net = Net()\n",
        "        return GetParametersRes(status=Status(Code.OK, \"\"), parameters=ndarrays_to_parameters(self.net.get_weights()))\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        if self.net is None:\n",
        "            self.net = Net()\n",
        "        self.net.set_weights(parameters_to_ndarrays(parameters))\n",
        "\n",
        "    def fit(self, fit_params: FitIns) -> FitRes:\n",
        "        # Instantiate model (best practise)\n",
        "        self.net = Net()\n",
        "        # Process incoming request to train\n",
        "        batch_size = fit_params.config[\"batch_size\"]\n",
        "        num_iterations = fit_params.config[\"num_iterations\"]\n",
        "        self.set_parameters(fit_params.parameters)\n",
        "\n",
        "        # Initialise data loader\n",
        "        trainloader = get_dataloader(\n",
        "            path_to_data=self.data_dir,\n",
        "            cid=self.cid,\n",
        "            partition=\"train\",\n",
        "            batch_size=batch_size)\n",
        "\n",
        "        # num_iterations = None special behaviour: train(...) runs for a single epoch, however many updates it may be\n",
        "        num_iterations = num_iterations or len(trainloader)\n",
        "\n",
        "        # Train the model\n",
        "        print(f\"Client {self.cid}: training for {num_iterations} iterations/updates\")\n",
        "        self.net.to(self.device)\n",
        "        train_loss, train_acc, num_examples = \\\n",
        "            train(self.net, trainloader,\n",
        "                  device=self.device,\n",
        "                  num_iterations=num_iterations,\n",
        "                  log_progress=self.log_progress,\n",
        "                  optim='Adam')\n",
        "        print(f\"Client {self.cid}: training round complete, {num_examples} examples processed\")\n",
        "\n",
        "        # Return training information: model, number of examples processed and metrics\n",
        "        return FitRes(\n",
        "            status=Status(Code.OK, \"\"),\n",
        "            parameters=self.get_parameters(fit_params.config).parameters,\n",
        "            num_examples=num_examples,\n",
        "            metrics={\"loss\": train_loss, \"accuracy\": train_acc})\n",
        "\n",
        "    def evaluate(self, eval_params: EvaluateIns) -> EvaluateRes:\n",
        "        # Process incoming request to evaluate\n",
        "        batch_size = eval_params.config[\"batch_size\"]\n",
        "        self.set_parameters(eval_params.parameters)\n",
        "\n",
        "        # Initialise data loader\n",
        "        valloader = get_dataloader(\n",
        "            path_to_data=self.data_dir,\n",
        "            cid=self.cid,\n",
        "            partition=\"val\",\n",
        "            batch_size=batch_size)\n",
        "\n",
        "        # Evaluate the model\n",
        "        self.net.to(self.device)\n",
        "        loss, accuracy, num_examples, _, _, _ = test(self.net, valloader, device=self.device, log_progress=self.log_progress)\n",
        "\n",
        "        print(f\"Client {self.cid}: evaluation on {num_examples} examples: loss={loss:.4f}, accuracy={accuracy:.4f}\")\n",
        "        # Return evaluation information\n",
        "        return EvaluateRes(\n",
        "            status=Status(Code.OK, \"\"),\n",
        "            loss=loss, num_examples=num_examples,\n",
        "            metrics={\"accuracy\": accuracy})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0YpW4aFVdGi",
        "outputId": "99a52bed-9d02-4087-9e83-46fca0b153e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing client.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile server.py\n",
        "\n",
        "import argparse\n",
        "import functools\n",
        "\n",
        "import flwr as fl\n",
        "import torch\n",
        "import click\n",
        "from torch.utils.data import DataLoader\n",
        "#from flwr.server.strategy import FedAvg\n",
        "from flwr.server.app import ServerConfig\n",
        "from flwr.common import NDArrays\n",
        "\n",
        "from dataset_utils import get_eurosat, do_fl_partitioning\n",
        "from simple_cnn import Net, test\n",
        "from client import EuroSATClient\n",
        "from fedavg import FedAvg\n",
        "\n",
        "def serverside_eval(server_round, parameters: NDArrays, config, testloader):\n",
        "    \"\"\"An evaluation function for centralized/serverside evaluation over the entire EuroSAT test set.\"\"\"\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = Net()\n",
        "    model.set_weights(parameters)\n",
        "    model.to(device)\n",
        "    loss, accuracy, _, precisions, recalls, proportions = test(model, testloader, device=device, log_progress=False)\n",
        "    print(f\"Evaluation on the server: test_loss={loss:.4f}, test_accuracy={accuracy:.4f}\")\n",
        "    return loss, {\"accuracy\": accuracy, \"precisions\": precisions, \"recalls\": recalls, \"class proportions\": proportions}\n",
        "\n",
        "\n",
        "@click.command()\n",
        "@click.option(\"--num-rounds\", default=10, help=\"The number of rounds in the FL experiment\")\n",
        "@click.option(\"--client-pool-size\", default=5, help=\"The number of clients made available to an FL round\")\n",
        "@click.option(\"--num-iterations\", default=None, type=int,\n",
        "              help=\"Number of iterations/updates a client performs per round (single local epoch if None)\")\n",
        "@click.option(\"--fraction-fit\", default=1.0,\n",
        "              help=\"Controls what fraction of clients should be sampled for an FL fitting round.\")\n",
        "@click.option(\"--min-fit-clients\", default=2,\n",
        "              help=\"The minimum number of clients to participate in a fitting round (regardless of 'fraction_fit')\")\n",
        "@click.option(\"--batch-size\", default=32, help=\"Batch size for a client fitting round\")\n",
        "@click.option(\"--val-ratio\", default=0.1, help=\"Proportion of local data to reserve as a local test set\")\n",
        "@click.option(\"--iid-alpha\", default=1000.0, help=\"LDA prior concentration parameter for data partitioning\")\n",
        "def start_experiment(\n",
        "    num_rounds=10,\n",
        "    client_pool_size=5,\n",
        "    num_iterations=None,\n",
        "    fraction_fit=1.0,\n",
        "    min_fit_clients=2,\n",
        "    batch_size=32,\n",
        "    val_ratio=0.1,\n",
        "    iid_alpha=1000.0):\n",
        "    client_resources = {\"num_cpus\": 0.5}  # 2 clients per CPU\n",
        "\n",
        "    # Download the EuroSAT dataset\n",
        "    train_path, testset = get_eurosat()\n",
        "\n",
        "    # Partition the dataset into subsets reserved for each client.\n",
        "    # - to control the degree of IID: use a large `alpha` to make it IID; a small value (e.g. 1) will make it non-IID\n",
        "    # - 'val_ratio' controls the proportion of the (local) client reserved as a local test set\n",
        "    # (good for testing how the final model performs on the client's local unseen data)\n",
        "    fed_data_dir = do_fl_partitioning(train_path, pool_size=client_pool_size,\n",
        "                                      alpha=iid_alpha, num_classes=10, val_ratio=val_ratio)\n",
        "    print(f\"Data partitioned across {client_pool_size} clients, with IID alpha = {iid_alpha} \"\n",
        "          f\"and {val_ratio} of local dataset reserved for validation.\")\n",
        "\n",
        "    testloader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Configure the strategy\n",
        "    def fit_config(server_round: int):\n",
        "        print(f\"Configuring round {server_round}\")\n",
        "\n",
        "        # iterations = 16*x^2 + 6*x\n",
        "        # (quadratically increase, total is 98830 iterations if num_rounds is 10)\n",
        "        new_num_iterations = 16*server_round*server_round + 6*server_round\n",
        "\n",
        "        return {\n",
        "            \"num_iterations\": num_iterations,\n",
        "            \"batch_size\": batch_size,\n",
        "        }\n",
        "\n",
        "    # FedAvg simply averages contributions from all clients\n",
        "    strategy = FedAvg(\n",
        "        fraction_fit=fraction_fit,\n",
        "        fraction_evaluate=fraction_fit if val_ratio > 0.0 else 0.0,\n",
        "        min_fit_clients=min_fit_clients,\n",
        "        min_evaluate_clients=min_fit_clients,\n",
        "        min_available_clients=client_pool_size,  # all clients should be available\n",
        "        on_fit_config_fn=fit_config,\n",
        "        on_evaluate_config_fn=(lambda r: {\"batch_size\": 100}),\n",
        "        evaluate_fn=functools.partial(serverside_eval, testloader=testloader),\n",
        "        accept_failures=False,\n",
        "    )\n",
        "\n",
        "    print(f\"FL experiment configured for {num_rounds} rounds with {client_pool_size} client in the pool.\")\n",
        "    print(f\"FL round will proceed with {fraction_fit * 100}% of clients sampled, at least {min_fit_clients}.\")\n",
        "\n",
        "    def client_fn(cid: str):\n",
        "        \"\"\"Creates a federated learning client\"\"\"\n",
        "        return EuroSATClient(cid, fed_data_dir, log_progress=False)\n",
        "\n",
        "    # Start the simulation\n",
        "    history = fl.simulation.start_simulation(\n",
        "        client_fn=client_fn,\n",
        "        num_clients=client_pool_size,\n",
        "        client_resources=client_resources,\n",
        "        config=ServerConfig(num_rounds=num_rounds),\n",
        "        strategy=strategy)\n",
        "\n",
        "    print(history)\n",
        "\n",
        "    return history\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start_experiment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQnE3FKgVj3F",
        "outputId": "446af32a-376f-48ea-bf7d-9c2530559df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset_utils import get_eurosat\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "training_path, test_set = get_eurosat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcO_aH8FDIh4",
        "outputId": "c298cff9-cabb-4df1-c582-341cf138da6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://madm.dfki.de/files/sentinel/EuroSAT.zip to ./eurosat_data/eurosat/EuroSAT.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 94280567/94280567 [00:01<00:00, 79882027.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./eurosat_data/eurosat/EuroSAT.zip to ./eurosat_data/eurosat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VAE Model\n",
        "\n",
        "Specified in network.py\n",
        "\n",
        "The model is a VAE adapted from __RaVAEn - Unsupervised Distaster Management via Change Detection On-board Satellites__"
      ],
      "metadata": {
        "id": "JscbS4OhO_of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_vae.py\n",
        "\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from typing import List, Any, Dict\n",
        "\n",
        "import flwr as fl\n",
        "\n",
        "class SimpleVAE(nn.Module):\n",
        "    \"\"\"Simple VAE adapted from 'RaVAEn - Unsupervised Distaster\n",
        "    Management via Change Detection On-board Satellites'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_shape=(3, 32, 32), latent_dim=128, visualisation_channels=[2,1,0]):\n",
        "        super(SimpleVAE, self).__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "        self.visualisation_channels = visualisation_channels # maybe specific to ravaen dataset TODO\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "        # Reconstructing things, so in and out channels should be the same (default is 10 channels for RaVAEn)\n",
        "        in_channels = input_shape[0]\n",
        "        out_channels = input_shape[0]\n",
        "\n",
        "        # Defines encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, 3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Conv2d(128, 256, 7),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "        self.width = (input_shape[1] // 2) // 2 - 6\n",
        "\n",
        "        # Encodes latent space, it's Linear. Latent dim = output features\n",
        "        self.fc_mu = nn.Linear(256 * self.width * self.width, latent_dim)\n",
        "        self.fc_var = nn.Linear(256 * self.width * self.width, latent_dim)\n",
        "\n",
        "        self.decoder_input = \\\n",
        "            nn.Linear(latent_dim, 256 * self.width * self.width)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, 7),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1,\n",
        "                               output_padding=1),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.ConvTranspose2d(64, out_channels, 3, stride=2, padding=1,\n",
        "                               output_padding=1),\n",
        "        )\n",
        "\n",
        "\n",
        "    def encode(self, input: Tensor) -> List[Tensor]:\n",
        "        \"\"\"\n",
        "        Encodes the input by passing through the encoder network\n",
        "        and returns the latent codes.\n",
        "        :param input: (Tensor) Input tensor to encoder [N x C x H x W]\n",
        "        :return: (Tensor) List of latent codes\n",
        "        \"\"\"\n",
        "        result = self.encoder(input)\n",
        "        result = torch.flatten(result, start_dim=1)\n",
        "\n",
        "        # Split the result into mu and var components\n",
        "        # of the latent Gaussian distribution\n",
        "        mu = self.fc_mu(result)\n",
        "        log_var = self.fc_var(result)\n",
        "\n",
        "        return [mu, log_var]\n",
        "\n",
        "    def decode(self, z: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Maps the given latent codes\n",
        "        onto the image space.\n",
        "        :param z: (Tensor) [B x D]\n",
        "        :return: (Tensor) [B x C x H x W]\n",
        "        \"\"\"\n",
        "        result = self.decoder_input(z)\n",
        "        result = result.view(-1, 256, self.width, self.width)\n",
        "        result = self.decoder(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "    def forward(self, input: Tensor, **kwargs) -> List[Tensor]:\n",
        "        mu, log_var = self.encode(torch.nan_to_num(input))\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        return [self.decode(z), mu, log_var]\n",
        "\n",
        "    def generate(self, x: Tensor, **kwargs) -> Tensor:\n",
        "        \"\"\"\n",
        "        Given an input image x, returns the reconstructed image\n",
        "        :param x: (Tensor) [B x C x H x W]\n",
        "        :return: (Tensor) [B x C x H x W]\n",
        "        \"\"\"\n",
        "        return self.forward(x)[0]\n",
        "\n",
        "    def reparameterize(self, mu: Tensor, logvar: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Reparameterization trick to sample from N(mu, var) from\n",
        "        N(0,1) - Normalises this\n",
        "        :param mu: Mean of the latent Gaussian [B x D]\n",
        "        :param logvar: Standard deviation of the latent Gaussian [B x D]\n",
        "        :return: [B x D]\n",
        "        \"\"\"\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps * std + mu\n",
        "\n",
        "    def get_weights(self) -> fl.common.NDArrays:\n",
        "        \"\"\"Get model weights as a list of NumPy ndarrays.\"\"\"\n",
        "        return [val.cpu().numpy() for _, val in self.state_dict().items()]\n",
        "\n",
        "    def set_weights(self, weights: fl.common.NDArrays) -> None:\n",
        "        \"\"\"Set model weight s from a list of NumPy ndarrays.\"\"\"\n",
        "        state_dict = OrderedDict(\n",
        "            {k: torch.Tensor(v) for k, v in zip(self.state_dict().keys(), weights)}\n",
        "        )\n",
        "        self.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def loss_function(self, input: Tensor, results: Any, **kwargs) -> Dict:\n",
        "        \"\"\"\n",
        "        Computes the VAE loss function.\n",
        "\n",
        "        :param args:\n",
        "        :param kwargs:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        # invalid_mask = torch.isnan(input)\n",
        "        input = torch.nan_to_num(input)\n",
        "\n",
        "        recons = results[0]\n",
        "        mu = results[1]\n",
        "        log_var = results[2]\n",
        "\n",
        "        # Account for the minibatch samples from the dataset\n",
        "        kld_weight = 0.1\n",
        "\n",
        "        recons_loss = F.mse_loss(recons, input)\n",
        "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim=1), dim=0)\n",
        "\n",
        "        # KLD weight is a hyperparameter, affects how much KLD loss govern training TODO experiment?\n",
        "        loss = recons_loss + kld_weight * kld_loss\n",
        "        return {'loss': loss, 'Reconstruction_Loss': recons_loss, 'KLD': -kld_loss}\n",
        "        #return {'loss': recons_loss, 'Reconstruction_Loss': recons_loss}\n",
        "\n",
        "def train(\n",
        "    net: SimpleVAE,\n",
        "    trainloader: DataLoader,\n",
        "    device: torch.device,\n",
        "    num_iterations: int,\n",
        "    log_progress: bool = True):\n",
        "    # Define loss and optimizer\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
        "\n",
        "    def cycle(iterable):\n",
        "        \"\"\"Repeats the contents of the train loader, in case it gets exhausted in 'num_iterations'.\"\"\"\n",
        "        while True:\n",
        "            for x in iterable:\n",
        "                yield x\n",
        "\n",
        "    # Train the network\n",
        "    net.train()\n",
        "    total_rec_loss, total_kld_loss, n_samples = 0.0, 0.0, 0\n",
        "    pbar = tqdm(iter(cycle(trainloader)), total=num_iterations, desc=f'TRAIN') if log_progress else iter(cycle(trainloader))\n",
        "\n",
        "    # Unusually, this training is formulated in terms of number of updates/iterations/batches processed\n",
        "    # by the network. This will be helpful later on, when partitioning the data across clients: resulting\n",
        "    # in differences between dataset sizes and hence inconsistent numbers of updates per 'epoch'.\n",
        "    for i, data in zip(range(num_iterations), pbar):\n",
        "        images = data[0].to(device)\n",
        "        #labels = data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # run the SimpleVAE forward() func to get reconstructed\n",
        "        # images, as well as the mu's and vars\n",
        "        recons_imgs = net(images)\n",
        "\n",
        "        # compute loss function as defined in SimpleVAE\n",
        "        loss = net.loss_function(images, recons_imgs)\n",
        "\n",
        "        # training step\n",
        "        loss['loss'].backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Collected training loss and accuracy statistics\n",
        "        total_rec_loss += loss['Reconstruction_Loss'].item()\n",
        "        total_kld_loss += loss['KLD'].item()\n",
        "        #_, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += images.size(0)\n",
        "        #total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        if log_progress:\n",
        "            pbar.set_postfix({\n",
        "                \"avg_train_rec_loss\": total_rec_loss/n_samples,\n",
        "                \"avg_train_kld_loss\": total_kld_loss/n_samples\n",
        "                #\"train_acc\": total_correct/n_samples\n",
        "            })\n",
        "\n",
        "    if log_progress:\n",
        "        print(\"\\n\")\n",
        "\n",
        "    return total_rec_loss/n_samples, total_kld_loss/n_samples, n_samples\n",
        "\n",
        "def test(\n",
        "    net: SimpleVAE,\n",
        "    testloader: DataLoader,\n",
        "    device: torch.device,\n",
        "    log_progress: bool = True):\n",
        "    \"\"\"Evaluates the network on test data.\"\"\"\n",
        "\n",
        "    total_rec_loss, total_kld_loss, n_samples = 0.0, 0.0, 0\n",
        "    net.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(testloader, desc=\"TEST\") if log_progress else testloader\n",
        "        for data in pbar:\n",
        "            images = data[0].to(device)\n",
        "            # labels = data[1].to(device)\n",
        "\n",
        "            # run the SimpleVAE forward() func to get reconstructed\n",
        "            # images, as well as the mu's and vars\n",
        "            recons_imgs = net(images)\n",
        "\n",
        "            # compute loss function as defined in SimpleVAE\n",
        "            loss = net.loss_function(images, recons_imgs)\n",
        "\n",
        "            # Collected training loss and accuracy statistics\n",
        "            total_rec_loss += loss['Reconstruction_Loss'].item()\n",
        "            total_kld_loss += loss['KLD'].item()\n",
        "            # Collected testing loss and accuracy statistics\n",
        "            #total_loss += loss.item()\n",
        "            #_, predicted = torch.max(outputs.data, 1)\n",
        "            n_samples += images.size(0)\n",
        "            #total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    if log_progress:\n",
        "        print(\"\\n\")\n",
        "\n",
        "    return total_rec_loss/n_samples, total_kld_loss/n_samples, n_samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxkLTwOhNtSP",
        "outputId": "31ee7d7c-e851-442d-b18a-055465496cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model_vae.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Model Instance"
      ],
      "metadata": {
        "id": "zyCcomBROAYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing on the CIFAR10 dataset"
      ],
      "metadata": {
        "id": "QgteFBeZOCxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from model_vae import SimpleVAE, train, test\n",
        "from dataset_utils import cifar10Transformation\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Using {DEVICE} device\")\n",
        "\n",
        "# Create network architecture and send it to preferred device\n",
        "net = SimpleVAE()\n",
        "net.to(DEVICE)\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "# Define a DataLoader for training and testing\n",
        "trainset = datasets.CIFAR10(\"./data\", train=True, download=True, transform=cifar10Transformation())\n",
        "testset = datasets.CIFAR10(\"./data\", train=False, transform=cifar10Transformation())\n",
        "\n",
        "trainloader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
        "testloader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Check the accuracy of the model *before training*\n",
        "test_rec_loss, test_kld_loss, num_test_samples = test(net, testloader, device=DEVICE, log_progress=True)\n",
        "print(f'Before training: test_rec_loss={test_rec_loss:.4f}, test_kld_loss={test_kld_loss:.4f}, num_samples_tested={num_test_samples}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eSxyEsNOFUq",
        "outputId": "897ae241-55eb-4ee4-b18e-32cb786ffcab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda:0 device\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 28442916.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TEST: 100%|██████████| 313/313 [00:06<00:00, 52.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Before training: test_rec_loss=0.0490, test_kld_loss=-0.0063, num_samples_tested=10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset_utils import get_cifar_10\n",
        "\n",
        "train_path, test_set = get_cifar_10()\n",
        "\n",
        "print(train_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocz9kq-pJqi1",
        "outputId": "b78c0873-e1ee-4a06-fae0-f886d7c20333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Generating unified CIFAR dataset\n",
            "data/cifar-10-batches-py/training.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model locally (no federated learning)\n",
        "for epoch in range(25):\n",
        "    # Equivalently, can be rewritten as a single train(...) call with num_iterations=10 * len(trainloader)\n",
        "    train_loss, train_acc, _ = train(net=net, trainloader=trainloader, device=DEVICE, num_iterations=len(trainloader))\n",
        "    print(f'Epoch {epoch + 1}: train_loss={train_loss:.4f}, train_accuracy={train_acc:.4f}')\n",
        "\n",
        "test_loss, test_acc, _ = test(net, testloader, device=DEVICE, log_progress=True)\n",
        "print(f'After training: test_loss={test_loss:.4f}, test_accuracy={test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "VWwUQInzQTnV",
        "outputId": "129cc147-10b8-4719-cecc-5be3f5d67348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN:  38%|███▊      | 284/750 [00:09<00:15, 29.49it/s, train_loss=0.0663, train_acc=0.212]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-e7f1c7ddd138>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Equivalently, can be rewritten as a single train(...) call with num_iterations=10 * len(trainloader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch + 1}: train_loss={train_loss:.4f}, train_accuracy={train_acc:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/simple_cnn6.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, device, num_iterations, log_progress)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# by the network. This will be helpful later on, when partitioning the data across clients: resulting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# in differences between dataset sizes and hence inconsistent numbers of updates per 'epoch'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/simple_cnn6.py\u001b[0m in \u001b[0;36mcycle\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;34m\"\"\"Repeats the contents of the train loader, in case it gets exhausted in 'num_iterations'.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[1;32m    228\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3174\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3175\u001b[0m     \"\"\"\n\u001b[1;32m   3176\u001b[0m     \u001b[0mOpens\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0midentifies\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "net_init = SimpleVAE()\n",
        "net_init.to(DEVICE)\n",
        "\n",
        "img_index = 4\n",
        "\n",
        "image_original = None\n",
        "image_reconstructed = None\n",
        "image_reconstructed_init = None\n",
        "\n",
        "count = 0\n",
        "for data in testloader:\n",
        "  if count == 0:\n",
        "    image_original = data[0].to(DEVICE)\n",
        "    label = data[1].to(DEVICE)\n",
        "    image_reconstructed = net(image_original)[0].to(DEVICE)\n",
        "    image_reconstructed_init = net_init(image_original)[0].to(DEVICE)\n",
        "    count = 1\n",
        "    break\n",
        "\n",
        "print(f\"Label: {label.cpu()[img_index]}\")\n",
        "\n",
        "image_original = image_original.permute(0, 2, 3, 1)\n",
        "image_reconstructed = image_reconstructed.permute(0, 2, 3, 1)\n",
        "image_reconstructed_init = image_reconstructed_init.permute(0, 2, 3, 1)\n",
        "\n",
        "image_original = image_original.cpu().numpy()[img_index]\n",
        "image_reconstructed = image_reconstructed.cpu().detach().numpy()[img_index]\n",
        "image_reconstructed_init = image_reconstructed_init.cpu().detach().numpy()[img_index]\n",
        "\n",
        "#print(image_original.shape)\n",
        "#print(image_original)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "axarr = fig.subplots(1,3)\n",
        "\n",
        "im1 = axarr[0].imshow(image_original)\n",
        "im2 = axarr[1].imshow(image_reconstructed)\n",
        "im3 = axarr[2].imshow(image_reconstructed_init)"
      ],
      "metadata": {
        "id": "zIes7NTIP41t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting the Airbus Dataset"
      ],
      "metadata": {
        "id": "ZULdbkZKXMkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://docs.google.com/uc?id=1C5R9oRKSQP0SNZ7J4KCIsYvDztl-IXzB\n",
        "!unzip -q airbus_dataset.zip -d airbus_data\n",
        "!rm airbus_dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJUNRv3gZaZj",
        "outputId": "1262484b-d3b4-4fbd-9c46-e989d40b26a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://docs.google.com/uc?id=1C5R9oRKSQP0SNZ7J4KCIsYvDztl-IXzB\n",
            "To: /content/airbus_dataset.zip\n",
            "100% 1.08G/1.08G [00:07<00:00, 150MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build training+test sets: label everything in targets as class 1 and the rest as class 0\n",
        "\n",
        "# TODO\n"
      ],
      "metadata": {
        "id": "u3kaFcjJbDaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EuroSAT Dataset"
      ],
      "metadata": {
        "id": "tSF8uNJbOdTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "import ssl\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "eurosat_dataset_og = datasets.EuroSAT(\"./eurosat_data\", download=True, transform=transforms.ToTensor())\n",
        "eurosat_loader_og = DataLoader(dataset=eurosat_dataset_og, batch_size=32, shuffle=False)\n",
        "\n",
        "# visualise 8 images from the first batch in eurosatloader\n",
        "for batch_idx, inputs in enumerate(eurosat_loader_og):\n",
        "    fig = plt.figure(figsize=(14, 7))\n",
        "    fig.suptitle('Images from EuroSAT Dataset (batch 0)')\n",
        "    for i in range(8):\n",
        "        ax = fig.add_subplot(2, 4, i + 1, xticks=[], yticks=[])\n",
        "        plt.imshow(inputs[0][i].numpy().transpose(1, 2, 0))\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "R1KZ4LN1bv6o",
        "outputId": "2751a99d-f464-4686-9979-d944891c49df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://madm.dfki.de/files/sentinel/EuroSAT.zip to ./eurosat_data/eurosat/EuroSAT.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 94280567/94280567 [00:04<00:00, 20769696.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./eurosat_data/eurosat/EuroSAT.zip to ./eurosat_data/eurosat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x700 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "image_size = 64\n",
        "\n",
        "# compute dataset normalisation statistics\n",
        "psum = torch.tensor([0.0, 0.0, 0.0])\n",
        "psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
        "\n",
        "# loop through images\n",
        "for inputs in tqdm(eurosat_loader_og):\n",
        "    input_images = inputs[0]\n",
        "    psum += input_images.sum(axis=[0, 2, 3])\n",
        "    psum_sq += (input_images**2).sum(axis=[0, 2, 3])\n",
        "\n",
        "# total pixel count (NxWxH)\n",
        "count = len(eurosat_dataset_og) * image_size * image_size\n",
        "\n",
        "# mean and std\n",
        "total_mean = psum / count\n",
        "total_var = (psum_sq / count) - (total_mean**2)\n",
        "total_std = torch.sqrt(total_var)\n",
        "\n",
        "# output\n",
        "print(\"\\nEuroSAT Normalisation Statistics\")\n",
        "print(\"mean: \" + str(total_mean))\n",
        "print(\"std:  \" + str(total_std))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iemRxm4ln5e",
        "outputId": "042a489e-9db3-403c-d045-e89e02ba3630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 844/844 [00:12<00:00, 65.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EuroSAT Normalisation Statistics\n",
            "mean: tensor([0.3444, 0.3803, 0.4078])\n",
            "std:  tensor([0.2027, 0.1369, 0.1156])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "from simple_cnn import Net, train, test\n",
        "from dataset_utils import eurosatTransformation\n",
        "\n",
        "import ssl\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Using {DEVICE} device\")\n",
        "\n",
        "# Create network architecture and send it to preferred device\n",
        "simple_net = Net()\n",
        "simple_net.to(DEVICE)\n",
        "\n",
        "# Define a DataLoader for training and testing\n",
        "\n",
        "# load the EuroSAT dataset\n",
        "eurosat_dataset = datasets.EuroSAT(\"./eurosat_data\", download=True, transform=eurosatTransformation())\n",
        "eurosat_loader = DataLoader(dataset=eurosat_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(\"\\nPreprocessing EuroSAT dataset...\\n\")\n",
        "\n",
        "print(eurosat_dataset)\n",
        "\n",
        "trainset, testset = random_split(eurosat_dataset, [24000, 3000], torch.Generator().manual_seed(42))\n",
        "\n",
        "print(f\"\\nLength of training set: {len(trainset)}\")\n",
        "print(f\"Length of test set: {len(testset)}\")\n",
        "\n",
        "trainloader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
        "testloader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(\"\\nTraining and test dataloaders created.\")\n",
        "\n",
        "# Check the accuracy of the model *before training*\n",
        "test_loss, test_acc, num_test_samples = test(simple_net, testloader, device=DEVICE, log_progress=True)\n",
        "print(f'\\nBefore training: test_loss={test_loss:.4f}, test_accuracy={test_acc:.4f}, num_samples_tested={num_test_samples}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVwVE4zgWQcE",
        "outputId": "871abd92-2b73-46fc-b00e-e60fe5f71c56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda:0 device\n",
            "Downloading https://madm.dfki.de/files/sentinel/EuroSAT.zip to ./eurosat_data/eurosat/EuroSAT.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 94280567/94280567 [00:00<00:00, 115696222.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./eurosat_data/eurosat/EuroSAT.zip to ./eurosat_data/eurosat\n",
            "\n",
            "Preprocessing EuroSAT dataset...\n",
            "\n",
            "Dataset EuroSAT\n",
            "    Number of datapoints: 27000\n",
            "    Root location: ./eurosat_data\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.3444, 0.3803, 0.4078), std=(0.2027, 0.1369, 0.1156))\n",
            "           )\n",
            "\n",
            "Length of training set: 24000\n",
            "Length of test set: 3000\n",
            "\n",
            "Training and test dataloaders created.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TEST: 100%|██████████| 94/94 [00:02<00:00, 32.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Before training: test_loss=0.0721, test_accuracy=0.1073, num_samples_tested=3000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normal Training (non-federated)"
      ],
      "metadata": {
        "id": "ucPARxFf0KQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training with simple CNN model"
      ],
      "metadata": {
        "id": "tKe6t64g0KVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model locally (no federated learning) for 25 epochs\n",
        "for epoch in range(25):\n",
        "    # Equivalently, can be rewritten as a single train(...) call with num_iterations=10 * len(trainloader)\n",
        "    train_loss, train_acc, _ = train(net=simple_net,\n",
        "                                     trainloader=trainloader,\n",
        "                                     device=DEVICE,\n",
        "                                     num_iterations=len(trainloader),\n",
        "                                     optim='Adam')\n",
        "    print(f'Epoch {epoch + 1}: train_loss={train_loss:.4f}, train_accuracy={train_acc:.4f}')\n",
        "\n",
        "test_loss, test_acc, _ = test(simple_net, testloader, device=DEVICE, log_progress=True)\n",
        "print(f'After training: test_loss={test_loss:.4f}, test_accuracy={test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aQ1TZEzApIn1",
        "outputId": "55713fd7-f555-425f-b2fa-8743126186c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:21<00:00, 35.35it/s, train_loss=0.024, train_acc=0.721]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 1: train_loss=0.0240, train_accuracy=0.7215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:19<00:00, 39.21it/s, train_loss=0.02, train_acc=0.768]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 2: train_loss=0.0200, train_accuracy=0.7684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:19<00:00, 39.40it/s, train_loss=0.0167, train_acc=0.806]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 3: train_loss=0.0167, train_accuracy=0.8063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:20<00:00, 37.17it/s, train_loss=0.0143, train_acc=0.835]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 4: train_loss=0.0143, train_accuracy=0.8349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:19<00:00, 37.91it/s, train_loss=0.0119, train_acc=0.864]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 5: train_loss=0.0119, train_accuracy=0.8638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:20<00:00, 36.89it/s, train_loss=0.0101, train_acc=0.884]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 6: train_loss=0.0101, train_accuracy=0.8838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:19<00:00, 37.95it/s, train_loss=0.00888, train_acc=0.899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 7: train_loss=0.0089, train_accuracy=0.8986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:20<00:00, 36.92it/s, train_loss=0.00743, train_acc=0.917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 8: train_loss=0.0074, train_accuracy=0.9169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:20<00:00, 37.11it/s, train_loss=0.00626, train_acc=0.929]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 9: train_loss=0.0063, train_accuracy=0.9295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:22<00:00, 33.26it/s, train_loss=0.00529, train_acc=0.942]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 10: train_loss=0.0053, train_accuracy=0.9421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:19<00:00, 37.81it/s, train_loss=0.00501, train_acc=0.946]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 11: train_loss=0.0050, train_accuracy=0.9464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:20<00:00, 36.30it/s, train_loss=0.00428, train_acc=0.954]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 12: train_loss=0.0043, train_accuracy=0.9537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:20<00:00, 37.24it/s, train_loss=0.00381, train_acc=0.959]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 13: train_loss=0.0038, train_accuracy=0.9593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:20<00:00, 36.24it/s, train_loss=0.00334, train_acc=0.965]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 14: train_loss=0.0033, train_accuracy=0.9646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:19<00:00, 37.47it/s, train_loss=0.00341, train_acc=0.966]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 15: train_loss=0.0034, train_accuracy=0.9655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:20<00:00, 36.10it/s, train_loss=0.00276, train_acc=0.97]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 16: train_loss=0.0028, train_accuracy=0.9705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:19<00:00, 37.63it/s, train_loss=0.00303, train_acc=0.968]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 17: train_loss=0.0030, train_accuracy=0.9685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:20<00:00, 36.92it/s, train_loss=0.0028, train_acc=0.971]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 18: train_loss=0.0028, train_accuracy=0.9713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:21<00:00, 34.37it/s, train_loss=0.00273, train_acc=0.973]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 19: train_loss=0.0027, train_accuracy=0.9729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:20<00:00, 36.64it/s, train_loss=0.0026, train_acc=0.975]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 20: train_loss=0.0026, train_accuracy=0.9753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:19<00:00, 38.83it/s, train_loss=0.00262, train_acc=0.973]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 21: train_loss=0.0026, train_accuracy=0.9730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:20<00:00, 36.81it/s, train_loss=0.00259, train_acc=0.975]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 22: train_loss=0.0026, train_accuracy=0.9753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:19<00:00, 37.92it/s, train_loss=0.00226, train_acc=0.977]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 23: train_loss=0.0023, train_accuracy=0.9770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:21<00:00, 35.33it/s, train_loss=0.00248, train_acc=0.975]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 24: train_loss=0.0025, train_accuracy=0.9753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:20<00:00, 36.47it/s, train_loss=0.00238, train_acc=0.978]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 25: train_loss=0.0024, train_accuracy=0.9782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TEST: 100%|██████████| 94/94 [00:01<00:00, 48.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "After training: test_loss=0.0357, test_accuracy=0.8203\n",
            "\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Parent directory ./models does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2ceba161ac9b>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSaving model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./models/simple_net'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disable_byteorder_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Parent directory ./models does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSaving model...\")\n",
        "torch.save(simple_net, 'simple_net')\n",
        "print(\"Done.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jF4fbHQ-34_",
        "outputId": "a9e6ac7a-bec0-401e-982c-9ab05cb32a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving model...\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_net = torch.load('simple_net')\n",
        "\n",
        "test_loss, test_acc, _ = test(loaded_net, testloader, device=DEVICE, log_progress=True)\n",
        "print(f'After training: test_loss={test_loss:.4f}, test_accuracy={test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXLCSvpqACyT",
        "outputId": "61729fc9-2c03-4807-b4e7-00019a6f4e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TEST: 100%|██████████| 94/94 [00:02<00:00, 33.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "After training: test_loss=0.0357, test_accuracy=0.8203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training with ResNet-50"
      ],
      "metadata": {
        "id": "mYyKyAPR0Nzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD Optimizer"
      ],
      "metadata": {
        "id": "vyGhPoyM8fMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet50\n",
        "\n",
        "resnet = resnet50().to(DEVICE)\n",
        "\n",
        "for epoch in range(25):\n",
        "    # Equivalently, can be rewritten as a single train(...) call with num_iterations=10 * len(trainloader)\n",
        "    train_loss, train_acc, _ = train(net=resnet, trainloader=trainloader, device=DEVICE, num_iterations=len(trainloader))\n",
        "    print(f'Epoch {epoch + 1}: train_loss={train_loss:.4f}, train_accuracy={train_acc:.4f}')\n",
        "\n",
        "test_loss, test_acc, _ = test(resnet, testloader, device=DEVICE, log_progress=True)\n",
        "print(f'After training: test_loss={test_loss:.4f}, test_accuracy={test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqkqCGz7wL9T",
        "outputId": "a43093c4-2430-4ac7-d757-b1a1916ba2ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:43<00:00, 17.19it/s, train_loss=0.0499, train_acc=0.453]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 1: train_loss=0.0499, train_accuracy=0.4532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:41<00:00, 18.07it/s, train_loss=0.0321, train_acc=0.645]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 2: train_loss=0.0321, train_accuracy=0.6451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.71it/s, train_loss=0.0266, train_acc=0.701]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 3: train_loss=0.0266, train_accuracy=0.7010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:40<00:00, 18.35it/s, train_loss=0.024, train_acc=0.734]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 4: train_loss=0.0240, train_accuracy=0.7341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:41<00:00, 17.87it/s, train_loss=0.0214, train_acc=0.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 5: train_loss=0.0214, train_accuracy=0.7598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.75it/s, train_loss=0.0197, train_acc=0.779]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 6: train_loss=0.0197, train_accuracy=0.7792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:41<00:00, 17.97it/s, train_loss=0.0179, train_acc=0.803]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 7: train_loss=0.0179, train_accuracy=0.8033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:41<00:00, 18.03it/s, train_loss=0.0167, train_acc=0.814]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 8: train_loss=0.0167, train_accuracy=0.8142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:40<00:00, 18.37it/s, train_loss=0.0151, train_acc=0.832]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 9: train_loss=0.0151, train_accuracy=0.8315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:40<00:00, 18.54it/s, train_loss=0.0139, train_acc=0.846]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 10: train_loss=0.0139, train_accuracy=0.8458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:40<00:00, 18.56it/s, train_loss=0.013, train_acc=0.856]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 11: train_loss=0.0130, train_accuracy=0.8561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:40<00:00, 18.33it/s, train_loss=0.012, train_acc=0.868]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 12: train_loss=0.0120, train_accuracy=0.8676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:41<00:00, 18.02it/s, train_loss=0.0109, train_acc=0.88]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 13: train_loss=0.0109, train_accuracy=0.8805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.75it/s, train_loss=0.00999, train_acc=0.89]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 14: train_loss=0.0100, train_accuracy=0.8899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.83it/s, train_loss=0.00972, train_acc=0.892]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 15: train_loss=0.0097, train_accuracy=0.8921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.70it/s, train_loss=0.0085, train_acc=0.907]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 16: train_loss=0.0085, train_accuracy=0.9075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:41<00:00, 17.90it/s, train_loss=0.00757, train_acc=0.917]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 17: train_loss=0.0076, train_accuracy=0.9167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:41<00:00, 17.98it/s, train_loss=0.00712, train_acc=0.92]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 18: train_loss=0.0071, train_accuracy=0.9204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:41<00:00, 17.95it/s, train_loss=0.0067, train_acc=0.926]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 19: train_loss=0.0067, train_accuracy=0.9262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:41<00:00, 17.99it/s, train_loss=0.00608, train_acc=0.933]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 20: train_loss=0.0061, train_accuracy=0.9330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.65it/s, train_loss=0.00535, train_acc=0.939]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 21: train_loss=0.0053, train_accuracy=0.9388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.61it/s, train_loss=0.00506, train_acc=0.943]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 22: train_loss=0.0051, train_accuracy=0.9435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.49it/s, train_loss=0.00491, train_acc=0.946]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 23: train_loss=0.0049, train_accuracy=0.9461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.67it/s, train_loss=0.00448, train_acc=0.952]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 24: train_loss=0.0045, train_accuracy=0.9523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.79it/s, train_loss=0.00417, train_acc=0.955]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 25: train_loss=0.0042, train_accuracy=0.9550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TEST: 100%|██████████| 94/94 [00:02<00:00, 32.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "After training: test_loss=0.0196, test_accuracy=0.8320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam Optimizer"
      ],
      "metadata": {
        "id": "fHok3giD8dZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet50\n",
        "\n",
        "resnet = resnet50().to(DEVICE)\n",
        "\n",
        "for epoch in range(25):\n",
        "    # Equivalently, can be rewritten as a single train(...) call with num_iterations=10 * len(trainloader)\n",
        "    train_loss, train_acc, _ = train(net=resnet,\n",
        "                                     trainloader=trainloader,\n",
        "                                     device=DEVICE,\n",
        "                                     num_iterations=len(trainloader),\n",
        "                                     optim='Adam')\n",
        "    print(f'Epoch {epoch + 1}: train_loss={train_loss:.4f}, train_accuracy={train_acc:.4f}')\n",
        "\n",
        "test_loss, test_acc, _ = test(resnet, testloader, device=DEVICE, log_progress=True)\n",
        "print(f'After training: test_loss={test_loss:.4f}, test_accuracy={test_acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-ocUHHs0mr9",
        "outputId": "71fa39fc-dad3-4828-d988-4818529d7d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.61it/s, train_loss=0.0418, train_acc=0.562]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 1: train_loss=0.0418, train_accuracy=0.5618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.72it/s, train_loss=0.0308, train_acc=0.659]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 2: train_loss=0.0308, train_accuracy=0.6592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.53it/s, train_loss=0.0238, train_acc=0.735]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 3: train_loss=0.0238, train_accuracy=0.7350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.46it/s, train_loss=0.0198, train_acc=0.783]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 4: train_loss=0.0198, train_accuracy=0.7833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.70it/s, train_loss=0.0178, train_acc=0.805]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 5: train_loss=0.0178, train_accuracy=0.8055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.78it/s, train_loss=0.0146, train_acc=0.839]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 6: train_loss=0.0146, train_accuracy=0.8392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:41<00:00, 18.07it/s, train_loss=0.0139, train_acc=0.85]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 7: train_loss=0.0139, train_accuracy=0.8502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.64it/s, train_loss=0.0113, train_acc=0.876]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 8: train_loss=0.0113, train_accuracy=0.8760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:43<00:00, 17.29it/s, train_loss=0.00972, train_acc=0.892]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 9: train_loss=0.0097, train_accuracy=0.8924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:43<00:00, 17.38it/s, train_loss=0.00863, train_acc=0.903]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 10: train_loss=0.0086, train_accuracy=0.9030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.49it/s, train_loss=0.00766, train_acc=0.915]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 11: train_loss=0.0077, train_accuracy=0.9151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:43<00:00, 17.27it/s, train_loss=0.00683, train_acc=0.925]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 12: train_loss=0.0068, train_accuracy=0.9251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:43<00:00, 17.16it/s, train_loss=0.00616, train_acc=0.931]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 13: train_loss=0.0062, train_accuracy=0.9315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.44it/s, train_loss=0.0056, train_acc=0.939]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 14: train_loss=0.0056, train_accuracy=0.9385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.61it/s, train_loss=0.00533, train_acc=0.941]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 15: train_loss=0.0053, train_accuracy=0.9406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.71it/s, train_loss=0.00464, train_acc=0.948]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 16: train_loss=0.0046, train_accuracy=0.9481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.61it/s, train_loss=0.00533, train_acc=0.942]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 17: train_loss=0.0053, train_accuracy=0.9419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.81it/s, train_loss=0.00418, train_acc=0.954]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 18: train_loss=0.0042, train_accuracy=0.9536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.78it/s, train_loss=0.00389, train_acc=0.958]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 19: train_loss=0.0039, train_accuracy=0.9584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:41<00:00, 18.03it/s, train_loss=0.00373, train_acc=0.958]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 20: train_loss=0.0037, train_accuracy=0.9583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:41<00:00, 17.94it/s, train_loss=0.00329, train_acc=0.965]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 21: train_loss=0.0033, train_accuracy=0.9655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:41<00:00, 17.87it/s, train_loss=0.00306, train_acc=0.967]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 22: train_loss=0.0031, train_accuracy=0.9670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:41<00:00, 17.88it/s, train_loss=0.00281, train_acc=0.969]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 23: train_loss=0.0028, train_accuracy=0.9691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:42<00:00, 17.73it/s, train_loss=0.00246, train_acc=0.973]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 24: train_loss=0.0025, train_accuracy=0.9730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|█████████▉| 749/750 [00:41<00:00, 17.89it/s, train_loss=0.00241, train_acc=0.974]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch 25: train_loss=0.0024, train_accuracy=0.9744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TEST: 100%|██████████| 94/94 [00:02<00:00, 35.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "After training: test_loss=0.0080, test_accuracy=0.9250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dtini5Ar9G1U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49a0d898-5927-4b45-890f-24b5783ba15c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing client.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NWM_ZnWNAcC",
        "outputId": "3e395bf6-92b1-4c11-f187-9fa6139b7753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset_utils import get_eurosat\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "training_path, test_set = get_eurosat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic_X7sCYNLKM",
        "outputId": "1205feb5-37d5-4bd5-b8af-a124f5f6f68f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://madm.dfki.de/files/sentinel/EuroSAT.zip to ./eurosat_data/eurosat/EuroSAT.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 94280567/94280567 [00:08<00:00, 11542491.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./eurosat_data/eurosat/EuroSAT.zip to ./eurosat_data/eurosat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_path)\n",
        "print(len(test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig6QbBu2msJJ",
        "outputId": "36069174-b82d-4cbd-e5e7-1a8bb89a2b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eurosat_data/eurosat/training.pt\n",
            "3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiments\n",
        "\n",
        "In federated learning, the server orchestrates the experiment by instructing chosen clients to start training and then aggregating the results. We can control the behavior of the server (and the clients) through a set of parameters. Go through the following list, taking care to understand each parameter (refer back to the code if necessary).\n",
        "\n",
        "--num-rounds: the number of rounds in the FL experiment\n",
        "\n",
        "--client-pool-size: the number of clients made available to an FL round\n",
        "\n",
        "--num-iterations: the number of iterations/updates a client performs per round (single local epoch if None). We will vary the client pool size in further experiments, which makes the number of local epochs an ambiguous target for training (more clients -> less data per client -> shorter local epochs), so we use the number of training iterations/updates, instead. However, if you're used to thinking of training in terms of number of epochs, you can compute how many examples would consistute N local epochs for a particular configuration:\n",
        "\n",
        "CIFAR-10 consists of 50000 training examples (distributed to clients) and 10000 test examples (kept on the server);\n",
        "with 10 clients, each client receives 50000/10 = 5000 examples as its local dataset;\n",
        "val-ratio fraction of the data (e.g. 0.1) is reserved for a local test set, giving a 4500/500 split;\n",
        "at batch size of 32, we need ceil(4500 / 32) = 141 updates to go through the entire training set;\n",
        "thus, N local epochs would correspond 141 * N iterations/updates, with the parameters assumed above.\n",
        "--fraction-fit: a fraction of clients that should be sampled for each round (0.0, 1.0].\n",
        "\n",
        "--min-fit-clients: the minimum number of clients to participate in a fitting round (will override if the number produced via --fraction_fit is smaller than --min-fit-clients).\n",
        "\n",
        "--batch-size: batch size for a client fitting round\n",
        "\n",
        "--val-ratio : a proportion of local data to reserve as a local test set\n",
        "\n",
        "--iid-alpha: (LDA prior concentration parameter for data partitioning). In practice, use a large --iid-alpha to make data IID across clients (all classes equally represented across all clients); a small value (e.g. 1) will make it non-IID (clients will hold data mostly belonging to one class). The script prints a class histogram for the first (0th) client as an example."
      ],
      "metadata": {
        "id": "k1d46c1s5w6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment 0 - Test FL Pipeline"
      ],
      "metadata": {
        "id": "v7z7WjjeVKtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --client-pool-size 2 --num-iterations 1000 --num-rounds 10 --val-ratio 0.0"
      ],
      "metadata": {
        "id": "egDVQqRpNZsU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a32132c-6cdb-4a47-887b-1627eabe55e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=1000.0, 10 classes): [1322 1403 1325 1320 1289 1393 1335 1417 1441 1255]\n",
            "Data partitioned across 2 clients, with IID alpha = 1000.0 and 0.0 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 2 client in the pool.\n",
            "FL round will proceed with 100.0% of clients sampled, at least 2.\n",
            "INFO flower 2024-01-11 09:51:19,146 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-11 09:51:23,248 | app.py:176 | Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'accelerator_type:V100': 1.0, 'object_store_memory': 3493215436.0, 'memory': 6986430875.0, 'CPU': 2.0, 'GPU': 1.0}\n",
            "INFO flower 2024-01-11 09:51:23,248 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-11 09:51:23,252 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-11 09:51:26,265 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-11 09:51:26,265 | server.py:88 | Evaluating initial parameters\n",
            "Evaluation on the server: test_loss=0.0723, test_accuracy=0.0700\n",
            "INFO flower 2024-01-11 09:51:29,868 | server.py:91 | initial parameters (loss, other metrics): 0.0723067488670349, {'accuracy': 0.07}\n",
            "INFO flower 2024-01-11 09:51:29,868 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-11 09:51:29,868 | server.py:215 | fit_round 1: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 1: training round complete, 31992 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 0: training round complete, 31992 examples processed\n",
            "DEBUG flower 2024-01-11 09:53:08,492 | server.py:229 | fit_round 1 received 2 results and 0 failures\n",
            "WARNING flower 2024-01-11 09:53:08,510 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "Evaluation on the server: test_loss=0.0346, test_accuracy=0.6260\n",
            "INFO flower 2024-01-11 09:53:10,958 | server.py:116 | fit progress: (1, 0.034594989041487376, {'accuracy': 0.626}, 101.08995986299988)\n",
            "INFO flower 2024-01-11 09:53:10,958 | server.py:163 | evaluate_round 1: no clients selected, cancel\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-11 09:53:10,958 | server.py:215 | fit_round 2: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 0: training round complete, 31992 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 1: training round complete, 31992 examples processed\n",
            "DEBUG flower 2024-01-11 09:54:42,012 | server.py:229 | fit_round 2 received 2 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0164, test_accuracy=0.8160\n",
            "INFO flower 2024-01-11 09:54:44,260 | server.py:116 | fit progress: (2, 0.016428479924798012, {'accuracy': 0.816}, 194.391957263)\n",
            "INFO flower 2024-01-11 09:54:44,260 | server.py:163 | evaluate_round 2: no clients selected, cancel\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-11 09:54:44,260 | server.py:215 | fit_round 3: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 1: training round complete, 31992 examples processed\n",
            "DEBUG flower 2024-01-11 09:56:15,055 | server.py:229 | fit_round 3 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 0: training round complete, 31992 examples processed\n",
            "Evaluation on the server: test_loss=0.0136, test_accuracy=0.8423\n",
            "INFO flower 2024-01-11 09:56:16,887 | server.py:116 | fit progress: (3, 0.013567370881636938, {'accuracy': 0.8423333333333334}, 287.0191542719999)\n",
            "INFO flower 2024-01-11 09:56:16,887 | server.py:163 | evaluate_round 3: no clients selected, cancel\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-11 09:56:16,887 | server.py:215 | fit_round 4: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 1: training round complete, 31992 examples processed\n",
            "DEBUG flower 2024-01-11 09:57:52,273 | server.py:229 | fit_round 4 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 0: training round complete, 31992 examples processed\n",
            "Evaluation on the server: test_loss=0.0106, test_accuracy=0.8823\n",
            "INFO flower 2024-01-11 09:57:54,131 | server.py:116 | fit progress: (4, 0.010551592032114665, {'accuracy': 0.8823333333333333}, 384.26297904800003)\n",
            "INFO flower 2024-01-11 09:57:54,131 | server.py:163 | evaluate_round 4: no clients selected, cancel\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-11 09:57:54,131 | server.py:215 | fit_round 5: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 1: training round complete, 31992 examples processed\n",
            "DEBUG flower 2024-01-11 09:59:27,376 | server.py:229 | fit_round 5 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 0: training round complete, 31992 examples processed\n",
            "Evaluation on the server: test_loss=0.0097, test_accuracy=0.8887\n",
            "INFO flower 2024-01-11 09:59:29,237 | server.py:116 | fit progress: (5, 0.009697937866051992, {'accuracy': 0.8886666666666667}, 479.3686754969999)\n",
            "INFO flower 2024-01-11 09:59:29,237 | server.py:163 | evaluate_round 5: no clients selected, cancel\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-11 09:59:29,237 | server.py:215 | fit_round 6: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 0: training round complete, 31992 examples processed\n",
            "DEBUG flower 2024-01-11 10:01:04,213 | server.py:229 | fit_round 6 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 1: training round complete, 31992 examples processed\n",
            "Evaluation on the server: test_loss=0.0074, test_accuracy=0.9130\n",
            "INFO flower 2024-01-11 10:01:06,047 | server.py:116 | fit progress: (6, 0.007409338408460219, {'accuracy': 0.913}, 576.1791868139999)\n",
            "INFO flower 2024-01-11 10:01:06,047 | server.py:163 | evaluate_round 6: no clients selected, cancel\n",
            "Configuring round 7\n",
            "DEBUG flower 2024-01-11 10:01:06,047 | server.py:215 | fit_round 7: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 0: training round complete, 31992 examples processed\n",
            "DEBUG flower 2024-01-11 10:02:39,791 | server.py:229 | fit_round 7 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 1: training round complete, 31992 examples processed\n",
            "Evaluation on the server: test_loss=0.0043, test_accuracy=0.9510\n",
            "INFO flower 2024-01-11 10:02:41,611 | server.py:116 | fit progress: (7, 0.004327420454472304, {'accuracy': 0.951}, 671.7429439349999)\n",
            "INFO flower 2024-01-11 10:02:41,611 | server.py:163 | evaluate_round 7: no clients selected, cancel\n",
            "Configuring round 8\n",
            "DEBUG flower 2024-01-11 10:02:41,611 | server.py:215 | fit_round 8: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 0: training round complete, 31992 examples processed\n",
            "DEBUG flower 2024-01-11 10:04:11,723 | server.py:229 | fit_round 8 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 1: training round complete, 31992 examples processed\n",
            "Evaluation on the server: test_loss=0.0037, test_accuracy=0.9603\n",
            "INFO flower 2024-01-11 10:04:14,261 | server.py:116 | fit progress: (8, 0.003748844251657526, {'accuracy': 0.9603333333333334}, 764.392861804)\n",
            "INFO flower 2024-01-11 10:04:14,261 | server.py:163 | evaluate_round 8: no clients selected, cancel\n",
            "Configuring round 9\n",
            "DEBUG flower 2024-01-11 10:04:14,261 | server.py:215 | fit_round 9: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 0: training round complete, 31992 examples processed\n",
            "DEBUG flower 2024-01-11 10:05:43,755 | server.py:229 | fit_round 9 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 1: training round complete, 31992 examples processed\n",
            "Evaluation on the server: test_loss=0.0028, test_accuracy=0.9683\n",
            "INFO flower 2024-01-11 10:05:45,731 | server.py:116 | fit progress: (9, 0.0028285741992294788, {'accuracy': 0.9683333333333334}, 855.863441513)\n",
            "INFO flower 2024-01-11 10:05:45,732 | server.py:163 | evaluate_round 9: no clients selected, cancel\n",
            "Configuring round 10\n",
            "DEBUG flower 2024-01-11 10:05:45,732 | server.py:215 | fit_round 10: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4954)\u001b[0m Client 1: training round complete, 31992 examples processed\n",
            "DEBUG flower 2024-01-11 10:07:19,711 | server.py:229 | fit_round 10 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4953)\u001b[0m Client 0: training round complete, 31992 examples processed\n",
            "Evaluation on the server: test_loss=0.0028, test_accuracy=0.9703\n",
            "INFO flower 2024-01-11 10:07:21,535 | server.py:116 | fit progress: (10, 0.002757666856671373, {'accuracy': 0.9703333333333334}, 951.6675318909997)\n",
            "INFO flower 2024-01-11 10:07:21,536 | server.py:163 | evaluate_round 10: no clients selected, cancel\n",
            "INFO flower 2024-01-11 10:07:21,536 | server.py:144 | FL finished in 951.667787242\n",
            "INFO flower 2024-01-11 10:07:21,536 | app.py:180 | app_fit: losses_distributed []\n",
            "INFO flower 2024-01-11 10:07:21,537 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2024-01-11 10:07:21,537 | app.py:182 | app_fit: losses_centralized [(0, 0.0723067488670349), (1, 0.034594989041487376), (2, 0.016428479924798012), (3, 0.013567370881636938), (4, 0.010551592032114665), (5, 0.009697937866051992), (6, 0.007409338408460219), (7, 0.004327420454472304), (8, 0.003748844251657526), (9, 0.0028285741992294788), (10, 0.002757666856671373)]\n",
            "INFO flower 2024-01-11 10:07:21,537 | app.py:183 | app_fit: metrics_centralized {'accuracy': [(0, 0.07), (1, 0.626), (2, 0.816), (3, 0.8423333333333334), (4, 0.8823333333333333), (5, 0.8886666666666667), (6, 0.913), (7, 0.951), (8, 0.9603333333333334), (9, 0.9683333333333334), (10, 0.9703333333333334)]}\n",
            "History (loss, centralized):\n",
            "\tround 0: 0.0723067488670349\n",
            "\tround 1: 0.034594989041487376\n",
            "\tround 2: 0.016428479924798012\n",
            "\tround 3: 0.013567370881636938\n",
            "\tround 4: 0.010551592032114665\n",
            "\tround 5: 0.009697937866051992\n",
            "\tround 6: 0.007409338408460219\n",
            "\tround 7: 0.004327420454472304\n",
            "\tround 8: 0.003748844251657526\n",
            "\tround 9: 0.0028285741992294788\n",
            "\tround 10: 0.002757666856671373\n",
            "History (metrics, centralized):\n",
            "{'accuracy': [(0, 0.07), (1, 0.626), (2, 0.816), (3, 0.8423333333333334), (4, 0.8823333333333333), (5, 0.8886666666666667), (6, 0.913), (7, 0.951), (8, 0.9603333333333334), (9, 0.9683333333333334), (10, 0.9703333333333334)]}\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_vals = [0.0723067488670349,\n",
        "             0.034594989041487376,\n",
        "             0.016428479924798012,\n",
        "             0.013567370881636938,\n",
        "             0.010551592032114665,\n",
        "             0.009697937866051992,\n",
        "             0.007409338408460219,\n",
        "             0.004327420454472304,\n",
        "             0.003748844251657526,\n",
        "             0.0028285741992294788,\n",
        "             0.002757666856671373]\n",
        "\n",
        "acc_vals = [0.07,\n",
        "            0.626,\n",
        "            0.816,\n",
        "            0.8423333333333334,\n",
        "            0.8823333333333333,\n",
        "            0.8886666666666667,\n",
        "            0.913,\n",
        "            0.951,\n",
        "            0.9603333333333334,\n",
        "            0.9683333333333334,\n",
        "            0.9703333333333334]\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(12,4))\n",
        "fig.suptitle('Initial FL on EuroSAT Dataset', fontsize=14)\n",
        "axarr = fig.subplots(1,2)\n",
        "\n",
        "axarr[0].plot(loss_vals), axarr[0].set(xlabel='Number of Training Rounds', ylabel='Cross Entropy Loss'), axarr[0].grid('on')\n",
        "axarr[1].plot(acc_vals), axarr[1].set(xlabel='Number of Training Rounds', ylabel='Accuracy (%)'), axarr[1].grid('on');"
      ],
      "metadata": {
        "id": "O_rksGqrZJPT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "5e580585-8021-4c68-fde4-a219579faa64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pBgUDKMdVGLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment 1: Changing the number of clients\n",
        "\n",
        "Running FL with [2, 5, 10, 20] clients"
      ],
      "metadata": {
        "id": "iMSzvz--VHE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --client-pool-size 2 --num-iterations 1000 --num-rounds 10 --val-ratio 0.1"
      ],
      "metadata": {
        "id": "B0YsZqs_AG1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8163205-efbb-4cc4-e1d1-d3ea09743300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=1000.0, 10 classes): [1295 1371 1378 1331 1334 1377 1343 1357 1395 1319]\n",
            "Data partitioned across 2 clients, with IID alpha = 1000.0 and 0.1 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 2 client in the pool.\n",
            "FL round will proceed with 100.0% of clients sampled, at least 2.\n",
            "INFO flower 2024-01-15 22:41:45,574 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-15 22:41:49,832 | app.py:176 | Flower VCE: Ray initialized with resources: {'accelerator_type:V100': 1.0, 'CPU': 2.0, 'node:172.28.0.12': 1.0, 'GPU': 1.0, 'object_store_memory': 3478579200.0, 'memory': 6957158400.0}\n",
            "INFO flower 2024-01-15 22:41:49,832 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-15 22:41:49,832 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-15 22:41:53,324 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-15 22:41:53,324 | server.py:88 | Evaluating initial parameters\n",
            "/content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "  precisions = total_tp / total_pred\n",
            "Evaluation on the server: test_loss=0.0723, test_accuracy=0.0693\n",
            "INFO flower 2024-01-15 22:41:56,484 | server.py:91 | initial parameters (loss, other metrics): 0.07225496729214986, {'accuracy': 0.06933333333333333, 'precisions': array([       nan,        nan,        nan,        nan,        nan,\n",
            "       0.06933333,        nan,        nan,        nan,        nan]), 'recalls': array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}\n",
            "INFO flower 2024-01-15 22:41:56,485 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-15 22:41:56,485 | server.py:215 | fit_round 1: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 1: training round complete, 31980 examples processed\n",
            "DEBUG flower 2024-01-15 22:43:24,998 | server.py:229 | fit_round 1 received 2 results and 0 failures\n",
            "WARNING flower 2024-01-15 22:43:25,004 | fedavg.py:234 | No fit_metrics_aggregation_fn provided\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 0: training round complete, 31980 examples processed\n",
            "Evaluation on the server: test_loss=0.0470, test_accuracy=0.4213\n",
            "INFO flower 2024-01-15 22:43:26,892 | server.py:116 | fit progress: (1, 0.046960618058840435, {'accuracy': 0.42133333333333334, 'precisions': array([0.28690808, 0.41818182, 0.35489221, 0.37554585, 0.53333333,\n",
            "       0.22807018, 0.32142857, 0.84971098, 0.48387097, 0.33229814]), 'recalls': array([0.30473373, 0.20909091, 0.62941176, 0.56953642, 0.9929078 ,\n",
            "       0.0625    , 0.0326087 , 0.42732558, 0.54545455, 0.35081967]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 90.40665975299999)\n",
            "DEBUG flower 2024-01-15 22:43:26,893 | server.py:165 | evaluate_round 1: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22276)\u001b[0m Client 1: evaluation on 1350 examples: loss=0.0161, accuracy=0.4052\n",
            "DEBUG flower 2024-01-15 22:43:28,609 | server.py:179 | evaluate_round 1 received 2 results and 0 failures\n",
            "WARNING flower 2024-01-15 22:43:28,609 | fedavg.py:265 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-15 22:43:28,609 | server.py:215 | fit_round 2: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22275)\u001b[0m Client 0: evaluation on 1350 examples: loss=0.0157, accuracy=0.4052\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 1: training round complete, 31980 examples processed\n",
            "DEBUG flower 2024-01-15 22:44:50,170 | server.py:229 | fit_round 2 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 0: training round complete, 31980 examples processed\n",
            "Evaluation on the server: test_loss=0.0163, test_accuracy=0.8103\n",
            "INFO flower 2024-01-15 22:44:52,072 | server.py:116 | fit progress: (2, 0.0162688850859801, {'accuracy': 0.8103333333333333, 'precisions': array([0.87352941, 0.84677419, 0.78308824, 0.72111554, 0.96212121,\n",
            "       0.75      , 0.63945578, 0.88095238, 0.67948718, 0.92882562]), 'recalls': array([0.87869822, 0.95454545, 0.62647059, 0.59933775, 0.90070922,\n",
            "       0.85096154, 0.68115942, 0.96802326, 0.77090909, 0.8557377 ]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 175.5870990049998)\n",
            "DEBUG flower 2024-01-15 22:44:52,073 | server.py:165 | evaluate_round 2: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22276)\u001b[0m Client 1: evaluation on 1350 examples: loss=0.0057, accuracy=0.7941\n",
            "DEBUG flower 2024-01-15 22:44:53,691 | server.py:179 | evaluate_round 2 received 2 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-15 22:44:53,691 | server.py:215 | fit_round 3: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22275)\u001b[0m Client 0: evaluation on 1350 examples: loss=0.0063, accuracy=0.7911\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 1: training round complete, 31980 examples processed\n",
            "DEBUG flower 2024-01-15 22:46:15,778 | server.py:229 | fit_round 3 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 0: training round complete, 31980 examples processed\n",
            "Evaluation on the server: test_loss=0.0125, test_accuracy=0.8580\n",
            "INFO flower 2024-01-15 22:46:17,688 | server.py:116 | fit progress: (3, 0.012538564672072728, {'accuracy': 0.858, 'precisions': array([0.9483871 , 0.89830508, 0.75476839, 0.80228137, 0.90460526,\n",
            "       0.77876106, 0.74157303, 0.91032609, 0.84046693, 0.96478873]), 'recalls': array([0.86982249, 0.96363636, 0.81470588, 0.6986755 , 0.9751773 ,\n",
            "       0.84615385, 0.7173913 , 0.97383721, 0.78545455, 0.89836066]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 261.202976048)\n",
            "DEBUG flower 2024-01-15 22:46:17,689 | server.py:165 | evaluate_round 3: strategy sampled 2 clients (out of 2)\n",
            "DEBUG flower 2024-01-15 22:46:19,359 | server.py:179 | evaluate_round 3 received 2 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-15 22:46:19,359 | server.py:215 | fit_round 4: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22275)\u001b[0m Client 1: evaluation on 1350 examples: loss=0.0051, accuracy=0.8215\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22276)\u001b[0m Client 0: evaluation on 1350 examples: loss=0.0061, accuracy=0.8030\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 0: training round complete, 31980 examples processed\n",
            "DEBUG flower 2024-01-15 22:47:40,905 | server.py:229 | fit_round 4 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 1: training round complete, 31980 examples processed\n",
            "Evaluation on the server: test_loss=0.0116, test_accuracy=0.8700\n",
            "INFO flower 2024-01-15 22:47:42,845 | server.py:116 | fit progress: (4, 0.011561048236986001, {'accuracy': 0.87, 'precisions': array([0.92424242, 0.82352941, 0.89568345, 0.90909091, 0.87267081,\n",
            "       0.80084746, 0.83394834, 0.92797784, 0.75226586, 0.97991968]), 'recalls': array([0.90236686, 0.97575758, 0.73235294, 0.69536424, 0.9964539 ,\n",
            "       0.90865385, 0.81884058, 0.97383721, 0.90545455, 0.8       ]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 346.3596753699994)\n",
            "DEBUG flower 2024-01-15 22:47:42,846 | server.py:165 | evaluate_round 4: strategy sampled 2 clients (out of 2)\n",
            "DEBUG flower 2024-01-15 22:47:44,527 | server.py:179 | evaluate_round 4 received 2 results and 0 failures\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-15 22:47:44,528 | server.py:215 | fit_round 5: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22275)\u001b[0m Client 1: evaluation on 1350 examples: loss=0.0056, accuracy=0.8067\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22276)\u001b[0m Client 0: evaluation on 1350 examples: loss=0.0068, accuracy=0.7874\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 0: training round complete, 31980 examples processed\n",
            "DEBUG flower 2024-01-15 22:49:05,757 | server.py:229 | fit_round 5 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 1: training round complete, 31980 examples processed\n",
            "Evaluation on the server: test_loss=0.0073, test_accuracy=0.9167\n",
            "INFO flower 2024-01-15 22:49:07,793 | server.py:116 | fit progress: (5, 0.007295409930249055, {'accuracy': 0.9166666666666666, 'precisions': array([0.91618497, 0.9271137 , 0.8489011 , 0.9375    , 0.97887324,\n",
            "       0.79423868, 0.9380531 , 0.97159091, 0.87272727, 0.96949153]), 'recalls': array([0.93786982, 0.96363636, 0.90882353, 0.84437086, 0.9858156 ,\n",
            "       0.92788462, 0.76811594, 0.99418605, 0.87272727, 0.93770492]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 431.30787640000017)\n",
            "DEBUG flower 2024-01-15 22:49:07,794 | server.py:165 | evaluate_round 5: strategy sampled 2 clients (out of 2)\n",
            "DEBUG flower 2024-01-15 22:49:09,421 | server.py:179 | evaluate_round 5 received 2 results and 0 failures\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-15 22:49:09,422 | server.py:215 | fit_round 6: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22275)\u001b[0m Client 0: evaluation on 1350 examples: loss=0.0065, accuracy=0.8259\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22276)\u001b[0m Client 1: evaluation on 1350 examples: loss=0.0050, accuracy=0.8326\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 0: training round complete, 31980 examples processed\n",
            "DEBUG flower 2024-01-15 22:50:29,380 | server.py:229 | fit_round 6 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 1: training round complete, 31980 examples processed\n",
            "Evaluation on the server: test_loss=0.0058, test_accuracy=0.9387\n",
            "INFO flower 2024-01-15 22:50:31,760 | server.py:116 | fit progress: (6, 0.005776783083875974, {'accuracy': 0.9386666666666666, 'precisions': array([0.95043732, 0.96      , 0.96539792, 0.89341693, 0.98924731,\n",
            "       0.81632653, 0.87931034, 0.98554913, 0.94252874, 0.97689769]), 'recalls': array([0.96449704, 0.94545455, 0.82058824, 0.94370861, 0.9787234 ,\n",
            "       0.96153846, 0.92391304, 0.99127907, 0.89454545, 0.9704918 ]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 515.2743219260001)\n",
            "DEBUG flower 2024-01-15 22:50:31,761 | server.py:165 | evaluate_round 6: strategy sampled 2 clients (out of 2)\n",
            "DEBUG flower 2024-01-15 22:50:33,355 | server.py:179 | evaluate_round 6 received 2 results and 0 failures\n",
            "Configuring round 7\n",
            "DEBUG flower 2024-01-15 22:50:33,355 | server.py:215 | fit_round 7: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22275)\u001b[0m Client 0: evaluation on 1350 examples: loss=0.0071, accuracy=0.8252\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22276)\u001b[0m Client 1: evaluation on 1350 examples: loss=0.0062, accuracy=0.8207\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 1: training round complete, 31980 examples processed\n",
            "DEBUG flower 2024-01-15 22:51:53,813 | server.py:229 | fit_round 7 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 0: training round complete, 31980 examples processed\n",
            "Evaluation on the server: test_loss=0.0054, test_accuracy=0.9480\n",
            "INFO flower 2024-01-15 22:51:56,415 | server.py:116 | fit progress: (7, 0.005388512606732548, {'accuracy': 0.948, 'precisions': array([0.92937853, 0.9180791 , 0.9031339 , 0.97864769, 0.98943662,\n",
            "       0.94680851, 0.97983871, 0.98550725, 0.90277778, 0.96416938]), 'recalls': array([0.97337278, 0.98484848, 0.93235294, 0.91059603, 0.9964539 ,\n",
            "       0.85576923, 0.88043478, 0.98837209, 0.94545455, 0.9704918 ]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 599.9300515570003)\n",
            "DEBUG flower 2024-01-15 22:51:56,416 | server.py:165 | evaluate_round 7: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22275)\u001b[0m Client 0: evaluation on 1350 examples: loss=0.0090, accuracy=0.8037\n",
            "DEBUG flower 2024-01-15 22:51:58,102 | server.py:179 | evaluate_round 7 received 2 results and 0 failures\n",
            "Configuring round 8\n",
            "DEBUG flower 2024-01-15 22:51:58,102 | server.py:215 | fit_round 8: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22276)\u001b[0m Client 1: evaluation on 1350 examples: loss=0.0069, accuracy=0.8193\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "DEBUG flower 2024-01-15 22:53:18,694 | server.py:229 | fit_round 8 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 1: training round complete, 31980 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 0: training round complete, 31980 examples processed\n",
            "Evaluation on the server: test_loss=0.0050, test_accuracy=0.9537\n",
            "INFO flower 2024-01-15 22:53:21,226 | server.py:116 | fit progress: (8, 0.004983850862830878, {'accuracy': 0.9536666666666667, 'precisions': array([0.97507788, 0.93913043, 0.94658754, 0.93506494, 0.98591549,\n",
            "       0.90047393, 0.93262411, 0.96348315, 0.95703125, 0.98666667]), 'recalls': array([0.9260355 , 0.98181818, 0.93823529, 0.95364238, 0.9929078 ,\n",
            "       0.91346154, 0.95289855, 0.99709302, 0.89090909, 0.9704918 ]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 684.7404180220001)\n",
            "DEBUG flower 2024-01-15 22:53:21,227 | server.py:165 | evaluate_round 8: strategy sampled 2 clients (out of 2)\n",
            "DEBUG flower 2024-01-15 22:53:22,940 | server.py:179 | evaluate_round 8 received 2 results and 0 failures\n",
            "Configuring round 9\n",
            "DEBUG flower 2024-01-15 22:53:22,940 | server.py:215 | fit_round 9: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22275)\u001b[0m Client 1: evaluation on 1350 examples: loss=0.0071, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22276)\u001b[0m Client 0: evaluation on 1350 examples: loss=0.0090, accuracy=0.8089\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 1: training round complete, 31980 examples processed\n",
            "DEBUG flower 2024-01-15 22:54:42,142 | server.py:229 | fit_round 9 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 0: training round complete, 31980 examples processed\n",
            "Evaluation on the server: test_loss=0.0058, test_accuracy=0.9483\n",
            "INFO flower 2024-01-15 22:54:44,709 | server.py:116 | fit progress: (9, 0.005829022336440782, {'accuracy': 0.9483333333333334, 'precisions': array([0.93982808, 0.95783133, 0.98207885, 0.94352159, 0.9825784 ,\n",
            "       0.85957447, 0.93548387, 0.98265896, 0.90311419, 0.97359736]), 'recalls': array([0.9704142 , 0.96363636, 0.80588235, 0.94039735, 1.        ,\n",
            "       0.97115385, 0.94565217, 0.98837209, 0.94909091, 0.96721311]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 768.2238820590001)\n",
            "DEBUG flower 2024-01-15 22:54:44,710 | server.py:165 | evaluate_round 9: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22276)\u001b[0m Client 1: evaluation on 1350 examples: loss=0.0084, accuracy=0.8089\n",
            "DEBUG flower 2024-01-15 22:54:47,101 | server.py:179 | evaluate_round 9 received 2 results and 0 failures\n",
            "Configuring round 10\n",
            "DEBUG flower 2024-01-15 22:54:47,101 | server.py:215 | fit_round 10: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22275)\u001b[0m Client 0: evaluation on 1350 examples: loss=0.0100, accuracy=0.8104\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22275)\u001b[0m Client 1: training round complete, 31980 examples processed\n",
            "DEBUG flower 2024-01-15 22:56:06,262 | server.py:229 | fit_round 10 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22276)\u001b[0m Client 0: training round complete, 31980 examples processed\n",
            "Evaluation on the server: test_loss=0.0045, test_accuracy=0.9640\n",
            "INFO flower 2024-01-15 22:56:08,824 | server.py:116 | fit progress: (10, 0.004462762908777222, {'accuracy': 0.964, 'precisions': array([0.9760479 , 0.9505814 , 0.98076923, 0.93569132, 0.9825784 ,\n",
            "       0.90990991, 0.95289855, 0.98563218, 0.95940959, 0.98983051]), 'recalls': array([0.96449704, 0.99090909, 0.9       , 0.96357616, 1.        ,\n",
            "       0.97115385, 0.95289855, 0.99709302, 0.94545455, 0.95737705]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 852.3388765519994)\n",
            "DEBUG flower 2024-01-15 22:56:08,825 | server.py:165 | evaluate_round 10: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22276)\u001b[0m Client 0: evaluation on 1350 examples: loss=0.0106, accuracy=0.8081\n",
            "DEBUG flower 2024-01-15 22:56:11,382 | server.py:179 | evaluate_round 10 received 2 results and 0 failures\n",
            "INFO flower 2024-01-15 22:56:11,382 | server.py:144 | FL finished in 854.8970031540002\n",
            "INFO flower 2024-01-15 22:56:11,383 | app.py:180 | app_fit: losses_distributed [(1, 0.015909959916715267), (2, 0.005959852558595163), (3, 0.005596680376264784), (4, 0.006238219848385564), (5, 0.0057808109124501544), (6, 0.006644574900468191), (7, 0.00795192375227257), (8, 0.008072886831230587), (9, 0.009194627161379214), (10, 0.009688594341278077)]\n",
            "INFO flower 2024-01-15 22:56:11,383 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2024-01-15 22:56:11,383 | app.py:182 | app_fit: losses_centralized [(0, 0.07225496729214986), (1, 0.046960618058840435), (2, 0.0162688850859801), (3, 0.012538564672072728), (4, 0.011561048236986001), (5, 0.007295409930249055), (6, 0.005776783083875974), (7, 0.005388512606732548), (8, 0.004983850862830878), (9, 0.005829022336440782), (10, 0.004462762908777222)]\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22275)\u001b[0m Client 1: evaluation on 1350 examples: loss=0.0088, accuracy=0.8096\n",
            "INFO flower 2024-01-15 22:56:11,392 | app.py:183 | app_fit: metrics_centralized {'accuracy': [(0, 0.06933333333333333), (1, 0.42133333333333334), (2, 0.8103333333333333), (3, 0.858), (4, 0.87), (5, 0.9166666666666666), (6, 0.9386666666666666), (7, 0.948), (8, 0.9536666666666667), (9, 0.9483333333333334), (10, 0.964)], 'precisions': [(0, array([       nan,        nan,        nan,        nan,        nan,\n",
            "       0.06933333,        nan,        nan,        nan,        nan])), (1, array([0.28690808, 0.41818182, 0.35489221, 0.37554585, 0.53333333,\n",
            "       0.22807018, 0.32142857, 0.84971098, 0.48387097, 0.33229814])), (2, array([0.87352941, 0.84677419, 0.78308824, 0.72111554, 0.96212121,\n",
            "       0.75      , 0.63945578, 0.88095238, 0.67948718, 0.92882562])), (3, array([0.9483871 , 0.89830508, 0.75476839, 0.80228137, 0.90460526,\n",
            "       0.77876106, 0.74157303, 0.91032609, 0.84046693, 0.96478873])), (4, array([0.92424242, 0.82352941, 0.89568345, 0.90909091, 0.87267081,\n",
            "       0.80084746, 0.83394834, 0.92797784, 0.75226586, 0.97991968])), (5, array([0.91618497, 0.9271137 , 0.8489011 , 0.9375    , 0.97887324,\n",
            "       0.79423868, 0.9380531 , 0.97159091, 0.87272727, 0.96949153])), (6, array([0.95043732, 0.96      , 0.96539792, 0.89341693, 0.98924731,\n",
            "       0.81632653, 0.87931034, 0.98554913, 0.94252874, 0.97689769])), (7, array([0.92937853, 0.9180791 , 0.9031339 , 0.97864769, 0.98943662,\n",
            "       0.94680851, 0.97983871, 0.98550725, 0.90277778, 0.96416938])), (8, array([0.97507788, 0.93913043, 0.94658754, 0.93506494, 0.98591549,\n",
            "       0.90047393, 0.93262411, 0.96348315, 0.95703125, 0.98666667])), (9, array([0.93982808, 0.95783133, 0.98207885, 0.94352159, 0.9825784 ,\n",
            "       0.85957447, 0.93548387, 0.98265896, 0.90311419, 0.97359736])), (10, array([0.9760479 , 0.9505814 , 0.98076923, 0.93569132, 0.9825784 ,\n",
            "       0.90990991, 0.95289855, 0.98563218, 0.95940959, 0.98983051]))], 'recalls': [(0, array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])), (1, array([0.30473373, 0.20909091, 0.62941176, 0.56953642, 0.9929078 ,\n",
            "       0.0625    , 0.0326087 , 0.42732558, 0.54545455, 0.35081967])), (2, array([0.87869822, 0.95454545, 0.62647059, 0.59933775, 0.90070922,\n",
            "       0.85096154, 0.68115942, 0.96802326, 0.77090909, 0.8557377 ])), (3, array([0.86982249, 0.96363636, 0.81470588, 0.6986755 , 0.9751773 ,\n",
            "       0.84615385, 0.7173913 , 0.97383721, 0.78545455, 0.89836066])), (4, array([0.90236686, 0.97575758, 0.73235294, 0.69536424, 0.9964539 ,\n",
            "       0.90865385, 0.81884058, 0.97383721, 0.90545455, 0.8       ])), (5, array([0.93786982, 0.96363636, 0.90882353, 0.84437086, 0.9858156 ,\n",
            "       0.92788462, 0.76811594, 0.99418605, 0.87272727, 0.93770492])), (6, array([0.96449704, 0.94545455, 0.82058824, 0.94370861, 0.9787234 ,\n",
            "       0.96153846, 0.92391304, 0.99127907, 0.89454545, 0.9704918 ])), (7, array([0.97337278, 0.98484848, 0.93235294, 0.91059603, 0.9964539 ,\n",
            "       0.85576923, 0.88043478, 0.98837209, 0.94545455, 0.9704918 ])), (8, array([0.9260355 , 0.98181818, 0.93823529, 0.95364238, 0.9929078 ,\n",
            "       0.91346154, 0.95289855, 0.99709302, 0.89090909, 0.9704918 ])), (9, array([0.9704142 , 0.96363636, 0.80588235, 0.94039735, 1.        ,\n",
            "       0.97115385, 0.94565217, 0.98837209, 0.94909091, 0.96721311])), (10, array([0.96449704, 0.99090909, 0.9       , 0.96357616, 1.        ,\n",
            "       0.97115385, 0.95289855, 0.99709302, 0.94545455, 0.95737705]))], 'class proportions': [(0, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (1, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (2, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (3, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (4, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (5, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (6, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (7, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (8, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (9, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (10, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667]))]}\n",
            "History (loss, distributed):\n",
            "\tround 1: 0.015909959916715267\n",
            "\tround 2: 0.005959852558595163\n",
            "\tround 3: 0.005596680376264784\n",
            "\tround 4: 0.006238219848385564\n",
            "\tround 5: 0.0057808109124501544\n",
            "\tround 6: 0.006644574900468191\n",
            "\tround 7: 0.00795192375227257\n",
            "\tround 8: 0.008072886831230587\n",
            "\tround 9: 0.009194627161379214\n",
            "\tround 10: 0.009688594341278077\n",
            "History (loss, centralized):\n",
            "\tround 0: 0.07225496729214986\n",
            "\tround 1: 0.046960618058840435\n",
            "\tround 2: 0.0162688850859801\n",
            "\tround 3: 0.012538564672072728\n",
            "\tround 4: 0.011561048236986001\n",
            "\tround 5: 0.007295409930249055\n",
            "\tround 6: 0.005776783083875974\n",
            "\tround 7: 0.005388512606732548\n",
            "\tround 8: 0.004983850862830878\n",
            "\tround 9: 0.005829022336440782\n",
            "\tround 10: 0.004462762908777222\n",
            "History (metrics, centralized):\n",
            "{'accuracy': [(0, 0.06933333333333333), (1, 0.42133333333333334), (2, 0.8103333333333333), (3, 0.858), (4, 0.87), (5, 0.9166666666666666), (6, 0.9386666666666666), (7, 0.948), (8, 0.9536666666666667), (9, 0.9483333333333334), (10, 0.964)], 'precisions': [(0, array([       nan,        nan,        nan,        nan,        nan,\n",
            "       0.06933333,        nan,        nan,        nan,        nan])), (1, array([0.28690808, 0.41818182, 0.35489221, 0.37554585, 0.53333333,\n",
            "       0.22807018, 0.32142857, 0.84971098, 0.48387097, 0.33229814])), (2, array([0.87352941, 0.84677419, 0.78308824, 0.72111554, 0.96212121,\n",
            "       0.75      , 0.63945578, 0.88095238, 0.67948718, 0.92882562])), (3, array([0.9483871 , 0.89830508, 0.75476839, 0.80228137, 0.90460526,\n",
            "       0.77876106, 0.74157303, 0.91032609, 0.84046693, 0.96478873])), (4, array([0.92424242, 0.82352941, 0.89568345, 0.90909091, 0.87267081,\n",
            "       0.80084746, 0.83394834, 0.92797784, 0.75226586, 0.97991968])), (5, array([0.91618497, 0.9271137 , 0.8489011 , 0.9375    , 0.97887324,\n",
            "       0.79423868, 0.9380531 , 0.97159091, 0.87272727, 0.96949153])), (6, array([0.95043732, 0.96      , 0.96539792, 0.89341693, 0.98924731,\n",
            "       0.81632653, 0.87931034, 0.98554913, 0.94252874, 0.97689769])), (7, array([0.92937853, 0.9180791 , 0.9031339 , 0.97864769, 0.98943662,\n",
            "       0.94680851, 0.97983871, 0.98550725, 0.90277778, 0.96416938])), (8, array([0.97507788, 0.93913043, 0.94658754, 0.93506494, 0.98591549,\n",
            "       0.90047393, 0.93262411, 0.96348315, 0.95703125, 0.98666667])), (9, array([0.93982808, 0.95783133, 0.98207885, 0.94352159, 0.9825784 ,\n",
            "       0.85957447, 0.93548387, 0.98265896, 0.90311419, 0.97359736])), (10, array([0.9760479 , 0.9505814 , 0.98076923, 0.93569132, 0.9825784 ,\n",
            "       0.90990991, 0.95289855, 0.98563218, 0.95940959, 0.98983051]))], 'recalls': [(0, array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])), (1, array([0.30473373, 0.20909091, 0.62941176, 0.56953642, 0.9929078 ,\n",
            "       0.0625    , 0.0326087 , 0.42732558, 0.54545455, 0.35081967])), (2, array([0.87869822, 0.95454545, 0.62647059, 0.59933775, 0.90070922,\n",
            "       0.85096154, 0.68115942, 0.96802326, 0.77090909, 0.8557377 ])), (3, array([0.86982249, 0.96363636, 0.81470588, 0.6986755 , 0.9751773 ,\n",
            "       0.84615385, 0.7173913 , 0.97383721, 0.78545455, 0.89836066])), (4, array([0.90236686, 0.97575758, 0.73235294, 0.69536424, 0.9964539 ,\n",
            "       0.90865385, 0.81884058, 0.97383721, 0.90545455, 0.8       ])), (5, array([0.93786982, 0.96363636, 0.90882353, 0.84437086, 0.9858156 ,\n",
            "       0.92788462, 0.76811594, 0.99418605, 0.87272727, 0.93770492])), (6, array([0.96449704, 0.94545455, 0.82058824, 0.94370861, 0.9787234 ,\n",
            "       0.96153846, 0.92391304, 0.99127907, 0.89454545, 0.9704918 ])), (7, array([0.97337278, 0.98484848, 0.93235294, 0.91059603, 0.9964539 ,\n",
            "       0.85576923, 0.88043478, 0.98837209, 0.94545455, 0.9704918 ])), (8, array([0.9260355 , 0.98181818, 0.93823529, 0.95364238, 0.9929078 ,\n",
            "       0.91346154, 0.95289855, 0.99709302, 0.89090909, 0.9704918 ])), (9, array([0.9704142 , 0.96363636, 0.80588235, 0.94039735, 1.        ,\n",
            "       0.97115385, 0.94565217, 0.98837209, 0.94909091, 0.96721311])), (10, array([0.96449704, 0.99090909, 0.9       , 0.96357616, 1.        ,\n",
            "       0.97115385, 0.95289855, 0.99709302, 0.94545455, 0.95737705]))], 'class proportions': [(0, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (1, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (2, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (3, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (4, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (5, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (6, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (7, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (8, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (9, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (10, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667]))]}\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --client-pool-size 5 --num-iterations 1000 --num-rounds 10 --val-ratio 0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-JlbwdcU1u9",
        "outputId": "1d307b4d-16aa-4861-a229-2059225c749e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=1000.0, 10 classes): [558 511 508 547 549 536 537 576 563 515]\n",
            "Data partitioned across 5 clients, with IID alpha = 1000.0 and 0.1 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 5 client in the pool.\n",
            "FL round will proceed with 100.0% of clients sampled, at least 2.\n",
            "INFO flower 2024-01-15 22:56:40,324 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-15 22:56:44,302 | app.py:176 | Flower VCE: Ray initialized with resources: {'memory': 7046836224.0, 'CPU': 2.0, 'accelerator_type:V100': 1.0, 'node:172.28.0.12': 1.0, 'object_store_memory': 3523418112.0, 'GPU': 1.0}\n",
            "INFO flower 2024-01-15 22:56:44,302 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-15 22:56:44,302 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-15 22:56:47,137 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-15 22:56:47,137 | server.py:88 | Evaluating initial parameters\n",
            "/content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "  precisions = total_tp / total_pred\n",
            "Evaluation on the server: test_loss=0.0723, test_accuracy=0.0740\n",
            "INFO flower 2024-01-15 22:56:49,563 | server.py:91 | initial parameters (loss, other metrics): 0.07225578943888346, {'accuracy': 0.074, 'precisions': array([       nan,        nan, 0.0875    , 0.06282723, 0.07174173,\n",
            "              nan, 0.10454545,        nan,        nan,        nan]), 'recalls': array([0.        , 0.        , 0.02058824, 0.0397351 , 0.63829787,\n",
            "       0.        , 0.08333333, 0.        , 0.        , 0.        ]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}\n",
            "INFO flower 2024-01-15 22:56:49,564 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-15 22:56:49,565 | server.py:215 | fit_round 1: strategy sampled 2 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26527)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26528)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26527)\u001b[0m Client 1: training round complete, 31976 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26528)\u001b[0m Client 4: training round complete, 31976 examples processed\n",
            "DEBUG flower 2024-01-15 22:58:15,361 | server.py:229 | fit_round 1 received 2 results and 0 failures\n",
            "WARNING flower 2024-01-15 22:58:15,369 | fedavg.py:234 | No fit_metrics_aggregation_fn provided\n",
            "Evaluation on the server: test_loss=0.0387, test_accuracy=0.6523\n",
            "INFO flower 2024-01-15 22:58:17,902 | server.py:116 | fit progress: (1, 0.03873693352937698, {'accuracy': 0.6523333333333333, 'precisions': array([0.55734767, 0.71860465, 0.50591716, 0.47550432, 0.78658537,\n",
            "              nan, 0.51428571, 0.79948586, 0.61797753, 0.90272374]), 'recalls': array([0.92011834, 0.93636364, 0.50294118, 0.54635762, 0.91489362,\n",
            "       0.        , 0.32608696, 0.90406977, 0.4       , 0.76065574]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 88.3376303719997)\n",
            "DEBUG flower 2024-01-15 22:58:17,903 | server.py:165 | evaluate_round 1: strategy sampled 5 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26527)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26527)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26527)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0153, accuracy=0.5944\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26528)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0134, accuracy=0.6370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26528)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26528)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26528)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0149, accuracy=0.6278\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26527)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0182, accuracy=0.5667\n",
            "DEBUG flower 2024-01-15 22:58:25,302 | server.py:179 | evaluate_round 1 received 5 results and 0 failures\n",
            "WARNING flower 2024-01-15 22:58:25,302 | fedavg.py:265 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-15 22:58:25,302 | server.py:215 | fit_round 2: strategy sampled 4 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27050)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27050)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27050)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27050)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27050)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0082, accuracy=0.7352\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27050)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26527)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27144)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27197)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27050)\u001b[0m Client 1: training round complete, 31976 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26527)\u001b[0m Client 3: training round complete, 31976 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27144)\u001b[0m Client 0: training round complete, 31976 examples processed\n",
            "DEBUG flower 2024-01-15 23:01:29,612 | server.py:229 | fit_round 2 received 4 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27197)\u001b[0m Client 2: training round complete, 31976 examples processed\n",
            "Evaluation on the server: test_loss=0.0158, test_accuracy=0.8160\n",
            "INFO flower 2024-01-15 23:01:32,139 | server.py:116 | fit progress: (2, 0.01577845543126265, {'accuracy': 0.816, 'precisions': array([0.85294118, 0.85915493, 0.74688797, 0.81465517, 0.88709677,\n",
            "       0.79545455, 0.59833795, 0.94378698, 0.72847682, 0.9269103 ]), 'recalls': array([0.85798817, 0.92424242, 0.52941176, 0.62582781, 0.9751773 ,\n",
            "       0.84134615, 0.7826087 , 0.92732558, 0.8       , 0.9147541 ]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 282.57436352700006)\n",
            "DEBUG flower 2024-01-15 23:01:32,140 | server.py:165 | evaluate_round 2: strategy sampled 5 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27197)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0063, accuracy=0.8000\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27144)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0068, accuracy=0.8000\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27197)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0068, accuracy=0.7741\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27197)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27197)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27144)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0080, accuracy=0.7722\n",
            "DEBUG flower 2024-01-15 23:01:39,313 | server.py:179 | evaluate_round 2 received 5 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-15 23:01:39,314 | server.py:215 | fit_round 3: strategy sampled 3 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28072)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0069, accuracy=0.7759\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28072)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27144)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28166)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28072)\u001b[0m Client 1: training round complete, 31976 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27144)\u001b[0m Client 4: training round complete, 31976 examples processed\n",
            "DEBUG flower 2024-01-15 23:03:51,058 | server.py:229 | fit_round 3 received 3 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28166)\u001b[0m Client 2: training round complete, 31976 examples processed\n",
            "Evaluation on the server: test_loss=0.0151, test_accuracy=0.8377\n",
            "INFO flower 2024-01-15 23:03:53,114 | server.py:116 | fit progress: (3, 0.015060801784197489, {'accuracy': 0.8376666666666667, 'precisions': array([0.77696078, 0.89820359, 0.83534137, 0.81443299, 0.90635452,\n",
            "       0.87162162, 0.66666667, 0.96978852, 0.74744027, 0.92282958]), 'recalls': array([0.93786982, 0.90909091, 0.61176471, 0.78476821, 0.96099291,\n",
            "       0.62019231, 0.8115942 , 0.93313953, 0.79636364, 0.94098361]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 423.5493239999996)\n",
            "DEBUG flower 2024-01-15 23:03:53,115 | server.py:165 | evaluate_round 3: strategy sampled 5 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28166)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0088, accuracy=0.7704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27144)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0099, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27144)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0071, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28166)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0090, accuracy=0.7907\n",
            "DEBUG flower 2024-01-15 23:04:00,922 | server.py:179 | evaluate_round 3 received 5 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-15 23:04:00,922 | server.py:215 | fit_round 4: strategy sampled 3 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28824)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0067, accuracy=0.8000\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28824)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28824)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28166)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28824)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28921)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28166)\u001b[0m Client 3: training round complete, 31976 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28824)\u001b[0m Client 2: training round complete, 31976 examples processed\n",
            "DEBUG flower 2024-01-15 23:06:08,673 | server.py:229 | fit_round 4 received 3 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28921)\u001b[0m Client 4: training round complete, 31976 examples processed\n",
            "Evaluation on the server: test_loss=0.0135, test_accuracy=0.8593\n",
            "INFO flower 2024-01-15 23:06:10,718 | server.py:116 | fit progress: (4, 0.013499050612250964, {'accuracy': 0.8593333333333333, 'precisions': array([0.8490566 , 0.85522788, 0.78592375, 0.8089172 , 0.85230769,\n",
            "       0.93137255, 0.80442804, 0.96996997, 0.82720588, 0.95302013]), 'recalls': array([0.93195266, 0.96666667, 0.78823529, 0.8410596 , 0.9822695 ,\n",
            "       0.45673077, 0.78985507, 0.93895349, 0.81818182, 0.93114754]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 561.1532119829999)\n",
            "DEBUG flower 2024-01-15 23:06:10,718 | server.py:165 | evaluate_round 4: strategy sampled 5 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28824)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0099, accuracy=0.8019\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28921)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0096, accuracy=0.7759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28824)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0064, accuracy=0.8333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28921)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0103, accuracy=0.7833\n",
            "DEBUG flower 2024-01-15 23:06:16,639 | server.py:179 | evaluate_round 4 received 5 results and 0 failures\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-15 23:06:16,640 | server.py:215 | fit_round 5: strategy sampled 2 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=29564)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0077, accuracy=0.7759\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28921)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=29564)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28921)\u001b[0m Client 0: training round complete, 31976 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=29564)\u001b[0m Client 1: training round complete, 31976 examples processed\n",
            "DEBUG flower 2024-01-15 23:07:37,194 | server.py:229 | fit_round 5 received 2 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0100, test_accuracy=0.8977\n",
            "INFO flower 2024-01-15 23:07:39,810 | server.py:116 | fit progress: (5, 0.010043084785342217, {'accuracy': 0.8976666666666666, 'precisions': array([0.90962099, 0.89664804, 0.90425532, 0.8370607 , 0.96428571,\n",
            "       0.86238532, 0.8028169 , 0.96242775, 0.83391003, 0.98606272]), 'recalls': array([0.92307692, 0.97272727, 0.75      , 0.86754967, 0.95744681,\n",
            "       0.90384615, 0.82608696, 0.96802326, 0.87636364, 0.92786885]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 650.2453184920005)\n",
            "DEBUG flower 2024-01-15 23:07:39,811 | server.py:165 | evaluate_round 5: strategy sampled 5 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=29564)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0109, accuracy=0.7981\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28921)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0088, accuracy=0.8019\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=29564)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0101, accuracy=0.8000\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28921)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28921)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28921)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0067, accuracy=0.8130\n",
            "DEBUG flower 2024-01-15 23:07:46,144 | server.py:179 | evaluate_round 5 received 5 results and 0 failures\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-15 23:07:46,144 | server.py:215 | fit_round 6: strategy sampled 3 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30028)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0080, accuracy=0.8037\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30028)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28921)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30118)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30028)\u001b[0m Client 1: training round complete, 31976 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28921)\u001b[0m Client 0: training round complete, 31976 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30118)\u001b[0m Client 3: training round complete, 31976 examples processed\n",
            "DEBUG flower 2024-01-15 23:09:58,397 | server.py:229 | fit_round 6 received 3 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0095, test_accuracy=0.9080\n",
            "INFO flower 2024-01-15 23:10:00,629 | server.py:116 | fit progress: (6, 0.009546019094685713, {'accuracy': 0.908, 'precisions': array([0.93865031, 0.90331492, 0.92387543, 0.85901639, 0.90163934,\n",
            "       0.86757991, 0.86590038, 0.93681319, 0.88086643, 0.97945205]), 'recalls': array([0.90532544, 0.99090909, 0.78529412, 0.86754967, 0.9751773 ,\n",
            "       0.91346154, 0.81884058, 0.99127907, 0.88727273, 0.93770492]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 791.0650754540002)\n",
            "DEBUG flower 2024-01-15 23:10:00,631 | server.py:165 | evaluate_round 6: strategy sampled 5 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28921)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0073, accuracy=0.8370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30118)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0111, accuracy=0.8000\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28921)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0125, accuracy=0.8074\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30118)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0089, accuracy=0.7981\n",
            "DEBUG flower 2024-01-15 23:10:08,578 | server.py:179 | evaluate_round 6 received 5 results and 0 failures\n",
            "Configuring round 7\n",
            "DEBUG flower 2024-01-15 23:10:08,579 | server.py:215 | fit_round 7: strategy sampled 2 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30780)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0092, accuracy=0.8167\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30780)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30118)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30118)\u001b[0m Client 2: training round complete, 31976 examples processed\n",
            "DEBUG flower 2024-01-15 23:11:28,958 | server.py:229 | fit_round 7 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30780)\u001b[0m Client 3: training round complete, 31976 examples processed\n",
            "Evaluation on the server: test_loss=0.0082, test_accuracy=0.9293\n",
            "INFO flower 2024-01-15 23:11:31,013 | server.py:116 | fit progress: (7, 0.00818750384139518, {'accuracy': 0.9293333333333333, 'precisions': array([0.91954023, 0.96923077, 0.9673913 , 0.89032258, 0.97535211,\n",
            "       0.824     , 0.85273973, 0.98507463, 0.91304348, 0.97368421]), 'recalls': array([0.94674556, 0.95454545, 0.78529412, 0.91390728, 0.9822695 ,\n",
            "       0.99038462, 0.90217391, 0.95930233, 0.91636364, 0.9704918 ]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 881.4483578939999)\n",
            "DEBUG flower 2024-01-15 23:11:31,014 | server.py:165 | evaluate_round 7: strategy sampled 5 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30118)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0139, accuracy=0.8037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30780)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0105, accuracy=0.8185\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30780)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30780)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30780)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0107, accuracy=0.8019\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30118)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0096, accuracy=0.8204\n",
            "DEBUG flower 2024-01-15 23:11:38,326 | server.py:179 | evaluate_round 7 received 5 results and 0 failures\n",
            "Configuring round 8\n",
            "DEBUG flower 2024-01-15 23:11:38,326 | server.py:215 | fit_round 8: strategy sampled 2 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31252)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0139, accuracy=0.8130\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30118)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31252)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30118)\u001b[0m Client 3: training round complete, 31976 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31252)\u001b[0m Client 1: training round complete, 31976 examples processed\n",
            "DEBUG flower 2024-01-15 23:13:00,793 | server.py:229 | fit_round 8 received 2 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0098, test_accuracy=0.9180\n",
            "INFO flower 2024-01-15 23:13:02,815 | server.py:116 | fit progress: (8, 0.009752940515056253, {'accuracy': 0.918, 'precisions': array([0.94153846, 0.93083573, 0.87134503, 0.93430657, 0.86687307,\n",
            "       0.92462312, 0.8277027 , 0.99076923, 0.91039427, 0.9862069 ]), 'recalls': array([0.90532544, 0.97878788, 0.87647059, 0.84768212, 0.9929078 ,\n",
            "       0.88461538, 0.88768116, 0.93604651, 0.92363636, 0.93770492]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 973.251045471)\n",
            "DEBUG flower 2024-01-15 23:13:02,816 | server.py:165 | evaluate_round 8: strategy sampled 5 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30118)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0094, accuracy=0.8111\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30118)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30118)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31252)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0114, accuracy=0.8000\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30118)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0108, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31252)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0134, accuracy=0.7778\n",
            "DEBUG flower 2024-01-15 23:13:08,935 | server.py:179 | evaluate_round 8 received 5 results and 0 failures\n",
            "Configuring round 9\n",
            "DEBUG flower 2024-01-15 23:13:08,935 | server.py:215 | fit_round 9: strategy sampled 2 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31725)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0141, accuracy=0.7944\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30118)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31725)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31725)\u001b[0m Client 4: training round complete, 31976 examples processed\n",
            "DEBUG flower 2024-01-15 23:14:30,326 | server.py:229 | fit_round 9 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30118)\u001b[0m Client 0: training round complete, 31976 examples processed\n",
            "Evaluation on the server: test_loss=0.0108, test_accuracy=0.9000\n",
            "INFO flower 2024-01-15 23:14:32,972 | server.py:116 | fit progress: (9, 0.01079030152099828, {'accuracy': 0.9, 'precisions': array([0.87131367, 0.83248731, 0.89940828, 0.80440771, 0.95818815,\n",
            "       0.99029126, 0.95633188, 0.97109827, 0.85239852, 0.97297297]), 'recalls': array([0.96153846, 0.99393939, 0.89411765, 0.96688742, 0.9751773 ,\n",
            "       0.49038462, 0.79347826, 0.97674419, 0.84      , 0.9442623 ]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 1063.4079776130002)\n",
            "DEBUG flower 2024-01-15 23:14:32,974 | server.py:165 | evaluate_round 9: strategy sampled 5 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30118)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0085, accuracy=0.8352\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31725)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0138, accuracy=0.7370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30118)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0134, accuracy=0.7444\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31725)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0149, accuracy=0.7704\n",
            "DEBUG flower 2024-01-15 23:14:39,824 | server.py:179 | evaluate_round 9 received 5 results and 0 failures\n",
            "Configuring round 10\n",
            "DEBUG flower 2024-01-15 23:14:39,825 | server.py:215 | fit_round 10: strategy sampled 3 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=32194)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0149, accuracy=0.7444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32194)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31725)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32286)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32194)\u001b[0m Client 2: training round complete, 31976 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31725)\u001b[0m Client 3: training round complete, 31976 examples processed\n",
            "DEBUG flower 2024-01-15 23:16:50,078 | server.py:229 | fit_round 10 received 3 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32286)\u001b[0m Client 0: training round complete, 31976 examples processed\n",
            "Evaluation on the server: test_loss=0.0060, test_accuracy=0.9510\n",
            "INFO flower 2024-01-15 23:16:52,072 | server.py:116 | fit progress: (10, 0.005984961841255426, {'accuracy': 0.951, 'precisions': array([0.98153846, 0.94186047, 0.96190476, 0.95862069, 0.96491228,\n",
            "       0.89333333, 0.89152542, 0.97707736, 0.93189964, 0.98634812]), 'recalls': array([0.94378698, 0.98181818, 0.89117647, 0.9205298 , 0.9751773 ,\n",
            "       0.96634615, 0.95289855, 0.99127907, 0.94545455, 0.94754098]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 1202.5079824160002)\n",
            "DEBUG flower 2024-01-15 23:16:52,073 | server.py:165 | evaluate_round 10: strategy sampled 5 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31725)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0108, accuracy=0.7815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=32286)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=32286)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=32286)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0092, accuracy=0.8352\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=32286)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0137, accuracy=0.7981\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31725)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0138, accuracy=0.7981\n",
            "DEBUG flower 2024-01-15 23:17:00,148 | server.py:179 | evaluate_round 10 received 5 results and 0 failures\n",
            "INFO flower 2024-01-15 23:17:00,148 | server.py:144 | FL finished in 1210.5839442349998\n",
            "INFO flower 2024-01-15 23:17:00,149 | app.py:180 | app_fit: losses_distributed [(1, 0.013975046541955735), (2, 0.0069624649705710235), (3, 0.008301367097430758), (4, 0.00874738695444884), (5, 0.008922572400834826), (6, 0.009793473051653968), (7, 0.011705032851960924), (8, 0.011827058659659492), (9, 0.013087526979269805), (10, 0.011636855337354871)]\n",
            "INFO flower 2024-01-15 23:17:00,149 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2024-01-15 23:17:00,149 | app.py:182 | app_fit: losses_centralized [(0, 0.07225578943888346), (1, 0.03873693352937698), (2, 0.01577845543126265), (3, 0.015060801784197489), (4, 0.013499050612250964), (5, 0.010043084785342217), (6, 0.009546019094685713), (7, 0.00818750384139518), (8, 0.009752940515056253), (9, 0.01079030152099828), (10, 0.005984961841255426)]\n",
            "INFO flower 2024-01-15 23:17:00,154 | app.py:183 | app_fit: metrics_centralized {'accuracy': [(0, 0.074), (1, 0.6523333333333333), (2, 0.816), (3, 0.8376666666666667), (4, 0.8593333333333333), (5, 0.8976666666666666), (6, 0.908), (7, 0.9293333333333333), (8, 0.918), (9, 0.9), (10, 0.951)], 'precisions': [(0, array([       nan,        nan, 0.0875    , 0.06282723, 0.07174173,\n",
            "              nan, 0.10454545,        nan,        nan,        nan])), (1, array([0.55734767, 0.71860465, 0.50591716, 0.47550432, 0.78658537,\n",
            "              nan, 0.51428571, 0.79948586, 0.61797753, 0.90272374])), (2, array([0.85294118, 0.85915493, 0.74688797, 0.81465517, 0.88709677,\n",
            "       0.79545455, 0.59833795, 0.94378698, 0.72847682, 0.9269103 ])), (3, array([0.77696078, 0.89820359, 0.83534137, 0.81443299, 0.90635452,\n",
            "       0.87162162, 0.66666667, 0.96978852, 0.74744027, 0.92282958])), (4, array([0.8490566 , 0.85522788, 0.78592375, 0.8089172 , 0.85230769,\n",
            "       0.93137255, 0.80442804, 0.96996997, 0.82720588, 0.95302013])), (5, array([0.90962099, 0.89664804, 0.90425532, 0.8370607 , 0.96428571,\n",
            "       0.86238532, 0.8028169 , 0.96242775, 0.83391003, 0.98606272])), (6, array([0.93865031, 0.90331492, 0.92387543, 0.85901639, 0.90163934,\n",
            "       0.86757991, 0.86590038, 0.93681319, 0.88086643, 0.97945205])), (7, array([0.91954023, 0.96923077, 0.9673913 , 0.89032258, 0.97535211,\n",
            "       0.824     , 0.85273973, 0.98507463, 0.91304348, 0.97368421])), (8, array([0.94153846, 0.93083573, 0.87134503, 0.93430657, 0.86687307,\n",
            "       0.92462312, 0.8277027 , 0.99076923, 0.91039427, 0.9862069 ])), (9, array([0.87131367, 0.83248731, 0.89940828, 0.80440771, 0.95818815,\n",
            "       0.99029126, 0.95633188, 0.97109827, 0.85239852, 0.97297297])), (10, array([0.98153846, 0.94186047, 0.96190476, 0.95862069, 0.96491228,\n",
            "       0.89333333, 0.89152542, 0.97707736, 0.93189964, 0.98634812]))], 'recalls': [(0, array([0.        , 0.        , 0.02058824, 0.0397351 , 0.63829787,\n",
            "       0.        , 0.08333333, 0.        , 0.        , 0.        ])), (1, array([0.92011834, 0.93636364, 0.50294118, 0.54635762, 0.91489362,\n",
            "       0.        , 0.32608696, 0.90406977, 0.4       , 0.76065574])), (2, array([0.85798817, 0.92424242, 0.52941176, 0.62582781, 0.9751773 ,\n",
            "       0.84134615, 0.7826087 , 0.92732558, 0.8       , 0.9147541 ])), (3, array([0.93786982, 0.90909091, 0.61176471, 0.78476821, 0.96099291,\n",
            "       0.62019231, 0.8115942 , 0.93313953, 0.79636364, 0.94098361])), (4, array([0.93195266, 0.96666667, 0.78823529, 0.8410596 , 0.9822695 ,\n",
            "       0.45673077, 0.78985507, 0.93895349, 0.81818182, 0.93114754])), (5, array([0.92307692, 0.97272727, 0.75      , 0.86754967, 0.95744681,\n",
            "       0.90384615, 0.82608696, 0.96802326, 0.87636364, 0.92786885])), (6, array([0.90532544, 0.99090909, 0.78529412, 0.86754967, 0.9751773 ,\n",
            "       0.91346154, 0.81884058, 0.99127907, 0.88727273, 0.93770492])), (7, array([0.94674556, 0.95454545, 0.78529412, 0.91390728, 0.9822695 ,\n",
            "       0.99038462, 0.90217391, 0.95930233, 0.91636364, 0.9704918 ])), (8, array([0.90532544, 0.97878788, 0.87647059, 0.84768212, 0.9929078 ,\n",
            "       0.88461538, 0.88768116, 0.93604651, 0.92363636, 0.93770492])), (9, array([0.96153846, 0.99393939, 0.89411765, 0.96688742, 0.9751773 ,\n",
            "       0.49038462, 0.79347826, 0.97674419, 0.84      , 0.9442623 ])), (10, array([0.94378698, 0.98181818, 0.89117647, 0.9205298 , 0.9751773 ,\n",
            "       0.96634615, 0.95289855, 0.99127907, 0.94545455, 0.94754098]))], 'class proportions': [(0, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (1, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (2, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (3, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (4, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (5, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (6, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (7, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (8, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (9, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (10, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667]))]}\n",
            "History (loss, distributed):\n",
            "\tround 1: 0.013975046541955735\n",
            "\tround 2: 0.0069624649705710235\n",
            "\tround 3: 0.008301367097430758\n",
            "\tround 4: 0.00874738695444884\n",
            "\tround 5: 0.008922572400834826\n",
            "\tround 6: 0.009793473051653968\n",
            "\tround 7: 0.011705032851960924\n",
            "\tround 8: 0.011827058659659492\n",
            "\tround 9: 0.013087526979269805\n",
            "\tround 10: 0.011636855337354871\n",
            "History (loss, centralized):\n",
            "\tround 0: 0.07225578943888346\n",
            "\tround 1: 0.03873693352937698\n",
            "\tround 2: 0.01577845543126265\n",
            "\tround 3: 0.015060801784197489\n",
            "\tround 4: 0.013499050612250964\n",
            "\tround 5: 0.010043084785342217\n",
            "\tround 6: 0.009546019094685713\n",
            "\tround 7: 0.00818750384139518\n",
            "\tround 8: 0.009752940515056253\n",
            "\tround 9: 0.01079030152099828\n",
            "\tround 10: 0.005984961841255426\n",
            "History (metrics, centralized):\n",
            "{'accuracy': [(0, 0.074), (1, 0.6523333333333333), (2, 0.816), (3, 0.8376666666666667), (4, 0.8593333333333333), (5, 0.8976666666666666), (6, 0.908), (7, 0.9293333333333333), (8, 0.918), (9, 0.9), (10, 0.951)], 'precisions': [(0, array([       nan,        nan, 0.0875    , 0.06282723, 0.07174173,\n",
            "              nan, 0.10454545,        nan,        nan,        nan])), (1, array([0.55734767, 0.71860465, 0.50591716, 0.47550432, 0.78658537,\n",
            "              nan, 0.51428571, 0.79948586, 0.61797753, 0.90272374])), (2, array([0.85294118, 0.85915493, 0.74688797, 0.81465517, 0.88709677,\n",
            "       0.79545455, 0.59833795, 0.94378698, 0.72847682, 0.9269103 ])), (3, array([0.77696078, 0.89820359, 0.83534137, 0.81443299, 0.90635452,\n",
            "       0.87162162, 0.66666667, 0.96978852, 0.74744027, 0.92282958])), (4, array([0.8490566 , 0.85522788, 0.78592375, 0.8089172 , 0.85230769,\n",
            "       0.93137255, 0.80442804, 0.96996997, 0.82720588, 0.95302013])), (5, array([0.90962099, 0.89664804, 0.90425532, 0.8370607 , 0.96428571,\n",
            "       0.86238532, 0.8028169 , 0.96242775, 0.83391003, 0.98606272])), (6, array([0.93865031, 0.90331492, 0.92387543, 0.85901639, 0.90163934,\n",
            "       0.86757991, 0.86590038, 0.93681319, 0.88086643, 0.97945205])), (7, array([0.91954023, 0.96923077, 0.9673913 , 0.89032258, 0.97535211,\n",
            "       0.824     , 0.85273973, 0.98507463, 0.91304348, 0.97368421])), (8, array([0.94153846, 0.93083573, 0.87134503, 0.93430657, 0.86687307,\n",
            "       0.92462312, 0.8277027 , 0.99076923, 0.91039427, 0.9862069 ])), (9, array([0.87131367, 0.83248731, 0.89940828, 0.80440771, 0.95818815,\n",
            "       0.99029126, 0.95633188, 0.97109827, 0.85239852, 0.97297297])), (10, array([0.98153846, 0.94186047, 0.96190476, 0.95862069, 0.96491228,\n",
            "       0.89333333, 0.89152542, 0.97707736, 0.93189964, 0.98634812]))], 'recalls': [(0, array([0.        , 0.        , 0.02058824, 0.0397351 , 0.63829787,\n",
            "       0.        , 0.08333333, 0.        , 0.        , 0.        ])), (1, array([0.92011834, 0.93636364, 0.50294118, 0.54635762, 0.91489362,\n",
            "       0.        , 0.32608696, 0.90406977, 0.4       , 0.76065574])), (2, array([0.85798817, 0.92424242, 0.52941176, 0.62582781, 0.9751773 ,\n",
            "       0.84134615, 0.7826087 , 0.92732558, 0.8       , 0.9147541 ])), (3, array([0.93786982, 0.90909091, 0.61176471, 0.78476821, 0.96099291,\n",
            "       0.62019231, 0.8115942 , 0.93313953, 0.79636364, 0.94098361])), (4, array([0.93195266, 0.96666667, 0.78823529, 0.8410596 , 0.9822695 ,\n",
            "       0.45673077, 0.78985507, 0.93895349, 0.81818182, 0.93114754])), (5, array([0.92307692, 0.97272727, 0.75      , 0.86754967, 0.95744681,\n",
            "       0.90384615, 0.82608696, 0.96802326, 0.87636364, 0.92786885])), (6, array([0.90532544, 0.99090909, 0.78529412, 0.86754967, 0.9751773 ,\n",
            "       0.91346154, 0.81884058, 0.99127907, 0.88727273, 0.93770492])), (7, array([0.94674556, 0.95454545, 0.78529412, 0.91390728, 0.9822695 ,\n",
            "       0.99038462, 0.90217391, 0.95930233, 0.91636364, 0.9704918 ])), (8, array([0.90532544, 0.97878788, 0.87647059, 0.84768212, 0.9929078 ,\n",
            "       0.88461538, 0.88768116, 0.93604651, 0.92363636, 0.93770492])), (9, array([0.96153846, 0.99393939, 0.89411765, 0.96688742, 0.9751773 ,\n",
            "       0.49038462, 0.79347826, 0.97674419, 0.84      , 0.9442623 ])), (10, array([0.94378698, 0.98181818, 0.89117647, 0.9205298 , 0.9751773 ,\n",
            "       0.96634615, 0.95289855, 0.99127907, 0.94545455, 0.94754098]))], 'class proportions': [(0, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (1, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (2, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (3, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (4, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (5, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (6, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (7, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (8, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (9, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (10, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667]))]}\n",
            "\u001b[0m\u001b[2m\u001b[36m(launch_and_evaluate pid=32941)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0107, accuracy=0.8167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --client-pool-size 10 --num-iterations 1000 --num-rounds 10 --val-ratio 0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oA-mDnFcWCnl",
        "outputId": "0c15fe4e-7a9c-4615-fa2c-2b8097e4e19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=1000.0, 10 classes): [270 268 279 253 277 275 254 277 274 273]\n",
            "Data partitioned across 10 clients, with IID alpha = 1000.0 and 0.1 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 10 client in the pool.\n",
            "FL round will proceed with 100.0% of clients sampled, at least 2.\n",
            "INFO flower 2024-01-15 23:17:29,453 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-15 23:17:33,663 | app.py:176 | Flower VCE: Ray initialized with resources: {'accelerator_type:V100': 1.0, 'GPU': 1.0, 'memory': 7117878068.0, 'CPU': 2.0, 'object_store_memory': 3558939033.0, 'node:172.28.0.12': 1.0}\n",
            "INFO flower 2024-01-15 23:17:33,663 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-15 23:17:33,664 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-15 23:17:37,576 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-15 23:17:37,576 | server.py:88 | Evaluating initial parameters\n",
            "/content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "  precisions = total_tp / total_pred\n",
            "Evaluation on the server: test_loss=0.0722, test_accuracy=0.1343\n",
            "INFO flower 2024-01-15 23:17:40,625 | server.py:91 | initial parameters (loss, other metrics): 0.07215377712249756, {'accuracy': 0.13433333333333333, 'precisions': array([       nan, 0.        ,        nan,        nan,        nan,\n",
            "       0.10347323,        nan, 0.16333809, 0.14485981,        nan]), 'recalls': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.6875    , 0.        , 0.66569767, 0.11272727, 0.        ]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}\n",
            "INFO flower 2024-01-15 23:17:40,626 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-15 23:17:40,626 | server.py:215 | fit_round 1: strategy sampled 3 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33269)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33268)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33400)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33269)\u001b[0m Client 0: training round complete, 31974 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33400)\u001b[0m Client 5: training round complete, 31974 examples processed\n",
            "DEBUG flower 2024-01-15 23:19:53,682 | server.py:229 | fit_round 1 received 3 results and 0 failures\n",
            "WARNING flower 2024-01-15 23:19:53,695 | fedavg.py:234 | No fit_metrics_aggregation_fn provided\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33268)\u001b[0m Client 3: training round complete, 31974 examples processed\n",
            "Evaluation on the server: test_loss=0.0587, test_accuracy=0.3230\n",
            "INFO flower 2024-01-15 23:19:55,720 | server.py:116 | fit progress: (1, 0.058672446529070534, {'accuracy': 0.323, 'precisions': array([0.38112306, 0.        , 0.57142857, 0.14744646, 0.60869565,\n",
            "       0.        , 0.23      , 0.81553398, 0.15      , 0.975     ]), 'recalls': array([0.94378698, 0.        , 0.07058824, 0.59271523, 0.89361702,\n",
            "       0.        , 0.25      , 0.24418605, 0.01090909, 0.12786885]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 135.09453594299976)\n",
            "DEBUG flower 2024-01-15 23:19:55,721 | server.py:165 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33268)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33268)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33268)\u001b[0m Client 0: evaluation on 270 examples: loss=0.0219, accuracy=0.3111\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33400)\u001b[0m Client 5: evaluation on 270 examples: loss=0.0199, accuracy=0.3481\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33400)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33400)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33268)\u001b[0m Client 1: evaluation on 270 examples: loss=0.0205, accuracy=0.3481\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33400)\u001b[0m Client 2: evaluation on 270 examples: loss=0.0210, accuracy=0.3444\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33268)\u001b[0m Client 6: evaluation on 270 examples: loss=0.0225, accuracy=0.3111\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33400)\u001b[0m Client 9: evaluation on 270 examples: loss=0.0215, accuracy=0.3037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33400)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33400)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33400)\u001b[0m Client 7: evaluation on 270 examples: loss=0.0196, accuracy=0.4111\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33268)\u001b[0m Client 4: evaluation on 270 examples: loss=0.0212, accuracy=0.2963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34062)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34062)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34062)\u001b[0m Client 3: evaluation on 270 examples: loss=0.0224, accuracy=0.2815\n",
            "DEBUG flower 2024-01-15 23:20:07,138 | server.py:179 | evaluate_round 1 received 10 results and 0 failures\n",
            "WARNING flower 2024-01-15 23:20:07,138 | fedavg.py:265 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-15 23:20:07,138 | server.py:215 | fit_round 2: strategy sampled 7 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34123)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34123)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34123)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34123)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34123)\u001b[0m Client 8: evaluation on 270 examples: loss=0.0199, accuracy=0.3630\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34123)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34062)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34216)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34268)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34062)\u001b[0m Client 9: training round complete, 31974 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34062)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34123)\u001b[0m Client 4: training round complete, 31974 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34123)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34216)\u001b[0m Client 5: training round complete, 31974 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34216)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34268)\u001b[0m Client 3: training round complete, 31974 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34062)\u001b[0m Client 8: training round complete, 31974 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34062)\u001b[0m E0115 23:25:04.518059364   34081 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34123)\u001b[0m Client 7: training round complete, 31974 examples processed\n",
            "DEBUG flower 2024-01-15 23:25:09,148 | server.py:229 | fit_round 2 received 7 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34216)\u001b[0m Client 6: training round complete, 31974 examples processed\n",
            "Evaluation on the server: test_loss=0.0265, test_accuracy=0.7413\n",
            "INFO flower 2024-01-15 23:25:11,664 | server.py:116 | fit progress: (2, 0.02649451701839765, {'accuracy': 0.7413333333333333, 'precisions': array([0.65495868, 0.78370787, 0.59640103, 0.68518519, 0.84713376,\n",
            "       0.94444444, 0.792     , 0.85025381, 0.67006803, 0.82840237]), 'recalls': array([0.93786982, 0.84545455, 0.68235294, 0.61258278, 0.94326241,\n",
            "       0.16346154, 0.35869565, 0.97383721, 0.71636364, 0.91803279]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 451.0379302849997)\n",
            "DEBUG flower 2024-01-15 23:25:11,664 | server.py:165 | evaluate_round 2: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34123)\u001b[0m Client 5: evaluation on 270 examples: loss=0.0133, accuracy=0.6519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34216)\u001b[0m Client 4: evaluation on 270 examples: loss=0.0131, accuracy=0.6556\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34123)\u001b[0m Client 9: evaluation on 270 examples: loss=0.0055, accuracy=0.8593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34216)\u001b[0m Client 6: evaluation on 270 examples: loss=0.0124, accuracy=0.6815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34123)\u001b[0m Client 7: evaluation on 270 examples: loss=0.0110, accuracy=0.7259\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34216)\u001b[0m Client 1: evaluation on 270 examples: loss=0.0119, accuracy=0.6815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34123)\u001b[0m Client 2: evaluation on 270 examples: loss=0.0120, accuracy=0.6778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34216)\u001b[0m Client 8: evaluation on 270 examples: loss=0.0086, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34216)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34216)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34216)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34216)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34123)\u001b[0m E0115 23:25:16.067267573   34142 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35667)\u001b[0m Client 0: evaluation on 270 examples: loss=0.0144, accuracy=0.6778\n",
            "DEBUG flower 2024-01-15 23:25:20,784 | server.py:179 | evaluate_round 2 received 10 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-15 23:25:20,785 | server.py:215 | fit_round 3: strategy sampled 3 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35706)\u001b[0m Client 3: evaluation on 270 examples: loss=0.0135, accuracy=0.7000\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35667)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35706)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35802)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35667)\u001b[0m Client 3: training round complete, 31974 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35706)\u001b[0m Client 4: training round complete, 31974 examples processed\n",
            "DEBUG flower 2024-01-15 23:27:28,909 | server.py:229 | fit_round 3 received 3 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35802)\u001b[0m Client 7: training round complete, 31974 examples processed\n",
            "Evaluation on the server: test_loss=0.0233, test_accuracy=0.8180\n",
            "INFO flower 2024-01-15 23:27:31,611 | server.py:116 | fit progress: (3, 0.02327257815748453, {'accuracy': 0.818, 'precisions': array([0.86646884, 0.89825581, 0.77737226, 0.76388889, 0.85126582,\n",
            "       0.79237288, 0.63225806, 0.90730337, 0.68787879, 0.97153025]), 'recalls': array([0.86390533, 0.93636364, 0.62647059, 0.54635762, 0.95390071,\n",
            "       0.89903846, 0.71014493, 0.93895349, 0.82545455, 0.89508197]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 590.984926653)\n",
            "DEBUG flower 2024-01-15 23:27:31,612 | server.py:165 | evaluate_round 3: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35802)\u001b[0m Client 3: evaluation on 270 examples: loss=0.0113, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35706)\u001b[0m Client 5: evaluation on 270 examples: loss=0.0114, accuracy=0.7519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35802)\u001b[0m Client 4: evaluation on 270 examples: loss=0.0099, accuracy=0.7852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35706)\u001b[0m Client 0: evaluation on 270 examples: loss=0.0163, accuracy=0.7556\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35802)\u001b[0m Client 9: evaluation on 270 examples: loss=0.0097, accuracy=0.8037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35802)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35802)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35706)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35706)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35706)\u001b[0m Client 8: evaluation on 270 examples: loss=0.0125, accuracy=0.7630\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35802)\u001b[0m Client 2: evaluation on 270 examples: loss=0.0109, accuracy=0.7519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35706)\u001b[0m Client 6: evaluation on 270 examples: loss=0.0135, accuracy=0.7481\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36447)\u001b[0m Client 7: evaluation on 270 examples: loss=0.0142, accuracy=0.7370\n",
            "DEBUG flower 2024-01-15 23:27:41,383 | server.py:179 | evaluate_round 3 received 10 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-15 23:27:41,384 | server.py:215 | fit_round 4: strategy sampled 5 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36450)\u001b[0m Client 1: evaluation on 270 examples: loss=0.0113, accuracy=0.7741\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36447)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36450)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36564)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36601)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\n",
            "Aborted!\n",
            "Exception ignored in: <module 'threading' from '/usr/lib/python3.10/threading.py'>\n",
            "*** SIGTERM received at time=1705361366 on cpu 0 ***\n",
            "PC: @     0x7b31d035e8bf  (unknown)  __write\n",
            "    @     0x7b31d028c520  (unknown)  (unknown)\n",
            "    @ ... and at least 12 more frames\n",
            "[2024-01-15 23:29:26,415 E 33068 33068] logging.cc:325: *** SIGTERM received at time=1705361366 on cpu 0 ***\n",
            "[2024-01-15 23:29:26,415 E 33068 33068] logging.cc:325: PC: @     0x7b31d035e8bf  (unknown)  __write\n",
            "[2024-01-15 23:29:26,415 E 33068 33068] logging.cc:325:     @     0x7b31d028c520  (unknown)  (unknown)\n",
            "[2024-01-15 23:29:26,415 E 33068 33068] logging.cc:325:     @ ... and at least 12 more frames\n",
            "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/worker.py\", line 1193, in sigterm_handler\n",
            "    sys.exit(signum)\n",
            "SystemExit: 15\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-cd6cddc306e2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python server.py --client-pool-size 10 --num-iterations 1000 --num-rounds 10 --val-ratio 0.1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    202\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_monitor_process\u001b[0;34m(parent_pty, epoll, p, cmd, update_stdin_widget)\u001b[0m\n\u001b[1;32m    232\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_poll_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_poll_process\u001b[0;34m(parent_pty, epoll, p, cmd, decoder, state)\u001b[0m\n\u001b[1;32m    280\u001b[0m   \u001b[0moutput_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m   \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m   \u001b[0minput_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --client-pool-size 25 --num-iterations 1000 --num-rounds 10 --val-ratio 0.1"
      ],
      "metadata": {
        "id": "rg2KGHJ7WCtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8i2FkYDBWCxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment 2: Changing the number of concurrent clients\n",
        "\n",
        "Total number of clients: 25\n",
        "\n",
        "Running FL with [2/25, 5/25, 10/25, 20/25] concurrent clients"
      ],
      "metadata": {
        "id": "tYP2DyRgWbpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --fraction-fit 0.08 --min-fit-clients 2 --client-pool-size 25 --num-iterations 1000 --num-rounds 10 --val-ratio 0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-1kKLl0Wqsj",
        "outputId": "c0f28f7b-668b-48ff-a5a4-f46a84e42d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=1000.0, 10 classes): [103  95 109  99 123 110 101 115 115 110]\n",
            "Data partitioned across 25 clients, with IID alpha = 1000.0 and 0.1 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 25 client in the pool.\n",
            "FL round will proceed with 8.0% of clients sampled, at least 2.\n",
            "INFO flower 2024-01-12 21:23:01,422 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-12 21:23:05,391 | app.py:176 | Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'CPU': 2.0, 'object_store_memory': 3597233356.0, 'GPU': 1.0, 'memory': 7194466715.0, 'accelerator_type:V100': 1.0}\n",
            "INFO flower 2024-01-12 21:23:05,392 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-12 21:23:05,392 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-12 21:23:08,180 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-12 21:23:08,180 | server.py:88 | Evaluating initial parameters\n",
            "Evaluation on the server: test_loss=0.0723, test_accuracy=0.1080\n",
            "INFO flower 2024-01-12 21:23:10,462 | server.py:91 | initial parameters (loss, other metrics): 0.07232879479726155, {'accuracy': 0.108}\n",
            "INFO flower 2024-01-12 21:23:10,462 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-12 21:23:10,462 | server.py:215 | fit_round 1: strategy sampled 2 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 3: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 21:24:31,713 | server.py:229 | fit_round 1 received 2 results and 0 failures\n",
            "WARNING flower 2024-01-12 21:24:31,723 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0508, test_accuracy=0.5310\n",
            "INFO flower 2024-01-12 21:24:34,148 | server.py:116 | fit progress: (1, 0.0508018311659495, {'accuracy': 0.531}, 83.68605990099968)\n",
            "DEBUG flower 2024-01-12 21:24:34,148 | server.py:165 | evaluate_round 1: strategy sampled 2 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102375)\u001b[0m Client 13: evaluation on 108 examples: loss=0.0352, accuracy=0.4907\n",
            "DEBUG flower 2024-01-12 21:24:34,406 | server.py:179 | evaluate_round 1 received 2 results and 0 failures\n",
            "WARNING flower 2024-01-12 21:24:34,406 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-12 21:24:34,406 | server.py:215 | fit_round 2: strategy sampled 2 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102374)\u001b[0m Client 15: evaluation on 108 examples: loss=0.0278, accuracy=0.5093\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 0: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 21:25:46,858 | server.py:229 | fit_round 2 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 8: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0365, test_accuracy=0.7403\n",
            "INFO flower 2024-01-12 21:25:48,635 | server.py:116 | fit progress: (2, 0.03645452072223027, {'accuracy': 0.7403333333333333}, 158.1730291319982)\n",
            "DEBUG flower 2024-01-12 21:25:48,635 | server.py:165 | evaluate_round 2: strategy sampled 2 clients (out of 25)\n",
            "DEBUG flower 2024-01-12 21:25:48,808 | server.py:179 | evaluate_round 2 received 2 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-12 21:25:48,808 | server.py:215 | fit_round 3: strategy sampled 2 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102375)\u001b[0m Client 24: evaluation on 108 examples: loss=0.0428, accuracy=0.6019\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102374)\u001b[0m Client 23: evaluation on 108 examples: loss=0.0108, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 21:27:05,407 | server.py:229 | fit_round 3 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 1: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0354, test_accuracy=0.7520\n",
            "INFO flower 2024-01-12 21:27:07,221 | server.py:116 | fit progress: (3, 0.03544182211657365, {'accuracy': 0.752}, 236.75832444299886)\n",
            "DEBUG flower 2024-01-12 21:27:07,221 | server.py:165 | evaluate_round 3: strategy sampled 2 clients (out of 25)\n",
            "DEBUG flower 2024-01-12 21:27:07,387 | server.py:179 | evaluate_round 3 received 2 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-12 21:27:07,387 | server.py:215 | fit_round 4: strategy sampled 2 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102375)\u001b[0m Client 24: evaluation on 108 examples: loss=0.0389, accuracy=0.6574\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102374)\u001b[0m Client 4: evaluation on 108 examples: loss=0.0477, accuracy=0.6759\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 11: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 21:28:21,333 | server.py:229 | fit_round 4 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 11: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0396, test_accuracy=0.7643\n",
            "INFO flower 2024-01-12 21:28:23,121 | server.py:116 | fit progress: (4, 0.0395765408774217, {'accuracy': 0.7643333333333333}, 312.65872612100065)\n",
            "DEBUG flower 2024-01-12 21:28:23,121 | server.py:165 | evaluate_round 4: strategy sampled 2 clients (out of 25)\n",
            "DEBUG flower 2024-01-12 21:28:23,292 | server.py:179 | evaluate_round 4 received 2 results and 0 failures\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-12 21:28:23,292 | server.py:215 | fit_round 5: strategy sampled 2 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102375)\u001b[0m Client 2: evaluation on 108 examples: loss=0.0408, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102374)\u001b[0m Client 17: evaluation on 108 examples: loss=0.0299, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 15: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 10: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 10: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 15: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 21:29:37,317 | server.py:229 | fit_round 5 received 2 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0350, test_accuracy=0.7850\n",
            "INFO flower 2024-01-12 21:29:39,139 | server.py:116 | fit progress: (5, 0.0349616357088089, {'accuracy': 0.785}, 388.67709130599906)\n",
            "DEBUG flower 2024-01-12 21:29:39,139 | server.py:165 | evaluate_round 5: strategy sampled 2 clients (out of 25)\n",
            "DEBUG flower 2024-01-12 21:29:39,307 | server.py:179 | evaluate_round 5 received 2 results and 0 failures\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-12 21:29:39,307 | server.py:215 | fit_round 6: strategy sampled 2 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102375)\u001b[0m Client 23: evaluation on 108 examples: loss=0.0093, accuracy=0.8519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102374)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0122, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 23: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 23: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 21:30:55,738 | server.py:229 | fit_round 6 received 2 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0786, test_accuracy=0.6307\n",
            "INFO flower 2024-01-12 21:30:57,584 | server.py:116 | fit progress: (6, 0.07864717521270116, {'accuracy': 0.6306666666666667}, 467.12192470199807)\n",
            "DEBUG flower 2024-01-12 21:30:57,584 | server.py:165 | evaluate_round 6: strategy sampled 2 clients (out of 25)\n",
            "DEBUG flower 2024-01-12 21:30:57,750 | server.py:179 | evaluate_round 6 received 2 results and 0 failures\n",
            "Configuring round 7\n",
            "DEBUG flower 2024-01-12 21:30:57,750 | server.py:215 | fit_round 7: strategy sampled 2 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102375)\u001b[0m Client 6: evaluation on 108 examples: loss=0.0428, accuracy=0.6019\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102374)\u001b[0m Client 24: evaluation on 108 examples: loss=0.0111, accuracy=0.9074\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 21: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 6: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 21:32:10,637 | server.py:229 | fit_round 7 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 21: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0363, test_accuracy=0.7637\n",
            "INFO flower 2024-01-12 21:32:12,895 | server.py:116 | fit progress: (7, 0.03627809812128544, {'accuracy': 0.7636666666666667}, 542.4329489669981)\n",
            "DEBUG flower 2024-01-12 21:32:12,895 | server.py:165 | evaluate_round 7: strategy sampled 2 clients (out of 25)\n",
            "DEBUG flower 2024-01-12 21:32:13,072 | server.py:179 | evaluate_round 7 received 2 results and 0 failures\n",
            "Configuring round 8\n",
            "DEBUG flower 2024-01-12 21:32:13,072 | server.py:215 | fit_round 8: strategy sampled 2 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102375)\u001b[0m Client 15: evaluation on 108 examples: loss=0.0193, accuracy=0.7222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102374)\u001b[0m Client 16: evaluation on 108 examples: loss=0.0236, accuracy=0.7407\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 10: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 6: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 21:33:27,219 | server.py:229 | fit_round 8 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 10: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0392, test_accuracy=0.7780\n",
            "INFO flower 2024-01-12 21:33:29,369 | server.py:116 | fit progress: (8, 0.03918866215646267, {'accuracy': 0.778}, 618.9064447689998)\n",
            "DEBUG flower 2024-01-12 21:33:29,369 | server.py:165 | evaluate_round 8: strategy sampled 2 clients (out of 25)\n",
            "DEBUG flower 2024-01-12 21:33:29,669 | server.py:179 | evaluate_round 8 received 2 results and 0 failures\n",
            "Configuring round 9\n",
            "DEBUG flower 2024-01-12 21:33:29,669 | server.py:215 | fit_round 9: strategy sampled 2 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102375)\u001b[0m Client 1: evaluation on 108 examples: loss=0.0327, accuracy=0.6574\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102374)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0477, accuracy=0.6204\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 24: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 21:34:43,208 | server.py:229 | fit_round 9 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 24: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0779, test_accuracy=0.6730\n",
            "INFO flower 2024-01-12 21:34:45,026 | server.py:116 | fit progress: (9, 0.0778984980781873, {'accuracy': 0.673}, 694.5633659470004)\n",
            "DEBUG flower 2024-01-12 21:34:45,026 | server.py:165 | evaluate_round 9: strategy sampled 2 clients (out of 25)\n",
            "DEBUG flower 2024-01-12 21:34:45,196 | server.py:179 | evaluate_round 9 received 2 results and 0 failures\n",
            "Configuring round 10\n",
            "DEBUG flower 2024-01-12 21:34:45,197 | server.py:215 | fit_round 10: strategy sampled 2 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102375)\u001b[0m Client 16: evaluation on 108 examples: loss=0.0566, accuracy=0.6204\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102374)\u001b[0m Client 21: evaluation on 108 examples: loss=0.0436, accuracy=0.6759\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 12: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102374)\u001b[0m Client 12: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 21:36:01,621 | server.py:229 | fit_round 10 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=102375)\u001b[0m Client 9: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0301, test_accuracy=0.7993\n",
            "INFO flower 2024-01-12 21:36:03,412 | server.py:116 | fit progress: (10, 0.03013719478622079, {'accuracy': 0.7993333333333333}, 772.9499817619981)\n",
            "DEBUG flower 2024-01-12 21:36:03,412 | server.py:165 | evaluate_round 10: strategy sampled 2 clients (out of 25)\n",
            "DEBUG flower 2024-01-12 21:36:03,573 | server.py:179 | evaluate_round 10 received 2 results and 0 failures\n",
            "INFO flower 2024-01-12 21:36:03,573 | server.py:144 | FL finished in 773.1106337950005\n",
            "INFO flower 2024-01-12 21:36:03,573 | app.py:180 | app_fit: losses_distributed [(1, 0.03150165522540057), (2, 0.026835849163708864), (3, 0.04328309054727907), (4, 0.03531578790258478), (5, 0.010764024806795296), (6, 0.026979092094633315), (7, 0.021422233018610213), (8, 0.040196484989590116), (9, 0.050096235893390795), (10, 0.011799252971454902)]\n",
            "INFO flower 2024-01-12 21:36:03,574 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2024-01-12 21:36:03,574 | app.py:182 | app_fit: losses_centralized [(0, 0.07232879479726155), (1, 0.0508018311659495), (2, 0.03645452072223027), (3, 0.03544182211657365), (4, 0.0395765408774217), (5, 0.0349616357088089), (6, 0.07864717521270116), (7, 0.03627809812128544), (8, 0.03918866215646267), (9, 0.0778984980781873), (10, 0.03013719478622079)]\n",
            "INFO flower 2024-01-12 21:36:03,574 | app.py:183 | app_fit: metrics_centralized {'accuracy': [(0, 0.108), (1, 0.531), (2, 0.7403333333333333), (3, 0.752), (4, 0.7643333333333333), (5, 0.785), (6, 0.6306666666666667), (7, 0.7636666666666667), (8, 0.778), (9, 0.673), (10, 0.7993333333333333)]}\n",
            "History (loss, distributed):\n",
            "\tround 1: 0.03150165522540057\n",
            "\tround 2: 0.026835849163708864\n",
            "\tround 3: 0.04328309054727907\n",
            "\tround 4: 0.03531578790258478\n",
            "\tround 5: 0.010764024806795296\n",
            "\tround 6: 0.026979092094633315\n",
            "\tround 7: 0.021422233018610213\n",
            "\tround 8: 0.040196484989590116\n",
            "\tround 9: 0.050096235893390795\n",
            "\tround 10: 0.011799252971454902\n",
            "History (loss, centralized):\n",
            "\tround 0: 0.07232879479726155\n",
            "\tround 1: 0.0508018311659495\n",
            "\tround 2: 0.03645452072223027\n",
            "\tround 3: 0.03544182211657365\n",
            "\tround 4: 0.0395765408774217\n",
            "\tround 5: 0.0349616357088089\n",
            "\tround 6: 0.07864717521270116\n",
            "\tround 7: 0.03627809812128544\n",
            "\tround 8: 0.03918866215646267\n",
            "\tround 9: 0.0778984980781873\n",
            "\tround 10: 0.03013719478622079\n",
            "History (metrics, centralized):\n",
            "{'accuracy': [(0, 0.108), (1, 0.531), (2, 0.7403333333333333), (3, 0.752), (4, 0.7643333333333333), (5, 0.785), (6, 0.6306666666666667), (7, 0.7636666666666667), (8, 0.778), (9, 0.673), (10, 0.7993333333333333)]}\n",
            "\u001b[0m\u001b[2m\u001b[36m(launch_and_evaluate pid=102375)\u001b[0m Client 23: evaluation on 108 examples: loss=0.0082, accuracy=0.8704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=102374)\u001b[0m Client 3: evaluation on 108 examples: loss=0.0154, accuracy=0.7778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --fraction-fit 0.20 --min-fit-clients 5 --client-pool-size 25 --num-iterations 1000 --num-rounds 10 --val-ratio 0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQufGpE0XAH-",
        "outputId": "efde7a88-016f-4dcf-aa76-46e130993245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=1000.0, 10 classes): [102  92 119 102 115 110 103 119 113 105]\n",
            "Data partitioned across 25 clients, with IID alpha = 1000.0 and 0.1 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 25 client in the pool.\n",
            "FL round will proceed with 20.0% of clients sampled, at least 5.\n",
            "INFO flower 2024-01-12 21:36:27,415 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-12 21:36:31,520 | app.py:176 | Flower VCE: Ray initialized with resources: {'memory': 7200581223.0, 'object_store_memory': 3600290611.0, 'CPU': 2.0, 'node:172.28.0.12': 1.0, 'accelerator_type:V100': 1.0, 'GPU': 1.0}\n",
            "INFO flower 2024-01-12 21:36:31,520 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-12 21:36:31,522 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-12 21:36:34,462 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-12 21:36:34,462 | server.py:88 | Evaluating initial parameters\n",
            "Evaluation on the server: test_loss=0.0722, test_accuracy=0.0823\n",
            "INFO flower 2024-01-12 21:36:37,536 | server.py:91 | initial parameters (loss, other metrics): 0.07221586068471272, {'accuracy': 0.08233333333333333}\n",
            "INFO flower 2024-01-12 21:36:37,536 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-12 21:36:37,536 | server.py:215 | fit_round 1: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=106093)\u001b[0m Client 14: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=106094)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=106218)\u001b[0m Client 22: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=106217)\u001b[0m Client 20: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=106093)\u001b[0m Client 14: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=106093)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=106094)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=106218)\u001b[0m Client 22: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=106217)\u001b[0m Client 20: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 21:40:06,729 | server.py:229 | fit_round 1 received 5 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=106093)\u001b[0m Client 4: training round complete, 31360 examples processed\n",
            "WARNING flower 2024-01-12 21:40:06,753 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "Evaluation on the server: test_loss=0.0539, test_accuracy=0.5103\n",
            "INFO flower 2024-01-12 21:40:08,515 | server.py:116 | fit progress: (1, 0.05394023180007935, {'accuracy': 0.5103333333333333}, 210.9790524609998)\n",
            "DEBUG flower 2024-01-12 21:40:08,515 | server.py:165 | evaluate_round 1: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=106218)\u001b[0m E0112 21:40:08.545169245  106283 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=106093)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0324, accuracy=0.4537\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=106093)\u001b[0m Client 20: evaluation on 108 examples: loss=0.0343, accuracy=0.5833\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=106093)\u001b[0m Client 1: evaluation on 108 examples: loss=0.0307, accuracy=0.5278\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=106218)\u001b[0m Client 18: evaluation on 108 examples: loss=0.0390, accuracy=0.4630\n",
            "DEBUG flower 2024-01-12 21:40:13,540 | server.py:179 | evaluate_round 1 received 5 results and 0 failures\n",
            "WARNING flower 2024-01-12 21:40:13,540 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-12 21:40:13,541 | server.py:215 | fit_round 2: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=107183)\u001b[0m Client 21: evaluation on 108 examples: loss=0.0222, accuracy=0.5833\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=107183)\u001b[0m Client 21: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=106218)\u001b[0m Client 10: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=107268)\u001b[0m Client 15: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=107267)\u001b[0m Client 22: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=106218)\u001b[0m Client 10: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=106218)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=107183)\u001b[0m Client 21: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=107268)\u001b[0m Client 15: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=107267)\u001b[0m Client 22: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 21:43:42,540 | server.py:229 | fit_round 2 received 5 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=106218)\u001b[0m Client 1: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0453, test_accuracy=0.7063\n",
            "INFO flower 2024-01-12 21:43:44,384 | server.py:116 | fit progress: (2, 0.04528161867459615, {'accuracy': 0.7063333333333334}, 426.84756451499925)\n",
            "DEBUG flower 2024-01-12 21:43:44,384 | server.py:165 | evaluate_round 2: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=107267)\u001b[0m E0112 21:43:44.407966905  107327 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=106218)\u001b[0m Client 5: evaluation on 108 examples: loss=0.0296, accuracy=0.5463\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=106218)\u001b[0m Client 12: evaluation on 108 examples: loss=0.0233, accuracy=0.6389\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=106218)\u001b[0m Client 9: evaluation on 108 examples: loss=0.0351, accuracy=0.6759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=107267)\u001b[0m Client 17: evaluation on 108 examples: loss=0.0318, accuracy=0.6389\n",
            "DEBUG flower 2024-01-12 21:43:48,838 | server.py:179 | evaluate_round 2 received 5 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-12 21:43:48,838 | server.py:215 | fit_round 3: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=108230)\u001b[0m Client 1: evaluation on 108 examples: loss=0.0291, accuracy=0.6944\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=107267)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=108230)\u001b[0m Client 22: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=108312)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=108313)\u001b[0m Client 21: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=108230)\u001b[0m Client 22: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=108230)\u001b[0m Client 15: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=107267)\u001b[0m Client 9: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=108313)\u001b[0m Client 21: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=108312)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 21:47:16,296 | server.py:229 | fit_round 3 received 5 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=108230)\u001b[0m Client 15: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0443, test_accuracy=0.7140\n",
            "INFO flower 2024-01-12 21:47:18,706 | server.py:116 | fit progress: (3, 0.04425165061155955, {'accuracy': 0.714}, 641.1694751920004)\n",
            "DEBUG flower 2024-01-12 21:47:18,706 | server.py:165 | evaluate_round 3: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=108312)\u001b[0m E0112 21:47:18.740445060  108370 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=108230)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0345, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=108230)\u001b[0m Client 14: evaluation on 108 examples: loss=0.0387, accuracy=0.6481\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=108230)\u001b[0m Client 9: evaluation on 108 examples: loss=0.0345, accuracy=0.6574\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=108312)\u001b[0m Client 11: evaluation on 108 examples: loss=0.0358, accuracy=0.5741\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=108230)\u001b[0m E0112 21:47:21.242734862  108293 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "DEBUG flower 2024-01-12 21:47:24,286 | server.py:179 | evaluate_round 3 received 5 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-12 21:47:24,286 | server.py:215 | fit_round 4: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=109272)\u001b[0m Client 0: evaluation on 108 examples: loss=0.0204, accuracy=0.6944\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=109272)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=109271)\u001b[0m Client 11: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=109361)\u001b[0m Client 21: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=109363)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=109272)\u001b[0m Client 1: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=109272)\u001b[0m Client 15: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=109271)\u001b[0m Client 11: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=109363)\u001b[0m Client 3: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=109361)\u001b[0m Client 21: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=109272)\u001b[0m Client 15: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 21:50:54,019 | server.py:229 | fit_round 4 received 5 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0312, test_accuracy=0.7553\n",
            "INFO flower 2024-01-12 21:50:56,263 | server.py:116 | fit progress: (4, 0.031167345295349758, {'accuracy': 0.7553333333333333}, 858.7272227909998)\n",
            "DEBUG flower 2024-01-12 21:50:56,264 | server.py:165 | evaluate_round 4: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=109272)\u001b[0m Client 2: evaluation on 108 examples: loss=0.0258, accuracy=0.6852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=109361)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0239, accuracy=0.6944\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=109272)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0183, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=109361)\u001b[0m Client 17: evaluation on 108 examples: loss=0.0321, accuracy=0.6852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=109272)\u001b[0m E0112 21:50:58.521432689  109291 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "DEBUG flower 2024-01-12 21:51:02,257 | server.py:179 | evaluate_round 4 received 5 results and 0 failures\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-12 21:51:02,257 | server.py:215 | fit_round 5: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=110338)\u001b[0m Client 5: evaluation on 108 examples: loss=0.0240, accuracy=0.6296\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=110338)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=110337)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=110424)\u001b[0m Client 10: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=110423)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=110338)\u001b[0m Client 6: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=110338)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=110423)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=110337)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=110424)\u001b[0m Client 10: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 21:54:30,845 | server.py:229 | fit_round 5 received 5 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=110338)\u001b[0m Client 7: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0289, test_accuracy=0.7833\n",
            "INFO flower 2024-01-12 21:54:32,878 | server.py:116 | fit progress: (5, 0.028929758911331496, {'accuracy': 0.7833333333333333}, 1075.341582825)\n",
            "DEBUG flower 2024-01-12 21:54:32,878 | server.py:165 | evaluate_round 5: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=110338)\u001b[0m Client 18: evaluation on 108 examples: loss=0.0125, accuracy=0.7130\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=110424)\u001b[0m Client 2: evaluation on 108 examples: loss=0.0253, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=110338)\u001b[0m Client 15: evaluation on 108 examples: loss=0.0102, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=110424)\u001b[0m Client 9: evaluation on 108 examples: loss=0.0119, accuracy=0.8241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=110338)\u001b[0m E0112 21:54:35.477895036  110375 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "DEBUG flower 2024-01-12 21:54:39,491 | server.py:179 | evaluate_round 5 received 5 results and 0 failures\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-12 21:54:39,491 | server.py:215 | fit_round 6: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=111412)\u001b[0m Client 23: evaluation on 108 examples: loss=0.0217, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=111412)\u001b[0m Client 20: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=111411)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=111502)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=111545)\u001b[0m Client 14: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=111412)\u001b[0m Client 20: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=111412)\u001b[0m Client 24: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=111411)\u001b[0m Client 2: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=111502)\u001b[0m Client 6: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=111545)\u001b[0m Client 14: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 21:58:08,973 | server.py:229 | fit_round 6 received 5 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=111412)\u001b[0m Client 24: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0323, test_accuracy=0.7640\n",
            "INFO flower 2024-01-12 21:58:11,311 | server.py:116 | fit progress: (6, 0.0323159834643205, {'accuracy': 0.764}, 1293.774652553002)\n",
            "DEBUG flower 2024-01-12 21:58:11,311 | server.py:165 | evaluate_round 6: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=111412)\u001b[0m Client 11: evaluation on 108 examples: loss=0.0276, accuracy=0.6852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=111545)\u001b[0m Client 9: evaluation on 108 examples: loss=0.0194, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=111412)\u001b[0m Client 23: evaluation on 108 examples: loss=0.0163, accuracy=0.8426\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=111545)\u001b[0m Client 2: evaluation on 108 examples: loss=0.0497, accuracy=0.6759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=111412)\u001b[0m E0112 21:58:13.919851024  111427 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "DEBUG flower 2024-01-12 21:58:17,219 | server.py:179 | evaluate_round 6 received 5 results and 0 failures\n",
            "Configuring round 7\n",
            "DEBUG flower 2024-01-12 21:58:17,219 | server.py:215 | fit_round 7: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=112543)\u001b[0m Client 13: evaluation on 108 examples: loss=0.0358, accuracy=0.6204\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=112543)\u001b[0m Client 12: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=112542)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=112629)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=112680)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=112543)\u001b[0m Client 12: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=112543)\u001b[0m Client 18: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=112629)\u001b[0m Client 0: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=112542)\u001b[0m Client 9: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=112680)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 22:01:48,225 | server.py:229 | fit_round 7 received 5 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=112543)\u001b[0m Client 18: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0235, test_accuracy=0.8113\n",
            "INFO flower 2024-01-12 22:01:50,086 | server.py:116 | fit progress: (7, 0.02348505282153686, {'accuracy': 0.8113333333333334}, 1512.5503537770019)\n",
            "DEBUG flower 2024-01-12 22:01:50,087 | server.py:165 | evaluate_round 7: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=112680)\u001b[0m E0112 22:01:50.119608218  112722 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=112543)\u001b[0m Client 9: evaluation on 108 examples: loss=0.0113, accuracy=0.8333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=112543)\u001b[0m Client 13: evaluation on 108 examples: loss=0.0200, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=112543)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0137, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=112680)\u001b[0m Client 5: evaluation on 108 examples: loss=0.0299, accuracy=0.7222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=112543)\u001b[0m E0112 22:01:52.688631808  112559 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=113670)\u001b[0m Client 6: evaluation on 108 examples: loss=0.0187, accuracy=0.8333\n",
            "DEBUG flower 2024-01-12 22:01:56,879 | server.py:179 | evaluate_round 7 received 5 results and 0 failures\n",
            "Configuring round 8\n",
            "DEBUG flower 2024-01-12 22:01:56,880 | server.py:215 | fit_round 8: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=113670)\u001b[0m Client 10: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=113669)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=113763)\u001b[0m Client 19: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=113814)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=113670)\u001b[0m Client 10: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=113670)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=113669)\u001b[0m Client 0: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=113763)\u001b[0m Client 19: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=113814)\u001b[0m Client 4: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 22:05:26,335 | server.py:229 | fit_round 8 received 5 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=113670)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0248, test_accuracy=0.8240\n",
            "INFO flower 2024-01-12 22:05:28,444 | server.py:116 | fit progress: (8, 0.024770476780831815, {'accuracy': 0.824}, 1730.9077689410005)\n",
            "DEBUG flower 2024-01-12 22:05:28,444 | server.py:165 | evaluate_round 8: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=113670)\u001b[0m Client 16: evaluation on 108 examples: loss=0.0239, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=113814)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0102, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=113670)\u001b[0m Client 0: evaluation on 108 examples: loss=0.0290, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=113814)\u001b[0m Client 23: evaluation on 108 examples: loss=0.0270, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=113670)\u001b[0m E0112 22:05:30.632989994  113697 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "DEBUG flower 2024-01-12 22:05:34,797 | server.py:179 | evaluate_round 8 received 5 results and 0 failures\n",
            "Configuring round 9\n",
            "DEBUG flower 2024-01-12 22:05:34,797 | server.py:215 | fit_round 9: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=114800)\u001b[0m Client 6: evaluation on 108 examples: loss=0.0338, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=114800)\u001b[0m Client 15: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=114799)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=114892)\u001b[0m Client 20: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=114941)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=114800)\u001b[0m Client 15: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=114800)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=114799)\u001b[0m Client 1: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=114941)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=114892)\u001b[0m Client 20: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 22:09:07,161 | server.py:229 | fit_round 9 received 5 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=114800)\u001b[0m Client 9: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0221, test_accuracy=0.8320\n",
            "INFO flower 2024-01-12 22:09:09,411 | server.py:116 | fit progress: (9, 0.02213471749300758, {'accuracy': 0.832}, 1951.8750174220004)\n",
            "DEBUG flower 2024-01-12 22:09:09,411 | server.py:165 | evaluate_round 9: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=114800)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0322, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=114892)\u001b[0m Client 0: evaluation on 108 examples: loss=0.0195, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=114892)\u001b[0m Client 14: evaluation on 108 examples: loss=0.0154, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=114800)\u001b[0m Client 13: evaluation on 108 examples: loss=0.0177, accuracy=0.7407\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=114800)\u001b[0m E0112 22:09:11.813058131  114813 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "DEBUG flower 2024-01-12 22:09:15,817 | server.py:179 | evaluate_round 9 received 5 results and 0 failures\n",
            "Configuring round 10\n",
            "DEBUG flower 2024-01-12 22:09:15,817 | server.py:215 | fit_round 10: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=115943)\u001b[0m Client 16: evaluation on 108 examples: loss=0.0266, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=115943)\u001b[0m Client 22: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=115942)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=116036)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=116037)\u001b[0m Client 11: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=115943)\u001b[0m Client 22: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=115943)\u001b[0m Client 23: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=115942)\u001b[0m Client 4: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=116036)\u001b[0m Client 1: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=116037)\u001b[0m Client 11: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 22:12:45,168 | server.py:229 | fit_round 10 received 5 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=115943)\u001b[0m Client 23: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0289, test_accuracy=0.8000\n",
            "INFO flower 2024-01-12 22:12:47,622 | server.py:116 | fit progress: (10, 0.028867913992454607, {'accuracy': 0.8}, 2170.0858552870013)\n",
            "DEBUG flower 2024-01-12 22:12:47,622 | server.py:165 | evaluate_round 10: strategy sampled 5 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=115943)\u001b[0m Client 16: evaluation on 108 examples: loss=0.0372, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=116036)\u001b[0m Client 6: evaluation on 108 examples: loss=0.0246, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=115943)\u001b[0m Client 21: evaluation on 108 examples: loss=0.0209, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=116036)\u001b[0m Client 8: evaluation on 108 examples: loss=0.0312, accuracy=0.8241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=115943)\u001b[0m E0112 22:12:50.033695583  115976 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "DEBUG flower 2024-01-12 22:12:53,390 | server.py:179 | evaluate_round 10 received 5 results and 0 failures\n",
            "INFO flower 2024-01-12 22:12:53,390 | server.py:144 | FL finished in 2175.853629628\n",
            "INFO flower 2024-01-12 22:12:53,390 | app.py:180 | app_fit: losses_distributed [(1, 0.03171255963819998), (2, 0.029785100563808724), (3, 0.03277008550034629), (4, 0.02480711296752647), (5, 0.01632298109708009), (6, 0.029749898667688724), (7, 0.01871629202807391), (8, 0.024782206338864785), (9, 0.022271174330402304), (10, 0.03356522652837965)]\n",
            "INFO flower 2024-01-12 22:12:53,391 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2024-01-12 22:12:53,391 | app.py:182 | app_fit: losses_centralized [(0, 0.07221586068471272), (1, 0.05394023180007935), (2, 0.04528161867459615), (3, 0.04425165061155955), (4, 0.031167345295349758), (5, 0.028929758911331496), (6, 0.0323159834643205), (7, 0.02348505282153686), (8, 0.024770476780831815), (9, 0.02213471749300758), (10, 0.028867913992454607)]\n",
            "INFO flower 2024-01-12 22:12:53,391 | app.py:183 | app_fit: metrics_centralized {'accuracy': [(0, 0.08233333333333333), (1, 0.5103333333333333), (2, 0.7063333333333334), (3, 0.714), (4, 0.7553333333333333), (5, 0.7833333333333333), (6, 0.764), (7, 0.8113333333333334), (8, 0.824), (9, 0.832), (10, 0.8)]}\n",
            "History (loss, distributed):\n",
            "\tround 1: 0.03171255963819998\n",
            "\tround 2: 0.029785100563808724\n",
            "\tround 3: 0.03277008550034629\n",
            "\tround 4: 0.02480711296752647\n",
            "\tround 5: 0.01632298109708009\n",
            "\tround 6: 0.029749898667688724\n",
            "\tround 7: 0.01871629202807391\n",
            "\tround 8: 0.024782206338864785\n",
            "\tround 9: 0.022271174330402304\n",
            "\tround 10: 0.03356522652837965\n",
            "History (loss, centralized):\n",
            "\tround 0: 0.07221586068471272\n",
            "\tround 1: 0.05394023180007935\n",
            "\tround 2: 0.04528161867459615\n",
            "\tround 3: 0.04425165061155955\n",
            "\tround 4: 0.031167345295349758\n",
            "\tround 5: 0.028929758911331496\n",
            "\tround 6: 0.0323159834643205\n",
            "\tround 7: 0.02348505282153686\n",
            "\tround 8: 0.024770476780831815\n",
            "\tround 9: 0.02213471749300758\n",
            "\tround 10: 0.028867913992454607\n",
            "History (metrics, centralized):\n",
            "{'accuracy': [(0, 0.08233333333333333), (1, 0.5103333333333333), (2, 0.7063333333333334), (3, 0.714), (4, 0.7553333333333333), (5, 0.7833333333333333), (6, 0.764), (7, 0.8113333333333334), (8, 0.824), (9, 0.832), (10, 0.8)]}\n",
            "\u001b[0m\u001b[2m\u001b[36m(launch_and_evaluate pid=117043)\u001b[0m Client 17: evaluation on 108 examples: loss=0.0539, accuracy=0.7037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --fraction-fit 0.40 --min-fit-clients 10 --client-pool-size 25 --num-iterations 1000 --num-rounds 10 --val-ratio 0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Anmzx-zeXAKT",
        "outputId": "d1829b5b-501a-4eaf-bf90-8463f962a1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=1000.0, 10 classes): [104  96 121 102 114 106  96 123 103 115]\n",
            "Data partitioned across 25 clients, with IID alpha = 1000.0 and 0.1 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 25 client in the pool.\n",
            "FL round will proceed with 40.0% of clients sampled, at least 10.\n",
            "INFO flower 2024-01-12 22:13:22,932 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-12 22:13:27,371 | app.py:176 | Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'accelerator_type:V100': 1.0, 'GPU': 1.0, 'CPU': 2.0, 'memory': 7263139431.0, 'object_store_memory': 3631569715.0}\n",
            "INFO flower 2024-01-12 22:13:27,372 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-12 22:13:27,372 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-12 22:13:31,166 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-12 22:13:31,166 | server.py:88 | Evaluating initial parameters\n",
            "Evaluation on the server: test_loss=0.0721, test_accuracy=0.1110\n",
            "INFO flower 2024-01-12 22:13:33,461 | server.py:91 | initial parameters (loss, other metrics): 0.0720986521244049, {'accuracy': 0.111}\n",
            "INFO flower 2024-01-12 22:13:33,461 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-12 22:13:33,461 | server.py:215 | fit_round 1: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117351)\u001b[0m Client 22: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117352)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117495)\u001b[0m Client 21: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117496)\u001b[0m Client 15: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117351)\u001b[0m Client 22: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117351)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117496)\u001b[0m Client 15: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117496)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117352)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117352)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117495)\u001b[0m Client 21: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117495)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117351)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117351)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117496)\u001b[0m Client 0: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117496)\u001b[0m Client 12: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117352)\u001b[0m Client 2: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117495)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117351)\u001b[0m Client 8: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 22:20:10,949 | server.py:229 | fit_round 1 received 10 results and 0 failures\n",
            "WARNING flower 2024-01-12 22:20:11,008 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117496)\u001b[0m Client 12: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0504, test_accuracy=0.5030\n",
            "INFO flower 2024-01-12 22:20:12,872 | server.py:116 | fit progress: (1, 0.05036309125026067, {'accuracy': 0.503}, 399.4108857490028)\n",
            "DEBUG flower 2024-01-12 22:20:12,872 | server.py:165 | evaluate_round 1: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=117496)\u001b[0m E0112 22:20:12.894415921  117562 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=117351)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0189, accuracy=0.5463\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=117351)\u001b[0m Client 18: evaluation on 108 examples: loss=0.0214, accuracy=0.5463\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=117351)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0318, accuracy=0.5370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=117351)\u001b[0m Client 16: evaluation on 108 examples: loss=0.0340, accuracy=0.4907\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=117496)\u001b[0m Client 1: evaluation on 108 examples: loss=0.0285, accuracy=0.4444\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=117351)\u001b[0m Client 5: evaluation on 108 examples: loss=0.0353, accuracy=0.4630\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=117496)\u001b[0m Client 21: evaluation on 108 examples: loss=0.0240, accuracy=0.5278\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=117351)\u001b[0m Client 9: evaluation on 108 examples: loss=0.0259, accuracy=0.5278\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=119348)\u001b[0m Client 12: evaluation on 108 examples: loss=0.0269, accuracy=0.4722\n",
            "DEBUG flower 2024-01-12 22:20:20,708 | server.py:179 | evaluate_round 1 received 10 results and 0 failures\n",
            "WARNING flower 2024-01-12 22:20:20,709 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-12 22:20:20,709 | server.py:215 | fit_round 2: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=119383)\u001b[0m Client 13: evaluation on 108 examples: loss=0.0371, accuracy=0.3981\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119383)\u001b[0m Client 12: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119348)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119477)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119521)\u001b[0m Client 18: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119383)\u001b[0m Client 12: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119383)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119348)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119348)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119477)\u001b[0m Client 1: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119477)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119521)\u001b[0m Client 18: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119521)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119383)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119383)\u001b[0m Client 15: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119348)\u001b[0m Client 8: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119348)\u001b[0m Client 16: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119477)\u001b[0m Client 3: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119477)\u001b[0m E0112 22:25:48.568340664  119522 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119521)\u001b[0m Client 7: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119383)\u001b[0m Client 15: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 22:26:57,737 | server.py:229 | fit_round 2 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=119348)\u001b[0m Client 16: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0281, test_accuracy=0.7520\n",
            "INFO flower 2024-01-12 22:26:59,574 | server.py:116 | fit progress: (2, 0.02807268998026848, {'accuracy': 0.752}, 806.1130865500018)\n",
            "DEBUG flower 2024-01-12 22:26:59,574 | server.py:165 | evaluate_round 2: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=119383)\u001b[0m Client 16: evaluation on 108 examples: loss=0.0185, accuracy=0.7407\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=119348)\u001b[0m Client 15: evaluation on 108 examples: loss=0.0306, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=119383)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0107, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=119348)\u001b[0m Client 21: evaluation on 108 examples: loss=0.0182, accuracy=0.7407\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=119383)\u001b[0m Client 8: evaluation on 108 examples: loss=0.0235, accuracy=0.6944\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=119348)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0198, accuracy=0.7130\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=119383)\u001b[0m Client 24: evaluation on 108 examples: loss=0.0370, accuracy=0.7222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=119348)\u001b[0m Client 14: evaluation on 108 examples: loss=0.0109, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=119383)\u001b[0m Client 10: evaluation on 108 examples: loss=0.0181, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=119383)\u001b[0m E0112 22:27:02.218076911  119446 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=119348)\u001b[0m E0112 22:27:02.324090081  119386 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "DEBUG flower 2024-01-12 22:27:06,922 | server.py:179 | evaluate_round 2 received 10 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-12 22:27:06,922 | server.py:215 | fit_round 3: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=121362)\u001b[0m Client 18: evaluation on 108 examples: loss=0.0113, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121362)\u001b[0m Client 16: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121361)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121460)\u001b[0m Client 23: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121461)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121362)\u001b[0m Client 16: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121362)\u001b[0m Client 19: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121361)\u001b[0m Client 6: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121461)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121361)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121461)\u001b[0m Client 18: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121460)\u001b[0m Client 23: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121460)\u001b[0m Client 10: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121362)\u001b[0m Client 19: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121362)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121460)\u001b[0m Client 10: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121460)\u001b[0m Client 21: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121461)\u001b[0m Client 18: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121361)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121361)\u001b[0m E0112 22:32:31.449008011  121398 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121362)\u001b[0m Client 4: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 22:33:45,601 | server.py:229 | fit_round 3 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=121460)\u001b[0m Client 21: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0247, test_accuracy=0.7770\n",
            "INFO flower 2024-01-12 22:33:47,431 | server.py:116 | fit progress: (3, 0.02467045416434606, {'accuracy': 0.777}, 1213.9700696400032)\n",
            "DEBUG flower 2024-01-12 22:33:47,431 | server.py:165 | evaluate_round 3: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=121362)\u001b[0m Client 1: evaluation on 108 examples: loss=0.0211, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=121460)\u001b[0m Client 10: evaluation on 108 examples: loss=0.0199, accuracy=0.7222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=121460)\u001b[0m Client 20: evaluation on 108 examples: loss=0.0167, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=121362)\u001b[0m Client 16: evaluation on 108 examples: loss=0.0178, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=121460)\u001b[0m Client 0: evaluation on 108 examples: loss=0.0188, accuracy=0.6944\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=121362)\u001b[0m Client 5: evaluation on 108 examples: loss=0.0149, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=121460)\u001b[0m Client 6: evaluation on 108 examples: loss=0.0297, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=121362)\u001b[0m Client 11: evaluation on 108 examples: loss=0.0248, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=121460)\u001b[0m Client 21: evaluation on 108 examples: loss=0.0176, accuracy=0.8056\n",
            "DEBUG flower 2024-01-12 22:33:52,933 | server.py:179 | evaluate_round 3 received 10 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-12 22:33:52,933 | server.py:215 | fit_round 4: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=123324)\u001b[0m Client 4: evaluation on 108 examples: loss=0.0195, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123324)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123323)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123419)\u001b[0m Client 15: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123420)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123324)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123324)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123323)\u001b[0m Client 1: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123323)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123420)\u001b[0m Client 8: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123420)\u001b[0m Client 20: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123419)\u001b[0m Client 15: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123419)\u001b[0m Client 16: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123324)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123324)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123323)\u001b[0m Client 9: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123323)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123419)\u001b[0m Client 16: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123420)\u001b[0m Client 20: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123419)\u001b[0m E0112 22:39:21.653049398  123430 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123420)\u001b[0m E0112 22:39:22.075799521  123483 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123324)\u001b[0m Client 2: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 22:40:36,821 | server.py:229 | fit_round 4 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=123323)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0250, test_accuracy=0.8087\n",
            "INFO flower 2024-01-12 22:40:38,681 | server.py:116 | fit progress: (4, 0.025009041460851828, {'accuracy': 0.8086666666666666}, 1625.219694481002)\n",
            "DEBUG flower 2024-01-12 22:40:38,681 | server.py:165 | evaluate_round 4: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=123324)\u001b[0m Client 15: evaluation on 108 examples: loss=0.0294, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=123323)\u001b[0m Client 2: evaluation on 108 examples: loss=0.0074, accuracy=0.8241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=123324)\u001b[0m Client 24: evaluation on 108 examples: loss=0.0320, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=123323)\u001b[0m Client 20: evaluation on 108 examples: loss=0.0179, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=123324)\u001b[0m Client 3: evaluation on 108 examples: loss=0.0128, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=123323)\u001b[0m Client 11: evaluation on 108 examples: loss=0.0211, accuracy=0.8426\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=123324)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0176, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=123323)\u001b[0m Client 10: evaluation on 108 examples: loss=0.0195, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=123324)\u001b[0m Client 13: evaluation on 108 examples: loss=0.0273, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=123324)\u001b[0m E0112 22:40:41.682075051  123346 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "DEBUG flower 2024-01-12 22:40:44,051 | server.py:179 | evaluate_round 4 received 10 results and 0 failures\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-12 22:40:44,051 | server.py:215 | fit_round 5: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=125302)\u001b[0m Client 4: evaluation on 108 examples: loss=0.0194, accuracy=0.8704\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125302)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125301)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125394)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125438)\u001b[0m Client 24: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125302)\u001b[0m Client 8: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125302)\u001b[0m Client 23: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125301)\u001b[0m Client 4: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125301)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125394)\u001b[0m Client 1: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125394)\u001b[0m Client 22: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125438)\u001b[0m Client 24: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125438)\u001b[0m Client 12: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125302)\u001b[0m Client 23: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125302)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125301)\u001b[0m Client 3: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125301)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125394)\u001b[0m Client 22: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125438)\u001b[0m Client 12: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125302)\u001b[0m Client 0: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 22:47:28,658 | server.py:229 | fit_round 5 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=125301)\u001b[0m Client 7: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0254, test_accuracy=0.7953\n",
            "INFO flower 2024-01-12 22:47:30,524 | server.py:116 | fit progress: (5, 0.025374730989336968, {'accuracy': 0.7953333333333333}, 2037.0627131180008)\n",
            "DEBUG flower 2024-01-12 22:47:30,524 | server.py:165 | evaluate_round 5: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=125302)\u001b[0m Client 1: evaluation on 108 examples: loss=0.0273, accuracy=0.6852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=125301)\u001b[0m Client 14: evaluation on 108 examples: loss=0.0109, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=125302)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0115, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=125301)\u001b[0m Client 11: evaluation on 108 examples: loss=0.0264, accuracy=0.8241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=125302)\u001b[0m Client 10: evaluation on 108 examples: loss=0.0224, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=125301)\u001b[0m Client 3: evaluation on 108 examples: loss=0.0159, accuracy=0.7407\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=125302)\u001b[0m Client 5: evaluation on 108 examples: loss=0.0150, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=125301)\u001b[0m Client 12: evaluation on 108 examples: loss=0.0143, accuracy=0.8426\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=125302)\u001b[0m Client 4: evaluation on 108 examples: loss=0.0209, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=125302)\u001b[0m E0112 22:47:33.633940355  125317 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "DEBUG flower 2024-01-12 22:47:36,092 | server.py:179 | evaluate_round 5 received 10 results and 0 failures\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-12 22:47:36,092 | server.py:215 | fit_round 6: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=127308)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0190, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127308)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127306)\u001b[0m Client 22: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127405)\u001b[0m Client 11: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127407)\u001b[0m Client 16: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127308)\u001b[0m Client 3: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127308)\u001b[0m Client 21: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127306)\u001b[0m Client 22: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127306)\u001b[0m Client 20: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127405)\u001b[0m Client 11: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127405)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127407)\u001b[0m Client 16: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127407)\u001b[0m Client 10: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127308)\u001b[0m Client 21: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127308)\u001b[0m Client 23: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127405)\u001b[0m Client 7: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127405)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127306)\u001b[0m Client 20: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127407)\u001b[0m Client 10: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127407)\u001b[0m E0112 22:53:08.948726890  127468 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127308)\u001b[0m Client 23: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 22:54:20,751 | server.py:229 | fit_round 6 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=127405)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0228, test_accuracy=0.8257\n",
            "INFO flower 2024-01-12 22:54:22,965 | server.py:116 | fit progress: (6, 0.022835416801273822, {'accuracy': 0.8256666666666667}, 2449.504188269002)\n",
            "DEBUG flower 2024-01-12 22:54:22,965 | server.py:165 | evaluate_round 6: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=127308)\u001b[0m Client 3: evaluation on 108 examples: loss=0.0208, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=127405)\u001b[0m Client 8: evaluation on 108 examples: loss=0.0304, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=127308)\u001b[0m Client 14: evaluation on 108 examples: loss=0.0107, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=127405)\u001b[0m Client 7: evaluation on 108 examples: loss=0.0104, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=127308)\u001b[0m Client 23: evaluation on 108 examples: loss=0.0126, accuracy=0.8241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=127405)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0141, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=127308)\u001b[0m Client 1: evaluation on 108 examples: loss=0.0315, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=127405)\u001b[0m Client 20: evaluation on 108 examples: loss=0.0164, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=127308)\u001b[0m Client 10: evaluation on 108 examples: loss=0.0297, accuracy=0.7315\n",
            "DEBUG flower 2024-01-12 22:54:28,503 | server.py:179 | evaluate_round 6 received 10 results and 0 failures\n",
            "Configuring round 7\n",
            "DEBUG flower 2024-01-12 22:54:28,503 | server.py:215 | fit_round 7: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=129294)\u001b[0m Client 0: evaluation on 108 examples: loss=0.0187, accuracy=0.7130\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129294)\u001b[0m Client 24: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129293)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129391)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129423)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129294)\u001b[0m Client 24: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129294)\u001b[0m Client 14: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129293)\u001b[0m Client 6: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129293)\u001b[0m Client 16: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129391)\u001b[0m Client 0: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129391)\u001b[0m Client 18: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129423)\u001b[0m Client 3: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129423)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129294)\u001b[0m Client 14: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129294)\u001b[0m Client 10: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129293)\u001b[0m Client 16: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129293)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129391)\u001b[0m Client 18: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129423)\u001b[0m Client 9: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129423)\u001b[0m E0112 23:00:00.880100342  129485 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "DEBUG flower 2024-01-12 23:01:13,446 | server.py:229 | fit_round 7 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129294)\u001b[0m Client 10: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=129293)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0190, test_accuracy=0.8340\n",
            "INFO flower 2024-01-12 23:01:15,936 | server.py:116 | fit progress: (7, 0.019017913430929186, {'accuracy': 0.834}, 2862.475432911)\n",
            "DEBUG flower 2024-01-12 23:01:15,937 | server.py:165 | evaluate_round 7: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=129294)\u001b[0m Client 0: evaluation on 108 examples: loss=0.0120, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=129293)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0105, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=129294)\u001b[0m Client 18: evaluation on 108 examples: loss=0.0087, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=129293)\u001b[0m Client 14: evaluation on 108 examples: loss=0.0096, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=129294)\u001b[0m Client 10: evaluation on 108 examples: loss=0.0184, accuracy=0.7130\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=129293)\u001b[0m Client 23: evaluation on 108 examples: loss=0.0127, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=129294)\u001b[0m Client 3: evaluation on 108 examples: loss=0.0112, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=129293)\u001b[0m Client 17: evaluation on 108 examples: loss=0.0178, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=129294)\u001b[0m Client 21: evaluation on 108 examples: loss=0.0154, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=129294)\u001b[0m E0112 23:01:19.199105339  129331 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "DEBUG flower 2024-01-12 23:01:21,653 | server.py:179 | evaluate_round 7 received 10 results and 0 failures\n",
            "Configuring round 8\n",
            "DEBUG flower 2024-01-12 23:01:21,654 | server.py:215 | fit_round 8: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=131308)\u001b[0m Client 12: evaluation on 108 examples: loss=0.0102, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131308)\u001b[0m Client 19: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131307)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131398)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131399)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131308)\u001b[0m Client 19: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131308)\u001b[0m Client 12: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131307)\u001b[0m Client 1: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131307)\u001b[0m Client 11: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131398)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131398)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131399)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131399)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131308)\u001b[0m Client 12: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131308)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131307)\u001b[0m Client 11: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131398)\u001b[0m Client 4: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131307)\u001b[0m Client 14: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131398)\u001b[0m E0112 23:06:51.432920255  131456 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131399)\u001b[0m Client 8: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131399)\u001b[0m E0112 23:06:55.782438976  131432 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131308)\u001b[0m Client 3: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 23:08:09,193 | server.py:229 | fit_round 8 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131307)\u001b[0m Client 14: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0192, test_accuracy=0.8460\n",
            "INFO flower 2024-01-12 23:08:11,077 | server.py:116 | fit progress: (8, 0.019200655601918696, {'accuracy': 0.846}, 3277.6162260029996)\n",
            "DEBUG flower 2024-01-12 23:08:11,078 | server.py:165 | evaluate_round 8: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131307)\u001b[0m E0112 23:08:11.103348400  131356 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=131308)\u001b[0m Client 2: evaluation on 108 examples: loss=0.0075, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=131308)\u001b[0m Client 16: evaluation on 108 examples: loss=0.0183, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=131308)\u001b[0m Client 18: evaluation on 108 examples: loss=0.0092, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=131307)\u001b[0m Client 21: evaluation on 108 examples: loss=0.0125, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=131308)\u001b[0m Client 4: evaluation on 108 examples: loss=0.0175, accuracy=0.8426\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=131307)\u001b[0m Client 23: evaluation on 108 examples: loss=0.0175, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=131308)\u001b[0m Client 7: evaluation on 108 examples: loss=0.0163, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=131308)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0129, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=131307)\u001b[0m Client 24: evaluation on 108 examples: loss=0.0294, accuracy=0.7870\n",
            "DEBUG flower 2024-01-12 23:08:18,102 | server.py:179 | evaluate_round 8 received 10 results and 0 failures\n",
            "Configuring round 9\n",
            "DEBUG flower 2024-01-12 23:08:18,103 | server.py:215 | fit_round 9: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=133303)\u001b[0m Client 15: evaluation on 108 examples: loss=0.0222, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=133303)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131308)\u001b[0m Client 23: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=133402)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=133456)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131308)\u001b[0m Client 23: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131308)\u001b[0m Client 12: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=133303)\u001b[0m Client 4: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=133303)\u001b[0m Client 21: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=133456)\u001b[0m Client 0: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=133456)\u001b[0m Client 19: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=133402)\u001b[0m Client 6: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=133402)\u001b[0m Client 16: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131308)\u001b[0m Client 12: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131308)\u001b[0m Client 24: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=133303)\u001b[0m Client 21: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=133303)\u001b[0m Client 10: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=133456)\u001b[0m Client 19: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=133402)\u001b[0m Client 16: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=131308)\u001b[0m Client 24: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=133303)\u001b[0m Client 10: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 23:15:04,841 | server.py:229 | fit_round 9 received 10 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0211, test_accuracy=0.8293\n",
            "INFO flower 2024-01-12 23:15:07,492 | server.py:116 | fit progress: (9, 0.021138408904274306, {'accuracy': 0.8293333333333334}, 3694.031374028)\n",
            "DEBUG flower 2024-01-12 23:15:07,493 | server.py:165 | evaluate_round 9: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=131308)\u001b[0m Client 7: evaluation on 108 examples: loss=0.0117, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=133303)\u001b[0m Client 8: evaluation on 108 examples: loss=0.0433, accuracy=0.6944\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=131308)\u001b[0m Client 23: evaluation on 108 examples: loss=0.0047, accuracy=0.8889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=133303)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0161, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=131308)\u001b[0m Client 13: evaluation on 108 examples: loss=0.0329, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=133303)\u001b[0m Client 24: evaluation on 108 examples: loss=0.0171, accuracy=0.8796\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=131308)\u001b[0m Client 20: evaluation on 108 examples: loss=0.0206, accuracy=0.7407\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=133303)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0121, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=131308)\u001b[0m Client 14: evaluation on 108 examples: loss=0.0125, accuracy=0.7222\n",
            "DEBUG flower 2024-01-12 23:15:13,236 | server.py:179 | evaluate_round 9 received 10 results and 0 failures\n",
            "Configuring round 10\n",
            "DEBUG flower 2024-01-12 23:15:13,236 | server.py:215 | fit_round 10: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=135334)\u001b[0m Client 12: evaluation on 108 examples: loss=0.0165, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135334)\u001b[0m Client 18: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135333)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135428)\u001b[0m Client 14: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135429)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135334)\u001b[0m Client 18: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135334)\u001b[0m Client 15: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135333)\u001b[0m Client 6: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135428)\u001b[0m Client 14: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135333)\u001b[0m Client 24: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135428)\u001b[0m Client 12: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135429)\u001b[0m Client 0: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135429)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135334)\u001b[0m Client 15: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135334)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135333)\u001b[0m Client 24: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135333)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135428)\u001b[0m Client 12: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135429)\u001b[0m Client 2: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135428)\u001b[0m E0112 23:20:50.798816682  135438 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135334)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-12 23:22:07,374 | server.py:229 | fit_round 10 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135333)\u001b[0m Client 7: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0161, test_accuracy=0.8570\n",
            "INFO flower 2024-01-12 23:22:09,279 | server.py:116 | fit progress: (10, 0.01612861920396487, {'accuracy': 0.857}, 4115.817706659)\n",
            "DEBUG flower 2024-01-12 23:22:09,279 | server.py:165 | evaluate_round 10: strategy sampled 10 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=135333)\u001b[0m E0112 23:22:09.295251883  135396 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=135334)\u001b[0m Client 10: evaluation on 108 examples: loss=0.0261, accuracy=0.7407\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=135334)\u001b[0m Client 7: evaluation on 108 examples: loss=0.0103, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=135334)\u001b[0m Client 6: evaluation on 108 examples: loss=0.0225, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=135334)\u001b[0m Client 4: evaluation on 108 examples: loss=0.0147, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=135333)\u001b[0m Client 9: evaluation on 108 examples: loss=0.0345, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=135334)\u001b[0m Client 11: evaluation on 108 examples: loss=0.0209, accuracy=0.8704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=135333)\u001b[0m Client 18: evaluation on 108 examples: loss=0.0095, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=135334)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0137, accuracy=0.8241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=135334)\u001b[0m E0112 23:22:12.421303266  135405 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=137358)\u001b[0m Client 13: evaluation on 108 examples: loss=0.0282, accuracy=0.7407\n",
            "DEBUG flower 2024-01-12 23:22:17,841 | server.py:179 | evaluate_round 10 received 10 results and 0 failures\n",
            "INFO flower 2024-01-12 23:22:17,841 | server.py:144 | FL finished in 4124.379951379\n",
            "INFO flower 2024-01-12 23:22:17,842 | app.py:180 | app_fit: losses_distributed [(1, 0.028382219981264185), (2, 0.019856406969052776), (3, 0.020073272674172013), (4, 0.02045348037586168), (5, 0.018370727656616105), (6, 0.019522883618871372), (7, 0.01265926970065468), (8, 0.01633544343834122), (9, 0.01874653635960486), (10, 0.019260692141122287)]\n",
            "INFO flower 2024-01-12 23:22:17,842 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2024-01-12 23:22:17,842 | app.py:182 | app_fit: losses_centralized [(0, 0.0720986521244049), (1, 0.05036309125026067), (2, 0.02807268998026848), (3, 0.02467045416434606), (4, 0.025009041460851828), (5, 0.025374730989336968), (6, 0.022835416801273822), (7, 0.019017913430929186), (8, 0.019200655601918696), (9, 0.021138408904274306), (10, 0.01612861920396487)]\n",
            "INFO flower 2024-01-12 23:22:17,842 | app.py:183 | app_fit: metrics_centralized {'accuracy': [(0, 0.111), (1, 0.503), (2, 0.752), (3, 0.777), (4, 0.8086666666666666), (5, 0.7953333333333333), (6, 0.8256666666666667), (7, 0.834), (8, 0.846), (9, 0.8293333333333334), (10, 0.857)]}\n",
            "History (loss, distributed):\n",
            "\tround 1: 0.028382219981264185\n",
            "\tround 2: 0.019856406969052776\n",
            "\tround 3: 0.020073272674172013\n",
            "\tround 4: 0.02045348037586168\n",
            "\tround 5: 0.018370727656616105\n",
            "\tround 6: 0.019522883618871372\n",
            "\tround 7: 0.01265926970065468\n",
            "\tround 8: 0.01633544343834122\n",
            "\tround 9: 0.01874653635960486\n",
            "\tround 10: 0.019260692141122287\n",
            "History (loss, centralized):\n",
            "\tround 0: 0.0720986521244049\n",
            "\tround 1: 0.05036309125026067\n",
            "\tround 2: 0.02807268998026848\n",
            "\tround 3: 0.02467045416434606\n",
            "\tround 4: 0.025009041460851828\n",
            "\tround 5: 0.025374730989336968\n",
            "\tround 6: 0.022835416801273822\n",
            "\tround 7: 0.019017913430929186\n",
            "\tround 8: 0.019200655601918696\n",
            "\tround 9: 0.021138408904274306\n",
            "\tround 10: 0.01612861920396487\n",
            "History (metrics, centralized):\n",
            "{'accuracy': [(0, 0.111), (1, 0.503), (2, 0.752), (3, 0.777), (4, 0.8086666666666666), (5, 0.7953333333333333), (6, 0.8256666666666667), (7, 0.834), (8, 0.846), (9, 0.8293333333333334), (10, 0.857)]}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=137357)\u001b[0m Client 21: evaluation on 108 examples: loss=0.0122, accuracy=0.8056\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --fraction-fit 0.80 --min-fit-clients 20 --client-pool-size 25 --num-iterations 1000 --num-rounds 10 --val-ratio 0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19s6NjR6XANV",
        "outputId": "0a1399d6-a46b-4ed3-dd38-81005648a33a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=1000.0, 10 classes): [103  88 114 114 117 110  98 124 114  98]\n",
            "Data partitioned across 25 clients, with IID alpha = 1000.0 and 0.1 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 25 client in the pool.\n",
            "FL round will proceed with 80.0% of clients sampled, at least 20.\n",
            "INFO flower 2024-01-13 11:10:12,358 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-13 11:10:16,511 | app.py:176 | Flower VCE: Ray initialized with resources: {'memory': 6987322983.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0, 'object_store_memory': 3493661491.0, 'accelerator_type:V100': 1.0, 'CPU': 2.0}\n",
            "INFO flower 2024-01-13 11:10:16,512 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-13 11:10:16,512 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-13 11:10:19,754 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-13 11:10:19,756 | server.py:88 | Evaluating initial parameters\n",
            "Evaluation on the server: test_loss=0.0722, test_accuracy=0.0863\n",
            "INFO flower 2024-01-13 11:10:23,025 | server.py:91 | initial parameters (loss, other metrics): 0.07224025885264079, {'accuracy': 0.08633333333333333}\n",
            "INFO flower 2024-01-13 11:10:23,025 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-13 11:10:23,025 | server.py:215 | fit_round 1: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3018)\u001b[0m Client 10: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3017)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3145)\u001b[0m Client 22: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3142)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3018)\u001b[0m Client 10: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3018)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3145)\u001b[0m Client 22: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3145)\u001b[0m Client 11: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3017)\u001b[0m Client 1: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3017)\u001b[0m Client 12: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3142)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3142)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3018)\u001b[0m Client 6: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3018)\u001b[0m Client 18: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3145)\u001b[0m Client 11: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3145)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3017)\u001b[0m Client 12: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3017)\u001b[0m Client 16: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3142)\u001b[0m Client 4: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3142)\u001b[0m Client 14: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3018)\u001b[0m Client 18: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3018)\u001b[0m Client 19: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3017)\u001b[0m Client 16: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3017)\u001b[0m Client 20: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3145)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3145)\u001b[0m Client 24: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3142)\u001b[0m Client 14: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3142)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3018)\u001b[0m Client 19: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3018)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3017)\u001b[0m Client 20: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3017)\u001b[0m Client 23: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3145)\u001b[0m Client 24: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3145)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3142)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3142)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3018)\u001b[0m Client 7: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3145)\u001b[0m Client 2: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3017)\u001b[0m Client 23: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3142)\u001b[0m Client 8: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-13 11:24:50,062 | server.py:229 | fit_round 1 received 20 results and 0 failures\n",
            "WARNING flower 2024-01-13 11:24:50,149 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "Evaluation on the server: test_loss=0.0559, test_accuracy=0.4223\n",
            "INFO flower 2024-01-13 11:24:52,311 | server.py:116 | fit progress: (1, 0.05592773207028707, {'accuracy': 0.42233333333333334}, 869.2858446390001)\n",
            "DEBUG flower 2024-01-13 11:24:52,311 | server.py:165 | evaluate_round 1: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3017)\u001b[0m Client 2: evaluation on 108 examples: loss=0.0315, accuracy=0.4352\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3142)\u001b[0m Client 4: evaluation on 108 examples: loss=0.0384, accuracy=0.3704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3017)\u001b[0m Client 8: evaluation on 108 examples: loss=0.0374, accuracy=0.3796\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3142)\u001b[0m Client 7: evaluation on 108 examples: loss=0.0393, accuracy=0.4259\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3017)\u001b[0m Client 14: evaluation on 108 examples: loss=0.0350, accuracy=0.4074\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3142)\u001b[0m Client 15: evaluation on 108 examples: loss=0.0340, accuracy=0.3519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3017)\u001b[0m Client 24: evaluation on 108 examples: loss=0.0196, accuracy=0.5370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3142)\u001b[0m Client 21: evaluation on 108 examples: loss=0.0332, accuracy=0.5278\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3017)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0304, accuracy=0.4722\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3142)\u001b[0m Client 6: evaluation on 108 examples: loss=0.0364, accuracy=0.3981\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3017)\u001b[0m Client 11: evaluation on 108 examples: loss=0.0313, accuracy=0.3704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3142)\u001b[0m Client 10: evaluation on 108 examples: loss=0.0352, accuracy=0.3796\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3142)\u001b[0m Client 20: evaluation on 108 examples: loss=0.0331, accuracy=0.4352\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3017)\u001b[0m Client 18: evaluation on 108 examples: loss=0.0322, accuracy=0.4259\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3142)\u001b[0m Client 5: evaluation on 108 examples: loss=0.0331, accuracy=0.3241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3017)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0328, accuracy=0.4722\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3142)\u001b[0m Client 17: evaluation on 108 examples: loss=0.0315, accuracy=0.3796\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3017)\u001b[0m Client 1: evaluation on 108 examples: loss=0.0302, accuracy=0.4537\n",
            "DEBUG flower 2024-01-13 11:25:03,189 | server.py:179 | evaluate_round 1 received 20 results and 0 failures\n",
            "WARNING flower 2024-01-13 11:25:03,189 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-13 11:25:03,189 | server.py:215 | fit_round 2: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7104)\u001b[0m Client 0: evaluation on 108 examples: loss=0.0303, accuracy=0.4907\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7105)\u001b[0m Client 9: evaluation on 108 examples: loss=0.0342, accuracy=0.3889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7104)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7105)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7229)\u001b[0m Client 24: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Client 20: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7105)\u001b[0m Client 1: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7105)\u001b[0m Client 18: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7104)\u001b[0m Client 7: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7104)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Client 20: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Client 21: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7229)\u001b[0m Client 24: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7229)\u001b[0m Client 14: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7105)\u001b[0m Client 18: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7105)\u001b[0m Client 16: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7104)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7104)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7229)\u001b[0m Client 14: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Client 21: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7229)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7105)\u001b[0m Client 16: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7105)\u001b[0m Client 23: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7104)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7104)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7229)\u001b[0m Client 0: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7229)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7105)\u001b[0m Client 23: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7105)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7104)\u001b[0m Client 4: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7104)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7229)\u001b[0m Client 6: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7229)\u001b[0m Client 11: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Client 9: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Client 10: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7105)\u001b[0m Client 2: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7104)\u001b[0m Client 3: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7228)\u001b[0m Client 10: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-13 11:39:29,176 | server.py:229 | fit_round 2 received 20 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7229)\u001b[0m Client 11: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0295, test_accuracy=0.7237\n",
            "INFO flower 2024-01-13 11:39:31,222 | server.py:116 | fit progress: (2, 0.029510234733422597, {'accuracy': 0.7236666666666667}, 1748.196667584)\n",
            "DEBUG flower 2024-01-13 11:39:31,222 | server.py:165 | evaluate_round 2: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7228)\u001b[0m Client 20: evaluation on 108 examples: loss=0.0124, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7229)\u001b[0m Client 9: evaluation on 108 examples: loss=0.0196, accuracy=0.7407\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7228)\u001b[0m Client 7: evaluation on 108 examples: loss=0.0276, accuracy=0.6759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7229)\u001b[0m Client 10: evaluation on 108 examples: loss=0.0204, accuracy=0.6667\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7228)\u001b[0m Client 6: evaluation on 108 examples: loss=0.0180, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7229)\u001b[0m Client 3: evaluation on 108 examples: loss=0.0217, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7228)\u001b[0m Client 16: evaluation on 108 examples: loss=0.0268, accuracy=0.7130\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7229)\u001b[0m Client 17: evaluation on 108 examples: loss=0.0200, accuracy=0.6667\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7228)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0124, accuracy=0.7222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7229)\u001b[0m Client 2: evaluation on 108 examples: loss=0.0130, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7228)\u001b[0m Client 14: evaluation on 108 examples: loss=0.0152, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7229)\u001b[0m Client 21: evaluation on 108 examples: loss=0.0231, accuracy=0.7130\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7228)\u001b[0m Client 5: evaluation on 108 examples: loss=0.0167, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7229)\u001b[0m Client 24: evaluation on 108 examples: loss=0.0092, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7228)\u001b[0m Client 1: evaluation on 108 examples: loss=0.0185, accuracy=0.6944\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7229)\u001b[0m Client 8: evaluation on 108 examples: loss=0.0263, accuracy=0.6204\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7228)\u001b[0m Client 4: evaluation on 108 examples: loss=0.0242, accuracy=0.6759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7229)\u001b[0m Client 0: evaluation on 108 examples: loss=0.0094, accuracy=0.7778\n",
            "DEBUG flower 2024-01-13 11:39:41,930 | server.py:179 | evaluate_round 2 received 20 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-13 11:39:41,931 | server.py:215 | fit_round 3: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11177)\u001b[0m Client 13: evaluation on 108 examples: loss=0.0114, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11178)\u001b[0m Client 18: evaluation on 108 examples: loss=0.0157, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11177)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11178)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11306)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11305)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11177)\u001b[0m Client 4: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11177)\u001b[0m Client 23: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11178)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11178)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11306)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11306)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11305)\u001b[0m Client 9: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11305)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11177)\u001b[0m Client 23: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11177)\u001b[0m Client 15: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11178)\u001b[0m Client 8: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11178)\u001b[0m Client 20: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11306)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11306)\u001b[0m Client 19: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11305)\u001b[0m Client 6: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11305)\u001b[0m Client 10: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11177)\u001b[0m Client 15: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11177)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11178)\u001b[0m Client 20: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11178)\u001b[0m Client 16: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11306)\u001b[0m Client 19: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11306)\u001b[0m Client 14: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11305)\u001b[0m Client 10: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11305)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11177)\u001b[0m Client 0: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11177)\u001b[0m Client 21: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11178)\u001b[0m Client 16: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11178)\u001b[0m Client 24: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11306)\u001b[0m Client 14: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11306)\u001b[0m Client 12: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11305)\u001b[0m Client 7: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11305)\u001b[0m Client 22: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11177)\u001b[0m Client 21: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11178)\u001b[0m Client 24: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11306)\u001b[0m Client 12: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-13 11:54:04,487 | server.py:229 | fit_round 3 received 20 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11305)\u001b[0m Client 22: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0258, test_accuracy=0.7760\n",
            "INFO flower 2024-01-13 11:54:07,199 | server.py:116 | fit progress: (3, 0.025786146566271782, {'accuracy': 0.776}, 2624.17380625)\n",
            "DEBUG flower 2024-01-13 11:54:07,199 | server.py:165 | evaluate_round 3: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11305)\u001b[0m Client 2: evaluation on 108 examples: loss=0.0105, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11306)\u001b[0m Client 20: evaluation on 108 examples: loss=0.0126, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11305)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0130, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11306)\u001b[0m Client 21: evaluation on 108 examples: loss=0.0208, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11305)\u001b[0m Client 11: evaluation on 108 examples: loss=0.0127, accuracy=0.7407\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11306)\u001b[0m Client 8: evaluation on 108 examples: loss=0.0244, accuracy=0.6667\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11305)\u001b[0m Client 13: evaluation on 108 examples: loss=0.0107, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11306)\u001b[0m Client 17: evaluation on 108 examples: loss=0.0200, accuracy=0.6852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11305)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0134, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11306)\u001b[0m Client 9: evaluation on 108 examples: loss=0.0182, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11305)\u001b[0m Client 1: evaluation on 108 examples: loss=0.0177, accuracy=0.7130\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11306)\u001b[0m Client 7: evaluation on 108 examples: loss=0.0282, accuracy=0.6759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11305)\u001b[0m Client 5: evaluation on 108 examples: loss=0.0160, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11306)\u001b[0m Client 12: evaluation on 108 examples: loss=0.0281, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11306)\u001b[0m Client 16: evaluation on 108 examples: loss=0.0266, accuracy=0.7222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11305)\u001b[0m Client 18: evaluation on 108 examples: loss=0.0147, accuracy=0.7222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11305)\u001b[0m Client 24: evaluation on 108 examples: loss=0.0080, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11306)\u001b[0m Client 15: evaluation on 108 examples: loss=0.0211, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15245)\u001b[0m Client 0: evaluation on 108 examples: loss=0.0094, accuracy=0.8148\n",
            "DEBUG flower 2024-01-13 11:54:17,228 | server.py:179 | evaluate_round 3 received 20 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-13 11:54:17,228 | server.py:215 | fit_round 4: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15292)\u001b[0m Client 6: evaluation on 108 examples: loss=0.0173, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15245)\u001b[0m Client 15: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15292)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15394)\u001b[0m Client 11: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15395)\u001b[0m Client 19: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15245)\u001b[0m Client 15: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15245)\u001b[0m Client 24: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15292)\u001b[0m Client 9: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15292)\u001b[0m Client 16: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15395)\u001b[0m Client 19: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15395)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15394)\u001b[0m Client 11: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15394)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15245)\u001b[0m Client 24: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15245)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15292)\u001b[0m Client 16: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15292)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15394)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15394)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15395)\u001b[0m Client 2: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15395)\u001b[0m Client 10: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15245)\u001b[0m Client 8: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15245)\u001b[0m Client 14: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15292)\u001b[0m Client 1: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15292)\u001b[0m Client 23: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15394)\u001b[0m Client 0: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15394)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15395)\u001b[0m Client 10: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15395)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15245)\u001b[0m Client 14: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15245)\u001b[0m Client 21: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15292)\u001b[0m Client 23: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15292)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15394)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15395)\u001b[0m Client 6: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15394)\u001b[0m Client 12: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15395)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15245)\u001b[0m Client 21: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15292)\u001b[0m Client 3: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15394)\u001b[0m Client 12: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-13 12:08:49,651 | server.py:229 | fit_round 4 received 20 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15395)\u001b[0m Client 7: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0232, test_accuracy=0.8037\n",
            "INFO flower 2024-01-13 12:08:51,536 | server.py:116 | fit progress: (4, 0.02317730361223221, {'accuracy': 0.8036666666666666}, 3508.5106526369996)\n",
            "DEBUG flower 2024-01-13 12:08:51,536 | server.py:165 | evaluate_round 4: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15394)\u001b[0m Client 11: evaluation on 108 examples: loss=0.0099, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15395)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0134, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15394)\u001b[0m Client 16: evaluation on 108 examples: loss=0.0269, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15395)\u001b[0m Client 9: evaluation on 108 examples: loss=0.0175, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15395)\u001b[0m Client 17: evaluation on 108 examples: loss=0.0193, accuracy=0.7222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15394)\u001b[0m Client 2: evaluation on 108 examples: loss=0.0101, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15395)\u001b[0m Client 15: evaluation on 108 examples: loss=0.0186, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15394)\u001b[0m Client 1: evaluation on 108 examples: loss=0.0144, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15395)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0136, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15394)\u001b[0m Client 18: evaluation on 108 examples: loss=0.0136, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15395)\u001b[0m Client 5: evaluation on 108 examples: loss=0.0149, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15394)\u001b[0m Client 4: evaluation on 108 examples: loss=0.0235, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15395)\u001b[0m Client 23: evaluation on 108 examples: loss=0.0028, accuracy=0.9259\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15395)\u001b[0m Client 13: evaluation on 108 examples: loss=0.0096, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15394)\u001b[0m Client 6: evaluation on 108 examples: loss=0.0172, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15395)\u001b[0m Client 21: evaluation on 108 examples: loss=0.0238, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15394)\u001b[0m Client 24: evaluation on 108 examples: loss=0.0080, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15395)\u001b[0m Client 12: evaluation on 108 examples: loss=0.0285, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19374)\u001b[0m Client 14: evaluation on 108 examples: loss=0.0095, accuracy=0.7778\n",
            "DEBUG flower 2024-01-13 12:09:02,298 | server.py:179 | evaluate_round 4 received 20 results and 0 failures\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-13 12:09:02,299 | server.py:215 | fit_round 5: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19376)\u001b[0m Client 0: evaluation on 108 examples: loss=0.0086, accuracy=0.8333\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19376)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19374)\u001b[0m Client 12: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19504)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19503)\u001b[0m Client 23: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19376)\u001b[0m Client 4: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19376)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19374)\u001b[0m Client 12: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19374)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19504)\u001b[0m Client 0: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19504)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19503)\u001b[0m Client 23: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19503)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19376)\u001b[0m Client 1: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19376)\u001b[0m Client 10: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19374)\u001b[0m Client 3: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19374)\u001b[0m Client 20: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19503)\u001b[0m Client 7: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19503)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19504)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19504)\u001b[0m Client 16: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19376)\u001b[0m Client 10: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19376)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19374)\u001b[0m Client 20: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19374)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19503)\u001b[0m Client 9: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19503)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19504)\u001b[0m Client 16: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19504)\u001b[0m Client 24: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19376)\u001b[0m Client 2: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19376)\u001b[0m Client 19: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19374)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19374)\u001b[0m Client 21: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19503)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19503)\u001b[0m Client 18: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19504)\u001b[0m Client 24: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19504)\u001b[0m Client 15: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19376)\u001b[0m Client 19: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19374)\u001b[0m Client 21: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19503)\u001b[0m Client 18: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-13 12:23:29,796 | server.py:229 | fit_round 5 received 20 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=19504)\u001b[0m Client 15: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0216, test_accuracy=0.8167\n",
            "INFO flower 2024-01-13 12:23:31,740 | server.py:116 | fit progress: (5, 0.021568393503626188, {'accuracy': 0.8166666666666667}, 4388.715235281001)\n",
            "DEBUG flower 2024-01-13 12:23:31,741 | server.py:165 | evaluate_round 5: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19503)\u001b[0m Client 3: evaluation on 108 examples: loss=0.0220, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19504)\u001b[0m Client 15: evaluation on 108 examples: loss=0.0148, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19503)\u001b[0m Client 13: evaluation on 108 examples: loss=0.0092, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19504)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0145, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19503)\u001b[0m Client 8: evaluation on 108 examples: loss=0.0198, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19504)\u001b[0m Client 1: evaluation on 108 examples: loss=0.0135, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19503)\u001b[0m Client 20: evaluation on 108 examples: loss=0.0126, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19504)\u001b[0m Client 11: evaluation on 108 examples: loss=0.0124, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19503)\u001b[0m Client 2: evaluation on 108 examples: loss=0.0096, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19504)\u001b[0m Client 12: evaluation on 108 examples: loss=0.0283, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19503)\u001b[0m Client 14: evaluation on 108 examples: loss=0.0112, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19504)\u001b[0m Client 4: evaluation on 108 examples: loss=0.0232, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19503)\u001b[0m Client 21: evaluation on 108 examples: loss=0.0264, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19504)\u001b[0m Client 9: evaluation on 108 examples: loss=0.0212, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19503)\u001b[0m Client 24: evaluation on 108 examples: loss=0.0081, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19504)\u001b[0m Client 5: evaluation on 108 examples: loss=0.0144, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19503)\u001b[0m Client 7: evaluation on 108 examples: loss=0.0251, accuracy=0.7130\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=19504)\u001b[0m Client 0: evaluation on 108 examples: loss=0.0090, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23461)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0116, accuracy=0.7870\n",
            "DEBUG flower 2024-01-13 12:23:42,949 | server.py:179 | evaluate_round 5 received 20 results and 0 failures\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-13 12:23:42,949 | server.py:215 | fit_round 6: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23526)\u001b[0m Client 6: evaluation on 108 examples: loss=0.0193, accuracy=0.8241\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23461)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23526)\u001b[0m Client 22: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23616)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23668)\u001b[0m Client 14: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23526)\u001b[0m Client 22: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23526)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23461)\u001b[0m Client 1: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23461)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23616)\u001b[0m Client 2: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23616)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23668)\u001b[0m Client 14: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23668)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23526)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23526)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23461)\u001b[0m Client 9: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23461)\u001b[0m Client 21: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23616)\u001b[0m Client 0: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23668)\u001b[0m Client 6: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23616)\u001b[0m Client 24: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23668)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23526)\u001b[0m Client 7: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23526)\u001b[0m Client 18: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23461)\u001b[0m Client 21: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23461)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23668)\u001b[0m Client 8: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23668)\u001b[0m Client 11: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23616)\u001b[0m Client 24: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23616)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23526)\u001b[0m Client 18: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23526)\u001b[0m Client 12: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23461)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23461)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23668)\u001b[0m Client 11: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23668)\u001b[0m Client 19: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23616)\u001b[0m Client 3: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23616)\u001b[0m Client 23: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23526)\u001b[0m Client 12: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23461)\u001b[0m Client 4: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23668)\u001b[0m Client 19: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-13 12:38:16,648 | server.py:229 | fit_round 6 received 20 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23616)\u001b[0m Client 23: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0207, test_accuracy=0.8263\n",
            "INFO flower 2024-01-13 12:38:18,730 | server.py:116 | fit progress: (6, 0.02067141737540563, {'accuracy': 0.8263333333333334}, 5275.705264389)\n",
            "DEBUG flower 2024-01-13 12:38:18,731 | server.py:165 | evaluate_round 6: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23616)\u001b[0m Client 7: evaluation on 108 examples: loss=0.0276, accuracy=0.7222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23668)\u001b[0m Client 1: evaluation on 108 examples: loss=0.0151, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23668)\u001b[0m Client 4: evaluation on 108 examples: loss=0.0225, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23616)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0147, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23668)\u001b[0m Client 23: evaluation on 108 examples: loss=0.0020, accuracy=0.9444\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23616)\u001b[0m Client 16: evaluation on 108 examples: loss=0.0314, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23668)\u001b[0m Client 17: evaluation on 108 examples: loss=0.0216, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23616)\u001b[0m Client 12: evaluation on 108 examples: loss=0.0275, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23616)\u001b[0m Client 6: evaluation on 108 examples: loss=0.0198, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23668)\u001b[0m Client 10: evaluation on 108 examples: loss=0.0210, accuracy=0.7222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23668)\u001b[0m Client 2: evaluation on 108 examples: loss=0.0104, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23616)\u001b[0m Client 8: evaluation on 108 examples: loss=0.0201, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23668)\u001b[0m Client 13: evaluation on 108 examples: loss=0.0103, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23616)\u001b[0m Client 15: evaluation on 108 examples: loss=0.0170, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23668)\u001b[0m Client 5: evaluation on 108 examples: loss=0.0161, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23616)\u001b[0m Client 0: evaluation on 108 examples: loss=0.0087, accuracy=0.8519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23668)\u001b[0m Client 18: evaluation on 108 examples: loss=0.0138, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23616)\u001b[0m Client 3: evaluation on 108 examples: loss=0.0200, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27627)\u001b[0m Client 11: evaluation on 108 examples: loss=0.0122, accuracy=0.7593\n",
            "DEBUG flower 2024-01-13 12:38:29,826 | server.py:179 | evaluate_round 6 received 20 results and 0 failures\n",
            "Configuring round 7\n",
            "DEBUG flower 2024-01-13 12:38:29,826 | server.py:215 | fit_round 7: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27674)\u001b[0m Client 20: evaluation on 108 examples: loss=0.0132, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27627)\u001b[0m Client 21: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27674)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27784)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27834)\u001b[0m Client 22: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27627)\u001b[0m Client 21: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27627)\u001b[0m Client 20: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27674)\u001b[0m Client 2: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27674)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27784)\u001b[0m Client 4: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27784)\u001b[0m Client 11: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27834)\u001b[0m Client 22: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27834)\u001b[0m Client 23: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27627)\u001b[0m Client 20: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27627)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27674)\u001b[0m Client 9: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27674)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27784)\u001b[0m Client 11: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27784)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27834)\u001b[0m Client 23: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27834)\u001b[0m Client 10: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27627)\u001b[0m Client 3: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27627)\u001b[0m Client 14: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27674)\u001b[0m Client 8: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27674)\u001b[0m Client 16: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27784)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27784)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27834)\u001b[0m Client 10: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27834)\u001b[0m Client 12: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27674)\u001b[0m Client 16: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27674)\u001b[0m Client 24: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27627)\u001b[0m Client 14: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27627)\u001b[0m Client 18: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27784)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27784)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27834)\u001b[0m Client 12: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27834)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27674)\u001b[0m Client 24: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27627)\u001b[0m Client 18: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27784)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27834)\u001b[0m Client 0: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-13 12:53:07,668 | server.py:229 | fit_round 7 received 20 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0193, test_accuracy=0.8287\n",
            "INFO flower 2024-01-13 12:53:10,201 | server.py:116 | fit progress: (7, 0.01928938031196594, {'accuracy': 0.8286666666666667}, 6167.175532642001)\n",
            "DEBUG flower 2024-01-13 12:53:10,201 | server.py:165 | evaluate_round 7: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27834)\u001b[0m Client 9: evaluation on 108 examples: loss=0.0213, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27784)\u001b[0m Client 15: evaluation on 108 examples: loss=0.0145, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27834)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0122, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27784)\u001b[0m Client 7: evaluation on 108 examples: loss=0.0288, accuracy=0.6759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27784)\u001b[0m Client 14: evaluation on 108 examples: loss=0.0131, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27834)\u001b[0m Client 0: evaluation on 108 examples: loss=0.0088, accuracy=0.8241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27784)\u001b[0m Client 4: evaluation on 108 examples: loss=0.0218, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27834)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0145, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27784)\u001b[0m Client 18: evaluation on 108 examples: loss=0.0141, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27834)\u001b[0m Client 16: evaluation on 108 examples: loss=0.0296, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27784)\u001b[0m Client 2: evaluation on 108 examples: loss=0.0103, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27834)\u001b[0m Client 10: evaluation on 108 examples: loss=0.0208, accuracy=0.6852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27834)\u001b[0m Client 23: evaluation on 108 examples: loss=0.0017, accuracy=0.9537\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27784)\u001b[0m Client 24: evaluation on 108 examples: loss=0.0076, accuracy=0.8426\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27784)\u001b[0m Client 3: evaluation on 108 examples: loss=0.0196, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27834)\u001b[0m Client 5: evaluation on 108 examples: loss=0.0152, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27784)\u001b[0m Client 6: evaluation on 108 examples: loss=0.0209, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27834)\u001b[0m Client 17: evaluation on 108 examples: loss=0.0210, accuracy=0.7222\n",
            "DEBUG flower 2024-01-13 12:53:20,487 | server.py:179 | evaluate_round 7 received 20 results and 0 failures\n",
            "Configuring round 8\n",
            "DEBUG flower 2024-01-13 12:53:20,487 | server.py:215 | fit_round 8: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31799)\u001b[0m Client 12: evaluation on 108 examples: loss=0.0244, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31800)\u001b[0m Client 1: evaluation on 108 examples: loss=0.0166, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31799)\u001b[0m Client 18: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31800)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31925)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31981)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31799)\u001b[0m Client 18: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31799)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31800)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31800)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31925)\u001b[0m Client 4: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31925)\u001b[0m Client 24: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31981)\u001b[0m Client 8: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31981)\u001b[0m Client 12: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31799)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31799)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31800)\u001b[0m Client 3: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31800)\u001b[0m Client 14: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31925)\u001b[0m Client 24: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31925)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31981)\u001b[0m Client 12: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31981)\u001b[0m Client 11: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31799)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31799)\u001b[0m Client 23: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31800)\u001b[0m Client 14: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31800)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31925)\u001b[0m Client 2: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31925)\u001b[0m Client 19: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31981)\u001b[0m Client 11: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31981)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31799)\u001b[0m Client 23: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31799)\u001b[0m Client 20: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31800)\u001b[0m Client 0: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31800)\u001b[0m Client 15: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31925)\u001b[0m Client 19: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31925)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31981)\u001b[0m Client 1: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31981)\u001b[0m Client 16: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31799)\u001b[0m Client 20: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31800)\u001b[0m Client 15: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31925)\u001b[0m Client 9: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-13 13:07:45,683 | server.py:229 | fit_round 8 received 20 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31981)\u001b[0m Client 16: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0177, test_accuracy=0.8493\n",
            "INFO flower 2024-01-13 13:07:48,432 | server.py:116 | fit progress: (8, 0.017672901233037313, {'accuracy': 0.8493333333333334}, 7045.407233667)\n",
            "DEBUG flower 2024-01-13 13:07:48,433 | server.py:165 | evaluate_round 8: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31925)\u001b[0m Client 1: evaluation on 108 examples: loss=0.0147, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31981)\u001b[0m Client 7: evaluation on 108 examples: loss=0.0272, accuracy=0.6852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31925)\u001b[0m Client 11: evaluation on 108 examples: loss=0.0113, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31981)\u001b[0m Client 2: evaluation on 108 examples: loss=0.0100, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31925)\u001b[0m Client 16: evaluation on 108 examples: loss=0.0285, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31981)\u001b[0m Client 0: evaluation on 108 examples: loss=0.0096, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31925)\u001b[0m Client 20: evaluation on 108 examples: loss=0.0128, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31981)\u001b[0m Client 6: evaluation on 108 examples: loss=0.0222, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31925)\u001b[0m Client 5: evaluation on 108 examples: loss=0.0131, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31981)\u001b[0m Client 8: evaluation on 108 examples: loss=0.0167, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31925)\u001b[0m Client 24: evaluation on 108 examples: loss=0.0084, accuracy=0.8333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31981)\u001b[0m Client 15: evaluation on 108 examples: loss=0.0135, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31925)\u001b[0m Client 13: evaluation on 108 examples: loss=0.0102, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31981)\u001b[0m Client 21: evaluation on 108 examples: loss=0.0320, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31925)\u001b[0m Client 10: evaluation on 108 examples: loss=0.0216, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31925)\u001b[0m Client 18: evaluation on 108 examples: loss=0.0133, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31981)\u001b[0m Client 4: evaluation on 108 examples: loss=0.0215, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31981)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0122, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35903)\u001b[0m Client 23: evaluation on 108 examples: loss=0.0024, accuracy=0.9352\n",
            "DEBUG flower 2024-01-13 13:07:57,062 | server.py:179 | evaluate_round 8 received 20 results and 0 failures\n",
            "Configuring round 9\n",
            "DEBUG flower 2024-01-13 13:07:57,062 | server.py:215 | fit_round 9: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35904)\u001b[0m Client 9: evaluation on 108 examples: loss=0.0242, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35904)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35903)\u001b[0m Client 12: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36022)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36059)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35903)\u001b[0m Client 12: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35903)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35904)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35904)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36022)\u001b[0m Client 7: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36022)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36059)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36059)\u001b[0m Client 14: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35903)\u001b[0m Client 3: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35903)\u001b[0m Client 23: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35904)\u001b[0m Client 6: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35904)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36022)\u001b[0m Client 1: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36022)\u001b[0m Client 18: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36059)\u001b[0m Client 14: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36059)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35903)\u001b[0m Client 23: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35903)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35904)\u001b[0m Client 0: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35904)\u001b[0m Client 10: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36022)\u001b[0m Client 18: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36022)\u001b[0m Client 19: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36059)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36059)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35903)\u001b[0m Client 4: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35903)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35904)\u001b[0m Client 10: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35904)\u001b[0m Client 24: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36059)\u001b[0m Client 9: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36022)\u001b[0m Client 19: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36059)\u001b[0m Client 22: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36022)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35903)\u001b[0m Client 2: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35904)\u001b[0m Client 24: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36022)\u001b[0m Client 8: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-13 13:22:35,838 | server.py:229 | fit_round 9 received 20 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=36059)\u001b[0m Client 22: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0167, test_accuracy=0.8577\n",
            "INFO flower 2024-01-13 13:22:39,183 | server.py:116 | fit progress: (9, 0.016654814730087918, {'accuracy': 0.8576666666666667}, 7936.157984090001)\n",
            "DEBUG flower 2024-01-13 13:22:39,183 | server.py:165 | evaluate_round 9: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36022)\u001b[0m Client 2: evaluation on 108 examples: loss=0.0122, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36059)\u001b[0m Client 0: evaluation on 108 examples: loss=0.0087, accuracy=0.8333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36022)\u001b[0m Client 6: evaluation on 108 examples: loss=0.0196, accuracy=0.8241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36059)\u001b[0m Client 20: evaluation on 108 examples: loss=0.0120, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36022)\u001b[0m Client 15: evaluation on 108 examples: loss=0.0142, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36059)\u001b[0m Client 3: evaluation on 108 examples: loss=0.0203, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36022)\u001b[0m Client 7: evaluation on 108 examples: loss=0.0272, accuracy=0.6944\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36059)\u001b[0m Client 12: evaluation on 108 examples: loss=0.0283, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36059)\u001b[0m Client 14: evaluation on 108 examples: loss=0.0117, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36022)\u001b[0m Client 8: evaluation on 108 examples: loss=0.0166, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36059)\u001b[0m Client 18: evaluation on 108 examples: loss=0.0130, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36022)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0124, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36059)\u001b[0m Client 4: evaluation on 108 examples: loss=0.0209, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36022)\u001b[0m Client 21: evaluation on 108 examples: loss=0.0297, accuracy=0.8333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36059)\u001b[0m Client 19: evaluation on 108 examples: loss=0.0151, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36022)\u001b[0m Client 11: evaluation on 108 examples: loss=0.0112, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36059)\u001b[0m Client 13: evaluation on 108 examples: loss=0.0103, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=36022)\u001b[0m Client 1: evaluation on 108 examples: loss=0.0164, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40064)\u001b[0m Client 10: evaluation on 108 examples: loss=0.0210, accuracy=0.7037\n",
            "DEBUG flower 2024-01-13 13:22:49,172 | server.py:179 | evaluate_round 9 received 20 results and 0 failures\n",
            "Configuring round 10\n",
            "DEBUG flower 2024-01-13 13:22:49,173 | server.py:215 | fit_round 10: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40128)\u001b[0m Client 16: evaluation on 108 examples: loss=0.0289, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40064)\u001b[0m Client 20: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40128)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40212)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40214)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40128)\u001b[0m Client 5: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40128)\u001b[0m Client 14: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40064)\u001b[0m Client 20: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40064)\u001b[0m Client 11: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40212)\u001b[0m Client 4: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40212)\u001b[0m Client 22: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40214)\u001b[0m Client 6: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40214)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40128)\u001b[0m Client 14: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40128)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40064)\u001b[0m Client 11: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40064)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40214)\u001b[0m Client 9: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40214)\u001b[0m Client 19: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40212)\u001b[0m Client 22: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40212)\u001b[0m Client 13: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40064)\u001b[0m Client 1: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40064)\u001b[0m Client 18: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40128)\u001b[0m Client 3: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40128)\u001b[0m Client 23: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40214)\u001b[0m Client 19: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40214)\u001b[0m Client 17: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40212)\u001b[0m Client 13: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40212)\u001b[0m Client 12: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40064)\u001b[0m Client 18: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40064)\u001b[0m Client 21: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40128)\u001b[0m Client 23: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40128)\u001b[0m Client 24: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40214)\u001b[0m Client 17: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40214)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40212)\u001b[0m Client 12: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40212)\u001b[0m Client 10: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40064)\u001b[0m Client 21: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40128)\u001b[0m Client 24: training round complete, 31360 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40214)\u001b[0m Client 0: training round complete, 31360 examples processed\n",
            "DEBUG flower 2024-01-13 13:37:29,260 | server.py:229 | fit_round 10 received 20 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40212)\u001b[0m Client 10: training round complete, 31360 examples processed\n",
            "Evaluation on the server: test_loss=0.0165, test_accuracy=0.8603\n",
            "INFO flower 2024-01-13 13:37:31,098 | server.py:116 | fit progress: (10, 0.01652537159373363, {'accuracy': 0.8603333333333333}, 8828.072661392)\n",
            "DEBUG flower 2024-01-13 13:37:31,098 | server.py:165 | evaluate_round 10: strategy sampled 20 clients (out of 25)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40212)\u001b[0m Client 12: evaluation on 108 examples: loss=0.0285, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40214)\u001b[0m Client 3: evaluation on 108 examples: loss=0.0206, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40214)\u001b[0m Client 4: evaluation on 108 examples: loss=0.0220, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40212)\u001b[0m Client 24: evaluation on 108 examples: loss=0.0076, accuracy=0.8426\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40214)\u001b[0m Client 18: evaluation on 108 examples: loss=0.0126, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40212)\u001b[0m Client 8: evaluation on 108 examples: loss=0.0196, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40214)\u001b[0m Client 6: evaluation on 108 examples: loss=0.0255, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40212)\u001b[0m Client 17: evaluation on 108 examples: loss=0.0219, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40214)\u001b[0m Client 15: evaluation on 108 examples: loss=0.0161, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40212)\u001b[0m Client 23: evaluation on 108 examples: loss=0.0025, accuracy=0.9537\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40214)\u001b[0m Client 9: evaluation on 108 examples: loss=0.0221, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40212)\u001b[0m Client 16: evaluation on 108 examples: loss=0.0303, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40214)\u001b[0m Client 14: evaluation on 108 examples: loss=0.0127, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40212)\u001b[0m Client 0: evaluation on 108 examples: loss=0.0085, accuracy=0.8519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40214)\u001b[0m Client 11: evaluation on 108 examples: loss=0.0133, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40212)\u001b[0m Client 2: evaluation on 108 examples: loss=0.0110, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40214)\u001b[0m Client 1: evaluation on 108 examples: loss=0.0174, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=40212)\u001b[0m Client 5: evaluation on 108 examples: loss=0.0150, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=44194)\u001b[0m Client 22: evaluation on 108 examples: loss=0.0119, accuracy=0.8241\n",
            "DEBUG flower 2024-01-13 13:37:39,489 | server.py:179 | evaluate_round 10 received 20 results and 0 failures\n",
            "INFO flower 2024-01-13 13:37:39,489 | server.py:144 | FL finished in 8836.463649928\n",
            "INFO flower 2024-01-13 13:37:39,496 | app.py:180 | app_fit: losses_distributed [(1, 0.0329590090447002), (2, 0.018082881342895606), (3, 0.017163301514530622), (4, 0.015183994555155988), (5, 0.016303338169948094), (6, 0.01725926119575484), (7, 0.01683784895921471), (8, 0.016271200816629937), (9, 0.01748092002838988), (10, 0.016478674929088877)]\n",
            "INFO flower 2024-01-13 13:37:39,496 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2024-01-13 13:37:39,496 | app.py:182 | app_fit: losses_centralized [(0, 0.07224025885264079), (1, 0.05592773207028707), (2, 0.029510234733422597), (3, 0.025786146566271782), (4, 0.02317730361223221), (5, 0.021568393503626188), (6, 0.02067141737540563), (7, 0.01928938031196594), (8, 0.017672901233037313), (9, 0.016654814730087918), (10, 0.01652537159373363)]\n",
            "INFO flower 2024-01-13 13:37:39,496 | app.py:183 | app_fit: metrics_centralized {'accuracy': [(0, 0.08633333333333333), (1, 0.42233333333333334), (2, 0.7236666666666667), (3, 0.776), (4, 0.8036666666666666), (5, 0.8166666666666667), (6, 0.8263333333333334), (7, 0.8286666666666667), (8, 0.8493333333333334), (9, 0.8576666666666667), (10, 0.8603333333333333)]}\n",
            "History (loss, distributed):\n",
            "\tround 1: 0.0329590090447002\n",
            "\tround 2: 0.018082881342895606\n",
            "\tround 3: 0.017163301514530622\n",
            "\tround 4: 0.015183994555155988\n",
            "\tround 5: 0.016303338169948094\n",
            "\tround 6: 0.01725926119575484\n",
            "\tround 7: 0.01683784895921471\n",
            "\tround 8: 0.016271200816629937\n",
            "\tround 9: 0.01748092002838988\n",
            "\tround 10: 0.016478674929088877\n",
            "History (loss, centralized):\n",
            "\tround 0: 0.07224025885264079\n",
            "\tround 1: 0.05592773207028707\n",
            "\tround 2: 0.029510234733422597\n",
            "\tround 3: 0.025786146566271782\n",
            "\tround 4: 0.02317730361223221\n",
            "\tround 5: 0.021568393503626188\n",
            "\tround 6: 0.02067141737540563\n",
            "\tround 7: 0.01928938031196594\n",
            "\tround 8: 0.017672901233037313\n",
            "\tround 9: 0.016654814730087918\n",
            "\tround 10: 0.01652537159373363\n",
            "History (metrics, centralized):\n",
            "{'accuracy': [(0, 0.08633333333333333), (1, 0.42233333333333334), (2, 0.7236666666666667), (3, 0.776), (4, 0.8036666666666666), (5, 0.8166666666666667), (6, 0.8263333333333334), (7, 0.8286666666666667), (8, 0.8493333333333334), (9, 0.8576666666666667), (10, 0.8603333333333333)]}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=44195)\u001b[0m Client 13: evaluation on 108 examples: loss=0.0106, accuracy=0.7685\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UrhV3qkAXAgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment 3: Changing the iid-ness of the data\n",
        "\n",
        "Total number of clients: 10\n",
        "\n",
        "Running FL with iid-alpha={0.2, 0.5, 2.0, 5.0, 10.0, 100.0, 1000} concurrent clients"
      ],
      "metadata": {
        "id": "6bVEEjIcEFDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --iid-alpha 0.2 --fraction-fit 1.0 --client-pool-size 10 --num-iterations 1000 --num-rounds 10 --val-ratio 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB7u_FbXEFJi",
        "outputId": "ec967316-9219-4762-f198-c654b7227e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=0.2, 10 classes): [  0 137 949 251 310   0   8 118   0 927]\n",
            "Data partitioned across 10 clients, with IID alpha = 0.2 and 0.2 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 10 client in the pool.\n",
            "FL round will proceed with 100.0% of clients sampled, at least 2.\n",
            "INFO flower 2024-01-14 08:26:01,082 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-14 08:26:05,260 | app.py:176 | Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'object_store_memory': 3480791040.0, 'memory': 6961582080.0, 'CPU': 2.0, 'accelerator_type:V100': 1.0, 'GPU': 1.0}\n",
            "INFO flower 2024-01-14 08:26:05,260 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-14 08:26:05,260 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-14 08:26:09,849 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-14 08:26:09,849 | server.py:88 | Evaluating initial parameters\n",
            "Evaluation on the server: test_loss=0.0725, test_accuracy=0.0437\n",
            "INFO flower 2024-01-14 08:26:13,092 | server.py:91 | initial parameters (loss, other metrics): 0.07246543502807617, {'accuracy': 0.043666666666666666}\n",
            "INFO flower 2024-01-14 08:26:13,092 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-14 08:26:13,092 | server.py:215 | fit_round 1: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7647)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7646)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7783)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7782)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7647)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7647)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7646)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7646)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7783)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7783)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7782)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7782)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7647)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7647)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7646)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7646)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7783)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7783)\u001b[0m E0114 08:32:19.002256581    7796 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7782)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7647)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 08:33:37,948 | server.py:229 | fit_round 1 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7646)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "WARNING flower 2024-01-14 08:33:37,989 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "Evaluation on the server: test_loss=0.0612, test_accuracy=0.3310\n",
            "INFO flower 2024-01-14 08:33:39,818 | server.py:116 | fit progress: (1, 0.06119616154829661, {'accuracy': 0.331}, 446.726018736)\n",
            "DEBUG flower 2024-01-14 08:33:39,818 | server.py:165 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7646)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0215, accuracy=0.3870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7647)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0236, accuracy=0.2574\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7647)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0154, accuracy=0.7852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7646)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0205, accuracy=0.3815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7647)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0213, accuracy=0.3463\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7646)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0218, accuracy=0.2704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7647)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0213, accuracy=0.2556\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7646)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0244, accuracy=0.1722\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9839)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0221, accuracy=0.2241\n",
            "DEBUG flower 2024-01-14 08:33:53,384 | server.py:179 | evaluate_round 1 received 10 results and 0 failures\n",
            "WARNING flower 2024-01-14 08:33:53,385 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-14 08:33:53,385 | server.py:215 | fit_round 2: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9879)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0235, accuracy=0.2870\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9839)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9879)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9997)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9996)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9879)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9879)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9839)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9839)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9997)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9997)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9996)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9996)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9879)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9879)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9839)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9839)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9997)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9997)\u001b[0m E0114 08:39:54.783558677   10061 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9996)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9996)\u001b[0m E0114 08:40:01.445639803   10051 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9879)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 08:41:15,236 | server.py:229 | fit_round 2 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9839)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0493, test_accuracy=0.4270\n",
            "INFO flower 2024-01-14 08:41:17,034 | server.py:116 | fit progress: (2, 0.04929042911529541, {'accuracy': 0.427}, 903.9418914149999)\n",
            "DEBUG flower 2024-01-14 08:41:17,034 | server.py:165 | evaluate_round 2: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9839)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0173, accuracy=0.3796\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9879)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0177, accuracy=0.4778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9879)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0127, accuracy=0.4759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9839)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0252, accuracy=0.2556\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9879)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0192, accuracy=0.3074\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9839)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0093, accuracy=0.7889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9879)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0223, accuracy=0.3519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9839)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0158, accuracy=0.4759\n",
            "DEBUG flower 2024-01-14 08:41:29,969 | server.py:179 | evaluate_round 2 received 10 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-14 08:41:29,969 | server.py:215 | fit_round 3: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12044)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0172, accuracy=0.4611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12045)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0195, accuracy=0.3981\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12044)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12045)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12171)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12173)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12044)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12044)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12045)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12045)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12173)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12171)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12173)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12171)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12044)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12044)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12045)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12045)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12171)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12171)\u001b[0m E0114 08:47:32.535022316   12188 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12173)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12173)\u001b[0m E0114 08:47:36.420126456   12214 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12044)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 08:48:50,729 | server.py:229 | fit_round 3 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12045)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0363, test_accuracy=0.6233\n",
            "INFO flower 2024-01-14 08:48:52,680 | server.py:116 | fit progress: (3, 0.03634108938773473, {'accuracy': 0.6233333333333333}, 1359.588079374)\n",
            "DEBUG flower 2024-01-14 08:48:52,680 | server.py:165 | evaluate_round 3: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12045)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0249, accuracy=0.3574\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12044)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0082, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12044)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0132, accuracy=0.6167\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12045)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0141, accuracy=0.5444\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12044)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0191, accuracy=0.5074\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12045)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0095, accuracy=0.6926\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12045)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0091, accuracy=0.7093\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12044)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0127, accuracy=0.6852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14221)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0176, accuracy=0.5593\n",
            "DEBUG flower 2024-01-14 08:49:06,808 | server.py:179 | evaluate_round 3 received 10 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-14 08:49:06,808 | server.py:215 | fit_round 4: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14256)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0089, accuracy=0.7611\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14221)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14256)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14381)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14379)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14256)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14256)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14221)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14221)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14381)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14379)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14381)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14379)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14256)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14256)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14221)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14221)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14381)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14381)\u001b[0m E0114 08:55:19.497154809   14410 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14379)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14379)\u001b[0m E0114 08:55:21.401864485   14421 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14256)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 08:56:39,692 | server.py:229 | fit_round 4 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14221)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0312, test_accuracy=0.6697\n",
            "INFO flower 2024-01-14 08:56:42,239 | server.py:116 | fit progress: (4, 0.031204501509666444, {'accuracy': 0.6696666666666666}, 1829.1468687459999)\n",
            "DEBUG flower 2024-01-14 08:56:42,239 | server.py:165 | evaluate_round 4: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14221)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0098, accuracy=0.7204\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14256)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0062, accuracy=0.8037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14256)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0188, accuracy=0.5167\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14221)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0087, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14256)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0114, accuracy=0.6204\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14221)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0078, accuracy=0.7759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14256)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0132, accuracy=0.6167\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14221)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0182, accuracy=0.4759\n",
            "DEBUG flower 2024-01-14 08:56:53,376 | server.py:179 | evaluate_round 4 received 10 results and 0 failures\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-14 08:56:53,376 | server.py:215 | fit_round 5: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16479)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0083, accuracy=0.7889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16481)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0236, accuracy=0.4074\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16479)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16481)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16600)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16662)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16479)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16481)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16479)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16481)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16600)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16600)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16662)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16662)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16481)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16479)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16481)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16479)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16600)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16662)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16481)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 09:04:27,885 | server.py:229 | fit_round 5 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16479)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0258, test_accuracy=0.7380\n",
            "INFO flower 2024-01-14 09:04:29,845 | server.py:116 | fit progress: (5, 0.025752400040626525, {'accuracy': 0.738}, 2296.7526098610006)\n",
            "DEBUG flower 2024-01-14 09:04:29,845 | server.py:165 | evaluate_round 5: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16481)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0123, accuracy=0.6926\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16479)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0044, accuracy=0.8833\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16481)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0081, accuracy=0.7889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16479)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0067, accuracy=0.8241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16481)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0098, accuracy=0.7370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16479)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0098, accuracy=0.7556\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16481)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0171, accuracy=0.5593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16479)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0091, accuracy=0.7759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18732)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0153, accuracy=0.6093\n",
            "DEBUG flower 2024-01-14 09:04:44,196 | server.py:179 | evaluate_round 5 received 10 results and 0 failures\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-14 09:04:44,196 | server.py:215 | fit_round 6: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18782)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0232, accuracy=0.4444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18732)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18782)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18893)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18946)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18782)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18782)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18732)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18732)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18893)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18893)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18946)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18946)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18782)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18782)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18732)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18732)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18893)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18946)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18893)\u001b[0m E0114 09:10:59.320764244   18910 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18946)\u001b[0m E0114 09:11:00.568806508   18967 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18782)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 09:12:20,440 | server.py:229 | fit_round 6 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18732)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0241, test_accuracy=0.7650\n",
            "INFO flower 2024-01-14 09:12:22,408 | server.py:116 | fit progress: (6, 0.02410782464345296, {'accuracy': 0.765}, 2769.3154731210007)\n",
            "DEBUG flower 2024-01-14 09:12:22,408 | server.py:165 | evaluate_round 6: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18732)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0101, accuracy=0.7352\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18782)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0121, accuracy=0.7000\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18782)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0144, accuracy=0.6537\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18732)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0107, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18782)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0227, accuracy=0.4852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18732)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0104, accuracy=0.7370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18782)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0086, accuracy=0.7981\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18732)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0063, accuracy=0.8352\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=21035)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0040, accuracy=0.8833\n",
            "DEBUG flower 2024-01-14 09:12:35,708 | server.py:179 | evaluate_round 6 received 10 results and 0 failures\n",
            "Configuring round 7\n",
            "DEBUG flower 2024-01-14 09:12:35,708 | server.py:215 | fit_round 7: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=21087)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0151, accuracy=0.6370\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21087)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21035)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21187)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21189)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21035)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21035)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21087)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21087)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21187)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21187)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21189)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21189)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21087)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21035)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21087)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21035)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21187)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21189)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21189)\u001b[0m E0114 09:18:55.665395469   21256 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21087)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 09:20:11,834 | server.py:229 | fit_round 7 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=21035)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0247, test_accuracy=0.7507\n",
            "INFO flower 2024-01-14 09:20:14,531 | server.py:116 | fit progress: (7, 0.024723611836632093, {'accuracy': 0.7506666666666667}, 3241.4393174550005)\n",
            "DEBUG flower 2024-01-14 09:20:14,532 | server.py:165 | evaluate_round 7: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=21035)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0084, accuracy=0.7722\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=21087)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0069, accuracy=0.8370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=21087)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0092, accuracy=0.7722\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=21035)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0216, accuracy=0.4815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=21087)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0137, accuracy=0.6704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=21035)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0112, accuracy=0.6889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=21087)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0150, accuracy=0.6352\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=21035)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0049, accuracy=0.8463\n",
            "DEBUG flower 2024-01-14 09:20:26,482 | server.py:179 | evaluate_round 7 received 10 results and 0 failures\n",
            "Configuring round 8\n",
            "DEBUG flower 2024-01-14 09:20:26,482 | server.py:215 | fit_round 8: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23306)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0091, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23307)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0148, accuracy=0.6167\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23306)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23307)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23430)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23429)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23307)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23307)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23306)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23306)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23429)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23429)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23430)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23430)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23307)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23307)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23306)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23306)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23429)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23430)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23307)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=23306)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 09:27:56,885 | server.py:229 | fit_round 8 received 10 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0228, test_accuracy=0.7810\n",
            "INFO flower 2024-01-14 09:27:59,292 | server.py:116 | fit progress: (8, 0.02275890805820624, {'accuracy': 0.781}, 3706.199687524)\n",
            "DEBUG flower 2024-01-14 09:27:59,292 | server.py:165 | evaluate_round 8: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23306)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0152, accuracy=0.6444\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23307)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0075, accuracy=0.8204\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23306)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0098, accuracy=0.7630\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23307)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0147, accuracy=0.6778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23306)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0104, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23307)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0077, accuracy=0.8093\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23306)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0099, accuracy=0.7370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=23307)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0134, accuracy=0.6944\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=25520)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0223, accuracy=0.4852\n",
            "DEBUG flower 2024-01-14 09:28:12,109 | server.py:179 | evaluate_round 8 received 10 results and 0 failures\n",
            "Configuring round 9\n",
            "DEBUG flower 2024-01-14 09:28:12,109 | server.py:215 | fit_round 9: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=25554)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0041, accuracy=0.8759\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25520)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25554)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25671)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25673)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25554)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25554)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25520)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25520)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25671)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25671)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25673)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25673)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25554)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25554)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25520)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25520)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25673)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25673)\u001b[0m E0114 09:34:22.832393502   25743 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25671)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25671)\u001b[0m E0114 09:34:26.476271018   25693 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25554)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 09:35:44,090 | server.py:229 | fit_round 9 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=25520)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0220, test_accuracy=0.7990\n",
            "INFO flower 2024-01-14 09:35:46,055 | server.py:116 | fit progress: (9, 0.02203265401472648, {'accuracy': 0.799}, 4172.963365435)\n",
            "DEBUG flower 2024-01-14 09:35:46,056 | server.py:165 | evaluate_round 9: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=25520)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0136, accuracy=0.7093\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=25554)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0089, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=25520)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0101, accuracy=0.7611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=25554)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0116, accuracy=0.7389\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=25520)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0209, accuracy=0.5241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=25554)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0147, accuracy=0.6907\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=25520)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0086, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=25554)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0159, accuracy=0.6389\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27764)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0093, accuracy=0.7907\n",
            "DEBUG flower 2024-01-14 09:35:59,107 | server.py:179 | evaluate_round 9 received 10 results and 0 failures\n",
            "Configuring round 10\n",
            "DEBUG flower 2024-01-14 09:35:59,108 | server.py:215 | fit_round 10: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27765)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0050, accuracy=0.8463\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27764)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27765)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27888)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27890)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27764)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27765)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27764)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27765)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27888)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27888)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27890)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27890)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27764)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27764)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27765)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27765)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27888)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27890)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27764)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 09:43:31,367 | server.py:229 | fit_round 10 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=27765)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0231, test_accuracy=0.7917\n",
            "INFO flower 2024-01-14 09:43:34,188 | server.py:116 | fit progress: (10, 0.023085295086105663, {'accuracy': 0.7916666666666666}, 4641.096248049001)\n",
            "DEBUG flower 2024-01-14 09:43:34,189 | server.py:165 | evaluate_round 10: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27764)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0071, accuracy=0.8074\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27765)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0113, accuracy=0.7389\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27764)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0107, accuracy=0.7611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27765)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0179, accuracy=0.6148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27764)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0143, accuracy=0.6963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27765)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0114, accuracy=0.7296\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27765)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0098, accuracy=0.7889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=27764)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0212, accuracy=0.5389\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=29994)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0132, accuracy=0.7204\n",
            "DEBUG flower 2024-01-14 09:43:45,267 | server.py:179 | evaluate_round 10 received 10 results and 0 failures\n",
            "INFO flower 2024-01-14 09:43:45,268 | server.py:144 | FL finished in 4652.1757985780005\n",
            "INFO flower 2024-01-14 09:43:45,269 | app.py:180 | app_fit: losses_distributed [(1, 0.02153343149909267), (2, 0.017623890958450458), (3, 0.01372658685401634), (4, 0.012602515457956879), (5, 0.011571681289761155), (6, 0.011413514349195693), (7, 0.01149366488887204), (8, 0.011493156397784197), (9, 0.011856795508000586), (10, 0.012702152530352274)]\n",
            "INFO flower 2024-01-14 09:43:45,269 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2024-01-14 09:43:45,269 | app.py:182 | app_fit: losses_centralized [(0, 0.07246543502807617), (1, 0.06119616154829661), (2, 0.04929042911529541), (3, 0.03634108938773473), (4, 0.031204501509666444), (5, 0.025752400040626525), (6, 0.02410782464345296), (7, 0.024723611836632093), (8, 0.02275890805820624), (9, 0.02203265401472648), (10, 0.023085295086105663)]\n",
            "INFO flower 2024-01-14 09:43:45,269 | app.py:183 | app_fit: metrics_centralized {'accuracy': [(0, 0.043666666666666666), (1, 0.331), (2, 0.427), (3, 0.6233333333333333), (4, 0.6696666666666666), (5, 0.738), (6, 0.765), (7, 0.7506666666666667), (8, 0.781), (9, 0.799), (10, 0.7916666666666666)]}\n",
            "History (loss, distributed):\n",
            "\tround 1: 0.02153343149909267\n",
            "\tround 2: 0.017623890958450458\n",
            "\tround 3: 0.01372658685401634\n",
            "\tround 4: 0.012602515457956879\n",
            "\tround 5: 0.011571681289761155\n",
            "\tround 6: 0.011413514349195693\n",
            "\tround 7: 0.01149366488887204\n",
            "\tround 8: 0.011493156397784197\n",
            "\tround 9: 0.011856795508000586\n",
            "\tround 10: 0.012702152530352274\n",
            "History (loss, centralized):\n",
            "\tround 0: 0.07246543502807617\n",
            "\tround 1: 0.06119616154829661\n",
            "\tround 2: 0.04929042911529541\n",
            "\tround 3: 0.03634108938773473\n",
            "\tround 4: 0.031204501509666444\n",
            "\tround 5: 0.025752400040626525\n",
            "\tround 6: 0.02410782464345296\n",
            "\tround 7: 0.024723611836632093\n",
            "\tround 8: 0.02275890805820624\n",
            "\tround 9: 0.02203265401472648\n",
            "\tround 10: 0.023085295086105663\n",
            "History (metrics, centralized):\n",
            "{'accuracy': [(0, 0.043666666666666666), (1, 0.331), (2, 0.427), (3, 0.6233333333333333), (4, 0.6696666666666666), (5, 0.738), (6, 0.765), (7, 0.7506666666666667), (8, 0.781), (9, 0.799), (10, 0.7916666666666666)]}\n",
            "\u001b[0m\u001b[2m\u001b[36m(launch_and_evaluate pid=29992)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0101, accuracy=0.7667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --iid-alpha 0.5 --fraction-fit 1.0 --client-pool-size 10 --num-iterations 1000 --num-rounds 10 --val-ratio 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH9pLlRxEFMH",
        "outputId": "a9983259-107b-4c41-860d-bd1b89f755a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=0.5, 10 classes): [   2  108  230    2   52    8   97   12  799 1390]\n",
            "Data partitioned across 10 clients, with IID alpha = 0.5 and 0.2 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 10 client in the pool.\n",
            "FL round will proceed with 100.0% of clients sampled, at least 2.\n",
            "INFO flower 2024-01-14 09:44:11,575 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-14 09:44:16,576 | app.py:176 | Flower VCE: Ray initialized with resources: {'accelerator_type:V100': 1.0, 'node:172.28.0.12': 1.0, 'GPU': 1.0, 'CPU': 2.0, 'object_store_memory': 3478811443.0, 'memory': 6957622887.0}\n",
            "INFO flower 2024-01-14 09:44:16,576 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-14 09:44:16,576 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-14 09:44:20,821 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-14 09:44:20,821 | server.py:88 | Evaluating initial parameters\n",
            "Evaluation on the server: test_loss=0.0724, test_accuracy=0.1040\n",
            "INFO flower 2024-01-14 09:44:22,966 | server.py:91 | initial parameters (loss, other metrics): 0.07240117383003235, {'accuracy': 0.104}\n",
            "INFO flower 2024-01-14 09:44:22,966 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-14 09:44:22,966 | server.py:215 | fit_round 1: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30335)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30334)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30459)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30495)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30335)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30335)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30334)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30334)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30495)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30459)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30495)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30459)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30335)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30335)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30334)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30334)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30495)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30459)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30335)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 09:52:00,188 | server.py:229 | fit_round 1 received 10 results and 0 failures\n",
            "WARNING flower 2024-01-14 09:52:00,233 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=30334)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0608, test_accuracy=0.2467\n",
            "INFO flower 2024-01-14 09:52:02,131 | server.py:116 | fit progress: (1, 0.06081651337941488, {'accuracy': 0.24666666666666667}, 459.1650602060008)\n",
            "DEBUG flower 2024-01-14 09:52:02,131 | server.py:165 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30335)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0217, accuracy=0.2556\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30334)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0209, accuracy=0.3519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30335)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0217, accuracy=0.3167\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30334)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0214, accuracy=0.1259\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30335)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0222, accuracy=0.0685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30334)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0212, accuracy=0.1519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30335)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0225, accuracy=0.1630\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=30334)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0206, accuracy=0.4685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=32601)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0216, accuracy=0.2241\n",
            "DEBUG flower 2024-01-14 09:52:14,962 | server.py:179 | evaluate_round 1 received 10 results and 0 failures\n",
            "WARNING flower 2024-01-14 09:52:14,962 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-14 09:52:14,962 | server.py:215 | fit_round 2: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=32602)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0223, accuracy=0.3167\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32601)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32602)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32731)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32771)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32602)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32601)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32602)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32601)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32731)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32731)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32771)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32771)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32602)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32601)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32602)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32601)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32731)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32771)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32602)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=32601)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 09:59:48,916 | server.py:229 | fit_round 2 received 10 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0420, test_accuracy=0.4993\n",
            "INFO flower 2024-01-14 09:59:51,184 | server.py:116 | fit progress: (2, 0.04197037768363952, {'accuracy': 0.49933333333333335}, 928.2173627970005)\n",
            "DEBUG flower 2024-01-14 09:59:51,184 | server.py:165 | evaluate_round 2: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=32601)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0087, accuracy=0.7704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=32602)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0152, accuracy=0.6648\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=32602)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0170, accuracy=0.4778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=32601)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0145, accuracy=0.5759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=32601)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0145, accuracy=0.5185\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=32602)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0222, accuracy=0.1481\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=32601)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0189, accuracy=0.4000\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=32602)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0104, accuracy=0.6852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34862)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0225, accuracy=0.2704\n",
            "DEBUG flower 2024-01-14 10:00:04,313 | server.py:179 | evaluate_round 2 received 10 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-14 10:00:04,314 | server.py:215 | fit_round 3: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34863)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0171, accuracy=0.3593\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34862)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34863)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34988)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34987)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34863)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34863)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34862)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34862)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34988)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34988)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34987)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34987)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34863)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34863)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34862)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34862)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34988)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34987)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34987)\u001b[0m E0114 10:06:21.365794758   35027 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34863)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 10:07:42,529 | server.py:229 | fit_round 3 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=34862)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0340, test_accuracy=0.6197\n",
            "INFO flower 2024-01-14 10:07:44,389 | server.py:116 | fit progress: (3, 0.034016960581143695, {'accuracy': 0.6196666666666667}, 1401.4228185470001)\n",
            "DEBUG flower 2024-01-14 10:07:44,389 | server.py:165 | evaluate_round 3: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34862)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0170, accuracy=0.5370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34863)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0152, accuracy=0.4852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34862)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0179, accuracy=0.4667\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34863)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0147, accuracy=0.7130\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34862)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0099, accuracy=0.7389\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34863)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0174, accuracy=0.5259\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34862)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0129, accuracy=0.6296\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=34863)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0120, accuracy=0.6611\n",
            "DEBUG flower 2024-01-14 10:07:57,957 | server.py:179 | evaluate_round 3 received 10 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-14 10:07:57,957 | server.py:215 | fit_round 4: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37110)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0161, accuracy=0.3167\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37111)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0096, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37110)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37111)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37245)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37275)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37110)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37110)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37111)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37111)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37245)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37245)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37275)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37275)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37110)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37110)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37111)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37111)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37245)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37275)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37110)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 10:15:38,559 | server.py:229 | fit_round 4 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37111)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0261, test_accuracy=0.7540\n",
            "INFO flower 2024-01-14 10:15:40,970 | server.py:116 | fit progress: (4, 0.026089702208836874, {'accuracy': 0.754}, 1878.0041683520003)\n",
            "DEBUG flower 2024-01-14 10:15:40,971 | server.py:165 | evaluate_round 4: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37111)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0111, accuracy=0.7130\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37110)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0114, accuracy=0.7333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37110)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0090, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37111)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0107, accuracy=0.7370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37110)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0103, accuracy=0.7981\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37111)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0126, accuracy=0.7222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37111)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0106, accuracy=0.7148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37110)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0157, accuracy=0.6426\n",
            "DEBUG flower 2024-01-14 10:15:53,653 | server.py:179 | evaluate_round 4 received 10 results and 0 failures\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-14 10:15:53,654 | server.py:215 | fit_round 5: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39403)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0129, accuracy=0.6796\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39404)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0136, accuracy=0.6389\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39404)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39403)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39528)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39529)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39404)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39403)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39404)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39403)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39529)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39528)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39529)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39528)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39404)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39404)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39403)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39403)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39529)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39528)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39404)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 10:23:31,929 | server.py:229 | fit_round 5 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39403)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0231, test_accuracy=0.7867\n",
            "INFO flower 2024-01-14 10:23:34,350 | server.py:116 | fit progress: (5, 0.023122668584187826, {'accuracy': 0.7866666666666666}, 2351.384267462)\n",
            "DEBUG flower 2024-01-14 10:23:34,351 | server.py:165 | evaluate_round 5: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39403)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0093, accuracy=0.7907\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39404)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0140, accuracy=0.6537\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39403)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0090, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39404)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0096, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39403)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0115, accuracy=0.7296\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39404)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0098, accuracy=0.7537\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39404)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0131, accuracy=0.7148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39403)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0125, accuracy=0.7741\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41650)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0159, accuracy=0.6611\n",
            "DEBUG flower 2024-01-14 10:23:47,347 | server.py:179 | evaluate_round 5 received 10 results and 0 failures\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-14 10:23:47,347 | server.py:215 | fit_round 6: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41651)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0120, accuracy=0.7148\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41650)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41651)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41771)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41772)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41650)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41650)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41651)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41651)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41771)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41771)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41772)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41772)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41651)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41650)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41651)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41650)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41771)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41772)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41651)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 10:31:05,630 | server.py:229 | fit_round 6 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41650)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0216, test_accuracy=0.7983\n",
            "INFO flower 2024-01-14 10:31:07,748 | server.py:116 | fit progress: (6, 0.021587686359882355, {'accuracy': 0.7983333333333333}, 2804.7813340109997)\n",
            "DEBUG flower 2024-01-14 10:31:07,748 | server.py:165 | evaluate_round 6: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41651)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0085, accuracy=0.8000\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41650)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0160, accuracy=0.6296\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41650)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0125, accuracy=0.7389\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41651)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0114, accuracy=0.7722\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41651)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0080, accuracy=0.8000\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41650)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0116, accuracy=0.7481\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41651)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0094, accuracy=0.7907\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41650)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0114, accuracy=0.7444\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=43812)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0142, accuracy=0.6963\n",
            "DEBUG flower 2024-01-14 10:31:20,553 | server.py:179 | evaluate_round 6 received 10 results and 0 failures\n",
            "Configuring round 7\n",
            "DEBUG flower 2024-01-14 10:31:20,553 | server.py:215 | fit_round 7: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=43814)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0147, accuracy=0.7074\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43812)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43814)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43939)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43980)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43814)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43812)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43814)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43812)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43939)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43939)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43980)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43980)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43812)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43814)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43812)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43814)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43939)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43980)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43939)\u001b[0m E0114 10:37:17.152479116   43988 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43812)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 10:38:36,833 | server.py:229 | fit_round 7 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43814)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0211, test_accuracy=0.8183\n",
            "INFO flower 2024-01-14 10:38:38,922 | server.py:116 | fit progress: (7, 0.02105276735126972, {'accuracy': 0.8183333333333334}, 3255.9558257729996)\n",
            "DEBUG flower 2024-01-14 10:38:38,922 | server.py:165 | evaluate_round 7: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=43812)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0144, accuracy=0.7241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=43814)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0139, accuracy=0.7241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=43812)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0123, accuracy=0.7722\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=43814)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0077, accuracy=0.8370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=43814)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0120, accuracy=0.7463\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=43812)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0150, accuracy=0.7148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=43814)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0163, accuracy=0.6481\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=43812)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0098, accuracy=0.7815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=45992)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0122, accuracy=0.7667\n",
            "DEBUG flower 2024-01-14 10:38:51,292 | server.py:179 | evaluate_round 7 received 10 results and 0 failures\n",
            "Configuring round 8\n",
            "DEBUG flower 2024-01-14 10:38:51,292 | server.py:215 | fit_round 8: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=45994)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0087, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45994)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45992)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46114)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46113)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45992)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45992)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45994)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45994)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46113)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46114)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46114)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46113)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45992)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45992)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45994)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45994)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46114)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46113)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45992)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 10:46:03,284 | server.py:229 | fit_round 8 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45994)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0208, test_accuracy=0.8180\n",
            "INFO flower 2024-01-14 10:46:05,792 | server.py:116 | fit progress: (8, 0.020806779106458027, {'accuracy': 0.818}, 3702.826139013)\n",
            "DEBUG flower 2024-01-14 10:46:05,793 | server.py:165 | evaluate_round 8: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=45992)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0108, accuracy=0.7611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=45994)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0090, accuracy=0.8222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=45992)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0125, accuracy=0.7481\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=45994)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0144, accuracy=0.7204\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=45994)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0170, accuracy=0.6296\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=45992)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0144, accuracy=0.7278\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=45994)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0150, accuracy=0.7278\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=45992)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0118, accuracy=0.7648\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48126)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0074, accuracy=0.8611\n",
            "DEBUG flower 2024-01-14 10:46:16,458 | server.py:179 | evaluate_round 8 received 10 results and 0 failures\n",
            "Configuring round 9\n",
            "DEBUG flower 2024-01-14 10:46:16,459 | server.py:215 | fit_round 9: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48127)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0132, accuracy=0.7611\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48126)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48127)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48246)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48304)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48126)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48127)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48126)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48127)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48304)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48304)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48246)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48246)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48126)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48126)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48127)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48127)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48304)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48304)\u001b[0m E0114 10:52:10.926037938   48327 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48246)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48246)\u001b[0m E0114 10:52:13.804268163   48267 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48126)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 10:53:29,939 | server.py:229 | fit_round 9 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48127)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0200, test_accuracy=0.8203\n",
            "INFO flower 2024-01-14 10:53:31,884 | server.py:116 | fit progress: (9, 0.019961197887857756, {'accuracy': 0.8203333333333334}, 4148.91813155)\n",
            "DEBUG flower 2024-01-14 10:53:31,885 | server.py:165 | evaluate_round 9: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48127)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0144, accuracy=0.7278\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48126)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0134, accuracy=0.7259\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48126)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0115, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48127)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0103, accuracy=0.7852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48126)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0154, accuracy=0.7056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48127)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0118, accuracy=0.7519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48126)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0152, accuracy=0.7000\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48127)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0094, accuracy=0.8037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50229)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0088, accuracy=0.8111\n",
            "DEBUG flower 2024-01-14 10:53:44,563 | server.py:179 | evaluate_round 9 received 10 results and 0 failures\n",
            "Configuring round 10\n",
            "DEBUG flower 2024-01-14 10:53:44,564 | server.py:215 | fit_round 10: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50266)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0162, accuracy=0.6370\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50266)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50229)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50379)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50433)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50266)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50266)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50229)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50229)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50433)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50433)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50379)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50379)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50266)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50266)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50229)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50229)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50433)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50379)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50266)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 11:00:57,458 | server.py:229 | fit_round 10 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50229)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0205, test_accuracy=0.8243\n",
            "INFO flower 2024-01-14 11:00:59,383 | server.py:116 | fit progress: (10, 0.02046744670222203, {'accuracy': 0.8243333333333334}, 4596.416934855001)\n",
            "DEBUG flower 2024-01-14 11:00:59,383 | server.py:165 | evaluate_round 10: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50266)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0151, accuracy=0.7019\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50229)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0070, accuracy=0.8741\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50229)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0181, accuracy=0.6056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50266)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0153, accuracy=0.7241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50266)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0110, accuracy=0.7759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50229)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0125, accuracy=0.7667\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50266)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0123, accuracy=0.7556\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50229)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0100, accuracy=0.7889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=52337)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0135, accuracy=0.7241\n",
            "DEBUG flower 2024-01-14 11:01:12,291 | server.py:179 | evaluate_round 10 received 10 results and 0 failures\n",
            "INFO flower 2024-01-14 11:01:12,291 | server.py:144 | FL finished in 4609.324866144\n",
            "INFO flower 2024-01-14 11:01:12,292 | app.py:180 | app_fit: losses_distributed [(1, 0.021610084308518303), (2, 0.01609693037139045), (3, 0.014267815362524102), (4, 0.011819367519131414), (5, 0.01165724789654767), (6, 0.011771175828244952), (7, 0.012234148261723695), (8, 0.012551393409570058), (9, 0.012631613082355922), (10, 0.013010354654656517)]\n",
            "INFO flower 2024-01-14 11:01:12,292 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2024-01-14 11:01:12,292 | app.py:182 | app_fit: losses_centralized [(0, 0.07240117383003235), (1, 0.06081651337941488), (2, 0.04197037768363952), (3, 0.034016960581143695), (4, 0.026089702208836874), (5, 0.023122668584187826), (6, 0.021587686359882355), (7, 0.02105276735126972), (8, 0.020806779106458027), (9, 0.019961197887857756), (10, 0.02046744670222203)]\n",
            "INFO flower 2024-01-14 11:01:12,292 | app.py:183 | app_fit: metrics_centralized {'accuracy': [(0, 0.104), (1, 0.24666666666666667), (2, 0.49933333333333335), (3, 0.6196666666666667), (4, 0.754), (5, 0.7866666666666666), (6, 0.7983333333333333), (7, 0.8183333333333334), (8, 0.818), (9, 0.8203333333333334), (10, 0.8243333333333334)]}\n",
            "History (loss, distributed):\n",
            "\tround 1: 0.021610084308518303\n",
            "\tround 2: 0.01609693037139045\n",
            "\tround 3: 0.014267815362524102\n",
            "\tround 4: 0.011819367519131414\n",
            "\tround 5: 0.01165724789654767\n",
            "\tround 6: 0.011771175828244952\n",
            "\tround 7: 0.012234148261723695\n",
            "\tround 8: 0.012551393409570058\n",
            "\tround 9: 0.012631613082355922\n",
            "\tround 10: 0.013010354654656517\n",
            "History (loss, centralized):\n",
            "\tround 0: 0.07240117383003235\n",
            "\tround 1: 0.06081651337941488\n",
            "\tround 2: 0.04197037768363952\n",
            "\tround 3: 0.034016960581143695\n",
            "\tround 4: 0.026089702208836874\n",
            "\tround 5: 0.023122668584187826\n",
            "\tround 6: 0.021587686359882355\n",
            "\tround 7: 0.02105276735126972\n",
            "\tround 8: 0.020806779106458027\n",
            "\tround 9: 0.019961197887857756\n",
            "\tround 10: 0.02046744670222203\n",
            "History (metrics, centralized):\n",
            "{'accuracy': [(0, 0.104), (1, 0.24666666666666667), (2, 0.49933333333333335), (3, 0.6196666666666667), (4, 0.754), (5, 0.7866666666666666), (6, 0.7983333333333333), (7, 0.8183333333333334), (8, 0.818), (9, 0.8203333333333334), (10, 0.8243333333333334)]}\n",
            "\u001b[0m\u001b[2m\u001b[36m(launch_and_evaluate pid=52338)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0153, accuracy=0.7111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --iid-alpha 2 --fraction-fit 1.0 --client-pool-size 10 --num-iterations 1000 --num-rounds 10 --val-ratio 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gcdzs1KkEo-3",
        "outputId": "0a12a1bf-22ab-4ab1-8e0d-eb5e9dbfbb4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=2.0, 10 classes): [357 251 338 264  86 323 369 258 209 245]\n",
            "Data partitioned across 10 clients, with IID alpha = 2.0 and 0.2 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 10 client in the pool.\n",
            "FL round will proceed with 100.0% of clients sampled, at least 2.\n",
            "INFO flower 2024-01-14 12:21:00,709 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-14 12:21:05,848 | app.py:176 | Flower VCE: Ray initialized with resources: {'accelerator_type:V100': 1.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0, 'memory': 6995187303.0, 'CPU': 2.0, 'object_store_memory': 3497593651.0}\n",
            "INFO flower 2024-01-14 12:21:05,848 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-14 12:21:05,848 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-14 12:21:09,725 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-14 12:21:09,725 | server.py:88 | Evaluating initial parameters\n",
            "Evaluation on the server: test_loss=0.0723, test_accuracy=0.1177\n",
            "INFO flower 2024-01-14 12:21:12,702 | server.py:91 | initial parameters (loss, other metrics): 0.07227181847890218, {'accuracy': 0.11766666666666667}\n",
            "INFO flower 2024-01-14 12:21:12,702 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-14 12:21:12,702 | server.py:215 | fit_round 1: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1029)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1030)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1166)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1215)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1029)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1029)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1030)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1030)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1166)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1166)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1215)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1215)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1029)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1029)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1030)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1030)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1166)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1166)\u001b[0m E0114 12:26:57.998008424    1218 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1215)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1215)\u001b[0m E0114 12:27:01.206759891    1262 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1029)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 12:28:14,875 | server.py:229 | fit_round 1 received 10 results and 0 failures\n",
            "WARNING flower 2024-01-14 12:28:14,911 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1030)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0494, test_accuracy=0.4927\n",
            "INFO flower 2024-01-14 12:28:16,700 | server.py:116 | fit progress: (1, 0.04943153727054596, {'accuracy': 0.49266666666666664}, 423.997688237)\n",
            "DEBUG flower 2024-01-14 12:28:16,700 | server.py:165 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1029)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0193, accuracy=0.4037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1030)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0181, accuracy=0.4926\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1029)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0165, accuracy=0.4074\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1030)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0162, accuracy=0.5537\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1029)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0156, accuracy=0.5296\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1030)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0169, accuracy=0.5611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1029)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0159, accuracy=0.5426\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=1030)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0167, accuracy=0.4722\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3109)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0224, accuracy=0.3370\n",
            "DEBUG flower 2024-01-14 12:28:28,875 | server.py:179 | evaluate_round 1 received 10 results and 0 failures\n",
            "WARNING flower 2024-01-14 12:28:28,875 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-14 12:28:28,875 | server.py:215 | fit_round 2: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3108)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0181, accuracy=0.5519\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3109)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3108)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3231)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3267)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3108)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3108)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3109)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3109)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3231)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3231)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3267)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3267)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3108)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3108)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3109)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3109)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3231)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3267)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3231)\u001b[0m E0114 12:34:22.710009975    3244 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3267)\u001b[0m E0114 12:34:23.400026347    3305 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3109)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 12:35:33,432 | server.py:229 | fit_round 2 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3108)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0340, test_accuracy=0.7133\n",
            "INFO flower 2024-01-14 12:35:35,698 | server.py:116 | fit progress: (2, 0.034024812132120136, {'accuracy': 0.7133333333333334}, 862.995254557)\n",
            "DEBUG flower 2024-01-14 12:35:35,698 | server.py:165 | evaluate_round 2: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3108)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0157, accuracy=0.6889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3109)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0302, accuracy=0.4019\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3108)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0146, accuracy=0.6519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3109)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0136, accuracy=0.7074\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3108)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0059, accuracy=0.8389\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3109)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0129, accuracy=0.7222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3108)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0187, accuracy=0.6259\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3109)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0059, accuracy=0.8611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3109)\u001b[0m E0114 12:35:43.433992501    3176 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5151)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0083, accuracy=0.7500\n",
            "DEBUG flower 2024-01-14 12:35:46,956 | server.py:179 | evaluate_round 2 received 10 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-14 12:35:46,957 | server.py:215 | fit_round 3: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5152)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0129, accuracy=0.6926\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5151)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5152)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5274)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5306)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5151)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5151)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5152)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5152)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5274)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5274)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5306)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5306)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5151)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5151)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5152)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5152)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5274)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5306)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5152)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 12:43:01,554 | server.py:229 | fit_round 3 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5151)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0314, test_accuracy=0.7417\n",
            "INFO flower 2024-01-14 12:43:03,372 | server.py:116 | fit progress: (3, 0.03139801827073097, {'accuracy': 0.7416666666666667}, 1310.670031357)\n",
            "DEBUG flower 2024-01-14 12:43:03,373 | server.py:165 | evaluate_round 3: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5152)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0064, accuracy=0.8759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5151)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0148, accuracy=0.7222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5151)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0309, accuracy=0.4185\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5152)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0137, accuracy=0.7241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5151)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0205, accuracy=0.6389\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5152)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0156, accuracy=0.6500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5151)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0060, accuracy=0.8593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5152)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0088, accuracy=0.7815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7239)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0142, accuracy=0.7333\n",
            "DEBUG flower 2024-01-14 12:43:18,351 | server.py:179 | evaluate_round 3 received 10 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-14 12:43:18,351 | server.py:215 | fit_round 4: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7292)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0151, accuracy=0.7019\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7239)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7292)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7403)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7404)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7292)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7292)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7239)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7239)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7403)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7403)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7404)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7404)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7292)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7292)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7239)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7239)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7404)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7403)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7403)\u001b[0m E0114 12:49:10.129472377    7418 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7292)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 12:50:22,162 | server.py:229 | fit_round 4 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7239)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0255, test_accuracy=0.7847\n",
            "INFO flower 2024-01-14 12:50:24,083 | server.py:116 | fit progress: (4, 0.02545968483388424, {'accuracy': 0.7846666666666666}, 1751.381014063)\n",
            "DEBUG flower 2024-01-14 12:50:24,084 | server.py:165 | evaluate_round 4: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7239)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0185, accuracy=0.6574\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7292)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0129, accuracy=0.7370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7239)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0125, accuracy=0.7426\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7292)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0246, accuracy=0.4852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7239)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0135, accuracy=0.7241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7292)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0065, accuracy=0.8833\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7239)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0120, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7292)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0069, accuracy=0.8630\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9373)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0152, accuracy=0.6796\n",
            "DEBUG flower 2024-01-14 12:50:36,355 | server.py:179 | evaluate_round 4 received 10 results and 0 failures\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-14 12:50:36,355 | server.py:215 | fit_round 5: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9429)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0097, accuracy=0.7704\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9373)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9429)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9522)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9562)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9429)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9429)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9373)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9373)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9522)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9522)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9562)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9562)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9429)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9429)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9373)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9373)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9522)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9562)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9429)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 12:57:44,666 | server.py:229 | fit_round 5 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9373)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0206, test_accuracy=0.8093\n",
            "INFO flower 2024-01-14 12:57:46,969 | server.py:116 | fit progress: (5, 0.02064772365242243, {'accuracy': 0.8093333333333333}, 2194.2665499709997)\n",
            "DEBUG flower 2024-01-14 12:57:46,969 | server.py:165 | evaluate_round 5: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9373)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0117, accuracy=0.7556\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9429)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0065, accuracy=0.8685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9373)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0133, accuracy=0.6889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9429)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0120, accuracy=0.7296\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9373)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0111, accuracy=0.7667\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9429)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0094, accuracy=0.7741\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9373)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0068, accuracy=0.8537\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9429)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0211, accuracy=0.5259\n",
            "DEBUG flower 2024-01-14 12:57:57,831 | server.py:179 | evaluate_round 5 received 10 results and 0 failures\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-14 12:57:57,831 | server.py:215 | fit_round 6: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11545)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0106, accuracy=0.7667\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11546)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0166, accuracy=0.6667\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11545)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11546)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11663)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11722)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11546)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11546)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11545)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11545)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11663)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11663)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11722)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11722)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11546)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11546)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11545)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11545)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11663)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11722)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11722)\u001b[0m E0114 13:03:56.934219811   11766 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11546)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 13:05:06,970 | server.py:229 | fit_round 6 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=11545)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0187, test_accuracy=0.8347\n",
            "INFO flower 2024-01-14 13:05:08,802 | server.py:116 | fit progress: (6, 0.01873864670097828, {'accuracy': 0.8346666666666667}, 2636.100016948)\n",
            "DEBUG flower 2024-01-14 13:05:08,803 | server.py:165 | evaluate_round 6: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11545)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0118, accuracy=0.7852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11546)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0075, accuracy=0.8389\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11546)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0176, accuracy=0.6667\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11545)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0096, accuracy=0.7889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11546)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0106, accuracy=0.7926\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11545)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0133, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11546)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0131, accuracy=0.7407\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11545)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0064, accuracy=0.8852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=11546)\u001b[0m E0114 13:05:15.296029789   11576 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=13681)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0126, accuracy=0.7593\n",
            "DEBUG flower 2024-01-14 13:05:21,121 | server.py:179 | evaluate_round 6 received 10 results and 0 failures\n",
            "Configuring round 7\n",
            "DEBUG flower 2024-01-14 13:05:21,121 | server.py:215 | fit_round 7: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=13682)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0207, accuracy=0.5815\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13681)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13682)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13806)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13859)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13682)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13682)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13681)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13681)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13806)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13806)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13859)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13859)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13682)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13682)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13681)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13681)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13806)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13859)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13682)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 13:12:20,538 | server.py:229 | fit_round 7 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13681)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0173, test_accuracy=0.8530\n",
            "INFO flower 2024-01-14 13:12:22,308 | server.py:116 | fit progress: (7, 0.017273450617988906, {'accuracy': 0.853}, 3069.605857433)\n",
            "DEBUG flower 2024-01-14 13:12:22,308 | server.py:165 | evaluate_round 7: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=13682)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0133, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=13681)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0138, accuracy=0.7111\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=13681)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0179, accuracy=0.6833\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=13682)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0206, accuracy=0.5704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=13681)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0103, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=13682)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0101, accuracy=0.8019\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=13682)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0115, accuracy=0.7907\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=13681)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0065, accuracy=0.8815\n",
            "DEBUG flower 2024-01-14 13:12:34,483 | server.py:179 | evaluate_round 7 received 10 results and 0 failures\n",
            "Configuring round 8\n",
            "DEBUG flower 2024-01-14 13:12:34,484 | server.py:215 | fit_round 8: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15781)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0073, accuracy=0.8537\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15782)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0123, accuracy=0.7667\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15781)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15782)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15908)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15907)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15782)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15781)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15782)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15781)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15907)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15907)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15908)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15908)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15782)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15782)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15781)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15781)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15907)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15908)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15907)\u001b[0m E0114 13:18:25.231367249   15964 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15782)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15781)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 13:19:42,045 | server.py:229 | fit_round 8 received 10 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0166, test_accuracy=0.8577\n",
            "INFO flower 2024-01-14 13:19:43,978 | server.py:116 | fit progress: (8, 0.016558849026759467, {'accuracy': 0.8576666666666667}, 3511.275301703)\n",
            "DEBUG flower 2024-01-14 13:19:43,978 | server.py:165 | evaluate_round 8: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15781)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0103, accuracy=0.8093\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15782)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0172, accuracy=0.6852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15782)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0135, accuracy=0.7278\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15781)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0124, accuracy=0.7907\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15782)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0113, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15781)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0129, accuracy=0.7463\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15782)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0076, accuracy=0.8444\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15781)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0065, accuracy=0.8981\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=15782)\u001b[0m E0114 13:19:53.114059600   15815 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=17894)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0104, accuracy=0.7741\n",
            "DEBUG flower 2024-01-14 13:19:57,020 | server.py:179 | evaluate_round 8 received 10 results and 0 failures\n",
            "Configuring round 9\n",
            "DEBUG flower 2024-01-14 13:19:57,020 | server.py:215 | fit_round 9: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=17895)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0207, accuracy=0.5722\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=17894)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=17895)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18022)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18021)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=17894)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=17894)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=17895)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=17895)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18021)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18021)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18022)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18022)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=17894)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=17894)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=17895)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=17895)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18021)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18021)\u001b[0m E0114 13:25:47.409043418   18032 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18022)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18022)\u001b[0m E0114 13:25:51.146035146   18044 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=17894)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 13:27:05,342 | server.py:229 | fit_round 9 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=17895)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0158, test_accuracy=0.8653\n",
            "INFO flower 2024-01-14 13:27:07,942 | server.py:116 | fit progress: (9, 0.01582279944916566, {'accuracy': 0.8653333333333333}, 3955.239789192)\n",
            "DEBUG flower 2024-01-14 13:27:07,942 | server.py:165 | evaluate_round 9: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=17894)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0118, accuracy=0.7704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=17895)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0154, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=17895)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0140, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=17894)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0124, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=17895)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0076, accuracy=0.8500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=17894)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0173, accuracy=0.6852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=17895)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0067, accuracy=0.8815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=17894)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0107, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20020)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0202, accuracy=0.5944\n",
            "DEBUG flower 2024-01-14 13:27:18,392 | server.py:179 | evaluate_round 9 received 10 results and 0 failures\n",
            "Configuring round 10\n",
            "DEBUG flower 2024-01-14 13:27:18,392 | server.py:215 | fit_round 10: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20019)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0094, accuracy=0.8111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20019)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20020)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20133)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20134)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20019)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20019)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20020)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20020)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20133)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20133)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20134)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20134)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20019)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20019)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20020)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20020)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20133)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20133)\u001b[0m E0114 13:33:13.549992263   20155 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20134)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20019)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 13:34:27,526 | server.py:229 | fit_round 10 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20020)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0143, test_accuracy=0.8810\n",
            "INFO flower 2024-01-14 13:34:29,299 | server.py:116 | fit progress: (10, 0.014345106116185585, {'accuracy': 0.881}, 4396.596625708999)\n",
            "DEBUG flower 2024-01-14 13:34:29,299 | server.py:165 | evaluate_round 10: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20019)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0088, accuracy=0.8204\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20020)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0144, accuracy=0.7278\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20019)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0124, accuracy=0.7667\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20020)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0202, accuracy=0.6019\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20019)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0119, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20020)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0138, accuracy=0.7630\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20019)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0073, accuracy=0.8815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20020)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0102, accuracy=0.8019\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20019)\u001b[0m E0114 13:34:35.781592001   20030 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20020)\u001b[0m E0114 13:34:36.229981915   20049 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22125)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0176, accuracy=0.6833\n",
            "DEBUG flower 2024-01-14 13:34:42,128 | server.py:179 | evaluate_round 10 received 10 results and 0 failures\n",
            "INFO flower 2024-01-14 13:34:42,128 | server.py:144 | FL finished in 4409.425641295\n",
            "INFO flower 2024-01-14 13:34:42,129 | app.py:180 | app_fit: losses_distributed [(1, 0.017565251345987673), (2, 0.013869114893454092), (3, 0.014613001512156592), (4, 0.0132242212748086), (5, 0.011915144396049005), (6, 0.01232245064995907), (7, 0.012366960446039835), (8, 0.01228745793302854), (9, 0.012553302529785369), (10, 0.012797376049889458)]\n",
            "INFO flower 2024-01-14 13:34:42,129 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2024-01-14 13:34:42,129 | app.py:182 | app_fit: losses_centralized [(0, 0.07227181847890218), (1, 0.04943153727054596), (2, 0.034024812132120136), (3, 0.03139801827073097), (4, 0.02545968483388424), (5, 0.02064772365242243), (6, 0.01873864670097828), (7, 0.017273450617988906), (8, 0.016558849026759467), (9, 0.01582279944916566), (10, 0.014345106116185585)]\n",
            "INFO flower 2024-01-14 13:34:42,129 | app.py:183 | app_fit: metrics_centralized {'accuracy': [(0, 0.11766666666666667), (1, 0.49266666666666664), (2, 0.7133333333333334), (3, 0.7416666666666667), (4, 0.7846666666666666), (5, 0.8093333333333333), (6, 0.8346666666666667), (7, 0.853), (8, 0.8576666666666667), (9, 0.8653333333333333), (10, 0.881)]}\n",
            "History (loss, distributed):\n",
            "\tround 1: 0.017565251345987673\n",
            "\tround 2: 0.013869114893454092\n",
            "\tround 3: 0.014613001512156592\n",
            "\tround 4: 0.0132242212748086\n",
            "\tround 5: 0.011915144396049005\n",
            "\tround 6: 0.01232245064995907\n",
            "\tround 7: 0.012366960446039835\n",
            "\tround 8: 0.01228745793302854\n",
            "\tround 9: 0.012553302529785369\n",
            "\tround 10: 0.012797376049889458\n",
            "History (loss, centralized):\n",
            "\tround 0: 0.07227181847890218\n",
            "\tround 1: 0.04943153727054596\n",
            "\tround 2: 0.034024812132120136\n",
            "\tround 3: 0.03139801827073097\n",
            "\tround 4: 0.02545968483388424\n",
            "\tround 5: 0.02064772365242243\n",
            "\tround 6: 0.01873864670097828\n",
            "\tround 7: 0.017273450617988906\n",
            "\tround 8: 0.016558849026759467\n",
            "\tround 9: 0.01582279944916566\n",
            "\tround 10: 0.014345106116185585\n",
            "History (metrics, centralized):\n",
            "{'accuracy': [(0, 0.11766666666666667), (1, 0.49266666666666664), (2, 0.7133333333333334), (3, 0.7416666666666667), (4, 0.7846666666666666), (5, 0.8093333333333333), (6, 0.8346666666666667), (7, 0.853), (8, 0.8576666666666667), (9, 0.8653333333333333), (10, 0.881)]}\n",
            "\u001b[0m\u001b[2m\u001b[36m(launch_and_evaluate pid=22175)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0113, accuracy=0.7815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --iid-alpha 5 --fraction-fit 1.0 --client-pool-size 10 --num-iterations 1000 --num-rounds 10 --val-ratio 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnbT-U6xEpBF",
        "outputId": "c44de38e-3bb9-46a8-e270-3b7af9c6e2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=5.0, 10 classes): [377 219 449 305  96 283 259 173 168 371]\n",
            "Data partitioned across 10 clients, with IID alpha = 5.0 and 0.2 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 10 client in the pool.\n",
            "FL round will proceed with 100.0% of clients sampled, at least 2.\n",
            "INFO flower 2024-01-14 13:35:12,208 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-14 13:35:17,114 | app.py:176 | Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'GPU': 1.0, 'accelerator_type:V100': 1.0, 'memory': 6999549543.0, 'object_store_memory': 3499774771.0, 'CPU': 2.0}\n",
            "INFO flower 2024-01-14 13:35:17,115 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-14 13:35:17,115 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-14 13:35:20,803 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-14 13:35:20,804 | server.py:88 | Evaluating initial parameters\n",
            "Evaluation on the server: test_loss=0.0721, test_accuracy=0.1420\n",
            "INFO flower 2024-01-14 13:35:22,924 | server.py:91 | initial parameters (loss, other metrics): 0.07207950552304586, {'accuracy': 0.142}\n",
            "INFO flower 2024-01-14 13:35:22,924 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-14 13:35:22,924 | server.py:215 | fit_round 1: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22515)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22516)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22645)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22697)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22515)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22515)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22515)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22516)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22516)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22645)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22645)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22697)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22697)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22515)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22515)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22645)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22516)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22645)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22697)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22515)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 13:42:47,370 | server.py:229 | fit_round 1 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22645)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "WARNING flower 2024-01-14 13:42:47,415 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "Evaluation on the server: test_loss=0.0485, test_accuracy=0.3983\n",
            "INFO flower 2024-01-14 13:42:49,208 | server.py:116 | fit progress: (1, 0.04849874754746755, {'accuracy': 0.3983333333333333}, 446.28445524900053)\n",
            "DEBUG flower 2024-01-14 13:42:49,209 | server.py:165 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22515)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0172, accuracy=0.4296\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22645)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0167, accuracy=0.4944\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22515)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0161, accuracy=0.3611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22645)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0157, accuracy=0.3389\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22645)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0191, accuracy=0.2981\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22515)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0191, accuracy=0.3889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22645)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0190, accuracy=0.4481\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22515)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0170, accuracy=0.4574\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=24726)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0155, accuracy=0.3796\n",
            "DEBUG flower 2024-01-14 13:43:01,275 | server.py:179 | evaluate_round 1 received 10 results and 0 failures\n",
            "WARNING flower 2024-01-14 13:43:01,275 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-14 13:43:01,275 | server.py:215 | fit_round 2: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=24727)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0162, accuracy=0.4352\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24727)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24726)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24850)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24901)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24727)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24727)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24726)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24726)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24850)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24850)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24901)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24901)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24727)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24727)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24726)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24726)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24850)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24901)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24850)\u001b[0m E0114 13:48:53.734321092   24863 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24727)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 13:50:04,340 | server.py:229 | fit_round 2 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=24726)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0351, test_accuracy=0.7130\n",
            "INFO flower 2024-01-14 13:50:06,147 | server.py:116 | fit progress: (2, 0.035115479270617166, {'accuracy': 0.713}, 883.223315874)\n",
            "DEBUG flower 2024-01-14 13:50:06,147 | server.py:165 | evaluate_round 2: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=24727)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0191, accuracy=0.6130\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=24726)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0042, accuracy=0.8926\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=24727)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0111, accuracy=0.7407\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=24726)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0138, accuracy=0.7148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=24727)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0093, accuracy=0.7444\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=24726)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0181, accuracy=0.6296\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=24727)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0187, accuracy=0.6241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=24726)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0146, accuracy=0.6815\n",
            "DEBUG flower 2024-01-14 13:50:18,360 | server.py:179 | evaluate_round 2 received 10 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-14 13:50:18,361 | server.py:215 | fit_round 3: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26841)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0126, accuracy=0.6796\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26842)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0143, accuracy=0.7019\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26841)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26842)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26969)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26970)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26841)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26841)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26842)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26842)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26970)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26969)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26970)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26969)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26841)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26841)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26842)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26842)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26969)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26970)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26842)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 13:57:31,738 | server.py:229 | fit_round 3 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=26841)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0304, test_accuracy=0.7467\n",
            "INFO flower 2024-01-14 13:57:33,690 | server.py:116 | fit progress: (3, 0.030384632458289464, {'accuracy': 0.7466666666666667}, 1330.7660362570005)\n",
            "DEBUG flower 2024-01-14 13:57:33,690 | server.py:165 | evaluate_round 3: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26842)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0087, accuracy=0.8000\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26841)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0176, accuracy=0.6667\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26842)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0131, accuracy=0.7037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26841)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0124, accuracy=0.7426\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26841)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0109, accuracy=0.7704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26842)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0151, accuracy=0.6926\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26841)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0183, accuracy=0.6537\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=26842)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0128, accuracy=0.7278\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28980)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0054, accuracy=0.8944\n",
            "DEBUG flower 2024-01-14 13:57:46,318 | server.py:179 | evaluate_round 3 received 10 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-14 13:57:46,319 | server.py:215 | fit_round 4: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28981)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0155, accuracy=0.6778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28980)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28981)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=29107)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=29108)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28980)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28980)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28981)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28981)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=29107)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=29107)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=29108)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=29108)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28980)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28980)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28981)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28981)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=29107)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=29108)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28980)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 14:05:14,207 | server.py:229 | fit_round 4 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28981)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0224, test_accuracy=0.7987\n",
            "INFO flower 2024-01-14 14:05:16,492 | server.py:116 | fit progress: (4, 0.02240552715957165, {'accuracy': 0.7986666666666666}, 1793.5685144300005)\n",
            "DEBUG flower 2024-01-14 14:05:16,493 | server.py:165 | evaluate_round 4: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28980)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0100, accuracy=0.7907\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28981)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0133, accuracy=0.7370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28980)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0053, accuracy=0.8759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28981)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0083, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28981)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0103, accuracy=0.7833\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28980)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0114, accuracy=0.7556\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28981)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0095, accuracy=0.7796\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28980)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0153, accuracy=0.6870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31186)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0147, accuracy=0.7037\n",
            "DEBUG flower 2024-01-14 14:05:30,457 | server.py:179 | evaluate_round 4 received 10 results and 0 failures\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-14 14:05:30,457 | server.py:215 | fit_round 5: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31218)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0119, accuracy=0.7352\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31186)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31218)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31340)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31339)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31186)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31186)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31218)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31218)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31339)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31340)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31339)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31340)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31218)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31218)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31186)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31186)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31339)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31339)\u001b[0m E0114 14:11:24.841596367   31356 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31340)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31340)\u001b[0m E0114 14:11:26.788861093   31370 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31218)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=31186)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 14:12:37,860 | server.py:229 | fit_round 5 received 10 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0206, test_accuracy=0.8253\n",
            "INFO flower 2024-01-14 14:12:39,925 | server.py:116 | fit progress: (5, 0.02058480914433797, {'accuracy': 0.8253333333333334}, 2237.0007632240004)\n",
            "DEBUG flower 2024-01-14 14:12:39,925 | server.py:165 | evaluate_round 5: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31186)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0128, accuracy=0.7463\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31218)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0155, accuracy=0.6889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31218)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0142, accuracy=0.7389\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31186)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0096, accuracy=0.7926\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31186)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0098, accuracy=0.8019\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31218)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0114, accuracy=0.7704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31186)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0082, accuracy=0.8167\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31218)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0056, accuracy=0.8870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=31218)\u001b[0m E0114 14:12:48.373174530   31257 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33327)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0111, accuracy=0.7778\n",
            "DEBUG flower 2024-01-14 14:12:51,993 | server.py:179 | evaluate_round 5 received 10 results and 0 failures\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-14 14:12:51,993 | server.py:215 | fit_round 6: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33328)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0145, accuracy=0.7111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33327)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33328)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33450)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33501)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33328)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33328)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33327)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33327)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33450)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33450)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33501)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33501)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33328)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33328)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33327)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33327)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33450)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33501)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33450)\u001b[0m E0114 14:18:53.210255330   33464 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33328)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 14:20:11,005 | server.py:229 | fit_round 6 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=33327)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0161, test_accuracy=0.8530\n",
            "INFO flower 2024-01-14 14:20:12,881 | server.py:116 | fit progress: (6, 0.01607712399462859, {'accuracy': 0.853}, 2689.9572771110006)\n",
            "DEBUG flower 2024-01-14 14:20:12,881 | server.py:165 | evaluate_round 6: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33328)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0095, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33327)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0059, accuracy=0.8722\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33327)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0137, accuracy=0.7222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33328)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0120, accuracy=0.7519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33328)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0081, accuracy=0.8185\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33327)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0127, accuracy=0.7370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33328)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0105, accuracy=0.7852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=33327)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0089, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35518)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0136, accuracy=0.7407\n",
            "DEBUG flower 2024-01-14 14:20:25,829 | server.py:179 | evaluate_round 6 received 10 results and 0 failures\n",
            "Configuring round 7\n",
            "DEBUG flower 2024-01-14 14:20:25,829 | server.py:215 | fit_round 7: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35576)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0084, accuracy=0.8074\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35518)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35576)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35673)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35723)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35576)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35576)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35518)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35518)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35673)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35673)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35723)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35723)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35576)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35576)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35518)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35518)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35673)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35673)\u001b[0m E0114 14:26:22.334231557   35682 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35723)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35576)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 14:27:46,880 | server.py:229 | fit_round 7 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=35518)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0156, test_accuracy=0.8670\n",
            "INFO flower 2024-01-14 14:27:49,197 | server.py:116 | fit progress: (7, 0.015599443299074967, {'accuracy': 0.867}, 3146.273100554)\n",
            "DEBUG flower 2024-01-14 14:27:49,197 | server.py:165 | evaluate_round 7: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35518)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0142, accuracy=0.7463\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35576)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0099, accuracy=0.8167\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35518)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0114, accuracy=0.7722\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35576)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0150, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35518)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0065, accuracy=0.8741\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35576)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0091, accuracy=0.8000\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35518)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0107, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=35576)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0150, accuracy=0.7204\n",
            "DEBUG flower 2024-01-14 14:28:01,868 | server.py:179 | evaluate_round 7 received 10 results and 0 failures\n",
            "Configuring round 8\n",
            "DEBUG flower 2024-01-14 14:28:01,868 | server.py:215 | fit_round 8: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37746)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0124, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37747)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0093, accuracy=0.8111\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37747)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37746)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37870)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37871)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37747)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37747)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37746)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37746)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37870)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37870)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37871)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37871)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37747)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37746)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37747)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37746)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37871)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37870)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37747)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 14:35:21,183 | server.py:229 | fit_round 8 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=37746)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0140, test_accuracy=0.8770\n",
            "INFO flower 2024-01-14 14:35:23,576 | server.py:116 | fit progress: (8, 0.013958790853619575, {'accuracy': 0.877}, 3600.6518417550005)\n",
            "DEBUG flower 2024-01-14 14:35:23,576 | server.py:165 | evaluate_round 8: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37746)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0111, accuracy=0.7852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37747)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0062, accuracy=0.8907\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37747)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0098, accuracy=0.8185\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37746)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0099, accuracy=0.8000\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37747)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0130, accuracy=0.7444\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37746)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0110, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37747)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0141, accuracy=0.7370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=37746)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0145, accuracy=0.7259\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39906)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0087, accuracy=0.8241\n",
            "DEBUG flower 2024-01-14 14:35:35,425 | server.py:179 | evaluate_round 8 received 10 results and 0 failures\n",
            "Configuring round 9\n",
            "DEBUG flower 2024-01-14 14:35:35,425 | server.py:215 | fit_round 9: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39964)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0148, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39906)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39964)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40056)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40114)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39964)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39964)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39906)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39906)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40114)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40114)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40056)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40056)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39964)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39964)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39906)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39906)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40114)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40056)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40114)\u001b[0m E0114 14:41:49.243394354   40141 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39964)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 14:43:00,664 | server.py:229 | fit_round 9 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39906)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0135, test_accuracy=0.8853\n",
            "INFO flower 2024-01-14 14:43:03,109 | server.py:116 | fit progress: (9, 0.013469547974256178, {'accuracy': 0.8853333333333333}, 4060.1854415650005)\n",
            "DEBUG flower 2024-01-14 14:43:03,110 | server.py:165 | evaluate_round 9: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39906)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0140, accuracy=0.7611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39964)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0105, accuracy=0.7907\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39964)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0092, accuracy=0.8333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39906)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0146, accuracy=0.7444\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39906)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0115, accuracy=0.7852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39964)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0157, accuracy=0.7352\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39906)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0101, accuracy=0.8130\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39964)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0162, accuracy=0.7370\n",
            "DEBUG flower 2024-01-14 14:43:13,577 | server.py:179 | evaluate_round 9 received 10 results and 0 failures\n",
            "Configuring round 10\n",
            "DEBUG flower 2024-01-14 14:43:13,577 | server.py:215 | fit_round 10: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42150)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0130, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42151)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0065, accuracy=0.8852\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42151)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42150)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42263)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42265)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42150)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42150)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42151)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42151)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42265)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42265)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42263)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42263)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42150)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42150)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42151)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42151)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42263)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42263)\u001b[0m E0114 14:48:59.018452889   42309 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42265)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42151)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 14:50:10,561 | server.py:229 | fit_round 10 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42150)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0130, test_accuracy=0.8910\n",
            "INFO flower 2024-01-14 14:50:13,030 | server.py:116 | fit progress: (10, 0.013030723012052476, {'accuracy': 0.891}, 4490.10633254)\n",
            "DEBUG flower 2024-01-14 14:50:13,030 | server.py:165 | evaluate_round 10: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42151)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0145, accuracy=0.7481\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42150)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0130, accuracy=0.7611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42151)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0102, accuracy=0.7963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42150)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0101, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42151)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0161, accuracy=0.7444\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42150)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0070, accuracy=0.8815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42151)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0148, accuracy=0.7556\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42150)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0151, accuracy=0.7407\n",
            "DEBUG flower 2024-01-14 14:50:23,741 | server.py:179 | evaluate_round 10 received 10 results and 0 failures\n",
            "INFO flower 2024-01-14 14:50:23,742 | server.py:144 | FL finished in 4500.817779186001\n",
            "INFO flower 2024-01-14 14:50:23,742 | app.py:180 | app_fit: losses_distributed [(1, 0.017160763122417308), (2, 0.013575781280243839), (3, 0.012985247323910395), (4, 0.010990233482034118), (5, 0.011256454559387985), (6, 0.010328781429540228), (7, 0.011344342528393975), (8, 0.011294689621362422), (9, 0.012111242413520813), (10, 0.012167947281289984)]\n",
            "INFO flower 2024-01-14 14:50:23,743 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2024-01-14 14:50:23,743 | app.py:182 | app_fit: losses_centralized [(0, 0.07207950552304586), (1, 0.04849874754746755), (2, 0.035115479270617166), (3, 0.030384632458289464), (4, 0.02240552715957165), (5, 0.02058480914433797), (6, 0.01607712399462859), (7, 0.015599443299074967), (8, 0.013958790853619575), (9, 0.013469547974256178), (10, 0.013030723012052476)]\n",
            "INFO flower 2024-01-14 14:50:23,743 | app.py:183 | app_fit: metrics_centralized {'accuracy': [(0, 0.142), (1, 0.3983333333333333), (2, 0.713), (3, 0.7466666666666667), (4, 0.7986666666666666), (5, 0.8253333333333334), (6, 0.853), (7, 0.867), (8, 0.877), (9, 0.8853333333333333), (10, 0.891)]}\n",
            "History (loss, distributed):\n",
            "\tround 1: 0.017160763122417308\n",
            "\tround 2: 0.013575781280243839\n",
            "\tround 3: 0.012985247323910395\n",
            "\tround 4: 0.010990233482034118\n",
            "\tround 5: 0.011256454559387985\n",
            "\tround 6: 0.010328781429540228\n",
            "\tround 7: 0.011344342528393975\n",
            "\tround 8: 0.011294689621362422\n",
            "\tround 9: 0.012111242413520813\n",
            "\tround 10: 0.012167947281289984\n",
            "History (loss, centralized):\n",
            "\tround 0: 0.07207950552304586\n",
            "\tround 1: 0.04849874754746755\n",
            "\tround 2: 0.035115479270617166\n",
            "\tround 3: 0.030384632458289464\n",
            "\tround 4: 0.02240552715957165\n",
            "\tround 5: 0.02058480914433797\n",
            "\tround 6: 0.01607712399462859\n",
            "\tround 7: 0.015599443299074967\n",
            "\tround 8: 0.013958790853619575\n",
            "\tround 9: 0.013469547974256178\n",
            "\tround 10: 0.013030723012052476\n",
            "History (metrics, centralized):\n",
            "{'accuracy': [(0, 0.142), (1, 0.3983333333333333), (2, 0.713), (3, 0.7466666666666667), (4, 0.7986666666666666), (5, 0.8253333333333334), (6, 0.853), (7, 0.867), (8, 0.877), (9, 0.8853333333333333), (10, 0.891)]}\n",
            "\u001b[0m\u001b[2m\u001b[36m(launch_and_evaluate pid=44210)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0092, accuracy=0.8148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=44211)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0117, accuracy=0.7833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --iid-alpha 10 --fraction-fit 1.0 --client-pool-size 10 --num-iterations 1000 --num-rounds 10 --val-ratio 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhvlwxMCEpDl",
        "outputId": "43c0e058-cb80-42b1-fafd-8006f719dafa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=10.0, 10 classes): [299 279 166 220 311 242 293 185 383 322]\n",
            "Data partitioned across 10 clients, with IID alpha = 10.0 and 0.2 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 10 client in the pool.\n",
            "FL round will proceed with 100.0% of clients sampled, at least 2.\n",
            "INFO flower 2024-01-14 14:50:53,603 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-14 14:50:57,768 | app.py:176 | Flower VCE: Ray initialized with resources: {'accelerator_type:V100': 1.0, 'object_store_memory': 3530808115.0, 'memory': 7061616231.0, 'node:172.28.0.12': 1.0, 'CPU': 2.0, 'GPU': 1.0}\n",
            "INFO flower 2024-01-14 14:50:57,776 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-14 14:50:57,776 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-14 14:51:00,371 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-14 14:51:00,371 | server.py:88 | Evaluating initial parameters\n",
            "Evaluation on the server: test_loss=0.0722, test_accuracy=0.0573\n",
            "INFO flower 2024-01-14 14:51:02,464 | server.py:91 | initial parameters (loss, other metrics): 0.07220167748133341, {'accuracy': 0.05733333333333333}\n",
            "INFO flower 2024-01-14 14:51:02,464 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-14 14:51:02,464 | server.py:215 | fit_round 1: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44566)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44565)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44684)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44734)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44566)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44566)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44565)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44565)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44684)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44684)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44734)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44734)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44566)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44566)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44565)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44565)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44684)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44684)\u001b[0m E0114 14:56:57.361775606   44697 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44734)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44566)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 14:58:17,715 | server.py:229 | fit_round 1 received 10 results and 0 failures\n",
            "WARNING flower 2024-01-14 14:58:17,759 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=44565)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0391, test_accuracy=0.5040\n",
            "INFO flower 2024-01-14 14:58:19,740 | server.py:116 | fit progress: (1, 0.03908469339211782, {'accuracy': 0.504}, 437.2762197610009)\n",
            "DEBUG flower 2024-01-14 14:58:19,741 | server.py:165 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=44565)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0139, accuracy=0.5296\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=44566)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0090, accuracy=0.8093\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=44565)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0142, accuracy=0.4981\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=44566)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0148, accuracy=0.4537\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=44565)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0156, accuracy=0.4444\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=44566)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0146, accuracy=0.4704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=44565)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0158, accuracy=0.4259\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=44566)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0141, accuracy=0.4704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=46731)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0132, accuracy=0.5685\n",
            "DEBUG flower 2024-01-14 14:58:33,347 | server.py:179 | evaluate_round 1 received 10 results and 0 failures\n",
            "WARNING flower 2024-01-14 14:58:33,347 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-14 14:58:33,347 | server.py:215 | fit_round 2: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=46771)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0151, accuracy=0.4519\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46771)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46731)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46884)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46886)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46771)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46771)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46731)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46731)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46884)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46884)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46886)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46886)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46771)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46771)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46731)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46731)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46884)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46886)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46771)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 15:05:26,254 | server.py:229 | fit_round 2 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46731)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0231, test_accuracy=0.7723\n",
            "INFO flower 2024-01-14 15:05:28,029 | server.py:116 | fit progress: (2, 0.02305999934176604, {'accuracy': 0.7723333333333333}, 865.5644090090009)\n",
            "DEBUG flower 2024-01-14 15:05:28,029 | server.py:165 | evaluate_round 2: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=46731)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0094, accuracy=0.7574\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=46771)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0114, accuracy=0.7167\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=46771)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0090, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=46731)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0119, accuracy=0.6889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=46731)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0093, accuracy=0.7556\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=46771)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0089, accuracy=0.7722\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=46771)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0041, accuracy=0.8815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=46731)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0105, accuracy=0.7222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=46771)\u001b[0m E0114 15:05:34.247368029   46843 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48777)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0118, accuracy=0.7315\n",
            "DEBUG flower 2024-01-14 15:05:40,300 | server.py:179 | evaluate_round 2 received 10 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-14 15:05:40,300 | server.py:215 | fit_round 3: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48812)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0114, accuracy=0.7130\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48777)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48812)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48925)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48926)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48777)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48777)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48812)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48812)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48925)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48925)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48926)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48926)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48812)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48812)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48777)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48777)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48925)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48926)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48812)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 15:12:40,822 | server.py:229 | fit_round 3 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=48777)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0205, test_accuracy=0.8150\n",
            "INFO flower 2024-01-14 15:12:42,688 | server.py:116 | fit progress: (3, 0.020494024413327375, {'accuracy': 0.815}, 1300.2240875059997)\n",
            "DEBUG flower 2024-01-14 15:12:42,689 | server.py:165 | evaluate_round 3: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48777)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0097, accuracy=0.7889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48812)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0116, accuracy=0.7389\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48777)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0118, accuracy=0.7519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48812)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0050, accuracy=0.8685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48777)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0110, accuracy=0.7648\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48812)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0114, accuracy=0.7481\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48777)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0096, accuracy=0.7611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=48812)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0101, accuracy=0.7907\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50887)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0119, accuracy=0.7352\n",
            "DEBUG flower 2024-01-14 15:12:55,538 | server.py:179 | evaluate_round 3 received 10 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-14 15:12:55,538 | server.py:215 | fit_round 4: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50935)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0086, accuracy=0.8167\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50935)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50887)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51037)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51038)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50935)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50935)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50887)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50887)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51037)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51037)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51038)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51038)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50935)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50935)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50887)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50887)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51037)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51038)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50935)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 15:20:00,298 | server.py:229 | fit_round 4 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50887)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0178, test_accuracy=0.8360\n",
            "INFO flower 2024-01-14 15:20:02,147 | server.py:116 | fit progress: (4, 0.01775965634236733, {'accuracy': 0.836}, 1739.6825679699996)\n",
            "DEBUG flower 2024-01-14 15:20:02,147 | server.py:165 | evaluate_round 4: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50935)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0098, accuracy=0.7852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50887)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0122, accuracy=0.7481\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50935)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0103, accuracy=0.7722\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50887)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0124, accuracy=0.7333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50887)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0106, accuracy=0.7815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50935)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0112, accuracy=0.7574\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50935)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0051, accuracy=0.8741\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50887)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0111, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50935)\u001b[0m E0114 15:20:10.268844613   50962 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=53014)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0087, accuracy=0.8074\n",
            "DEBUG flower 2024-01-14 15:20:14,775 | server.py:179 | evaluate_round 4 received 10 results and 0 failures\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-14 15:20:14,776 | server.py:215 | fit_round 5: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=53050)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0113, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53014)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53050)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53167)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53199)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53050)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53050)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53014)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53014)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53167)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53167)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53199)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53199)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53050)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53050)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53014)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53014)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53167)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53199)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53050)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 15:27:17,092 | server.py:229 | fit_round 5 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53014)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0158, test_accuracy=0.8580\n",
            "INFO flower 2024-01-14 15:27:19,032 | server.py:116 | fit progress: (5, 0.01583532525971532, {'accuracy': 0.858}, 2176.567973952)\n",
            "DEBUG flower 2024-01-14 15:27:19,032 | server.py:165 | evaluate_round 5: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=53014)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0132, accuracy=0.7241\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=53050)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0099, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=53014)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0129, accuracy=0.7389\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=53050)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0116, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=53014)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0095, accuracy=0.8130\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=53050)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0120, accuracy=0.7648\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=53050)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0049, accuracy=0.8796\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=53014)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0116, accuracy=0.7759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55160)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0092, accuracy=0.7963\n",
            "DEBUG flower 2024-01-14 15:27:31,621 | server.py:179 | evaluate_round 5 received 10 results and 0 failures\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-14 15:27:31,621 | server.py:215 | fit_round 6: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55159)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0116, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55160)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55159)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55285)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55287)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55160)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55160)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55159)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55159)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55287)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55287)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55285)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55285)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55160)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55160)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55159)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55159)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55287)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55285)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55160)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 15:34:32,703 | server.py:229 | fit_round 6 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55159)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0137, test_accuracy=0.8790\n",
            "INFO flower 2024-01-14 15:34:34,596 | server.py:116 | fit progress: (6, 0.013675314222152034, {'accuracy': 0.879}, 2612.131285685)\n",
            "DEBUG flower 2024-01-14 15:34:34,596 | server.py:165 | evaluate_round 6: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55159)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0101, accuracy=0.7852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55160)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0131, accuracy=0.7333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55159)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0117, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55160)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0119, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55159)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0094, accuracy=0.7926\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55160)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0116, accuracy=0.7648\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55159)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0115, accuracy=0.7796\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55160)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0098, accuracy=0.8204\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55159)\u001b[0m E0114 15:34:43.306439682   55210 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55160)\u001b[0m E0114 15:34:43.914043982   55190 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=57243)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0050, accuracy=0.8833\n",
            "DEBUG flower 2024-01-14 15:34:47,750 | server.py:179 | evaluate_round 6 received 10 results and 0 failures\n",
            "Configuring round 7\n",
            "DEBUG flower 2024-01-14 15:34:47,751 | server.py:215 | fit_round 7: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=57287)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0127, accuracy=0.7426\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57287)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57243)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57401)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57400)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57243)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57243)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57287)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57287)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57401)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57401)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57400)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57400)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57243)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57243)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57287)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57287)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57401)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57401)\u001b[0m E0114 15:40:47.737930786   57429 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57400)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57400)\u001b[0m E0114 15:40:49.881721611   57410 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57287)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 15:42:01,795 | server.py:229 | fit_round 7 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=57243)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0139, test_accuracy=0.8797\n",
            "INFO flower 2024-01-14 15:42:03,739 | server.py:116 | fit progress: (7, 0.013885804576799273, {'accuracy': 0.8796666666666667}, 3061.274272863)\n",
            "DEBUG flower 2024-01-14 15:42:03,739 | server.py:165 | evaluate_round 7: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=57243)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0112, accuracy=0.7815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=57287)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0114, accuracy=0.8000\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=57243)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0136, accuracy=0.7537\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=57287)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0132, accuracy=0.7463\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=57243)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0129, accuracy=0.7722\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=57287)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0123, accuracy=0.7611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=57243)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0138, accuracy=0.7370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=57287)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0126, accuracy=0.7537\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=59417)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0098, accuracy=0.7926\n",
            "DEBUG flower 2024-01-14 15:42:15,833 | server.py:179 | evaluate_round 7 received 10 results and 0 failures\n",
            "Configuring round 8\n",
            "DEBUG flower 2024-01-14 15:42:15,833 | server.py:215 | fit_round 8: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=59418)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0045, accuracy=0.8926\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59418)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59417)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59542)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59543)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59417)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59417)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59418)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59418)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59542)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59542)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59543)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59543)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59417)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59417)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59418)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59418)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59543)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59542)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59418)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 15:48:58,442 | server.py:229 | fit_round 8 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=59417)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0125, test_accuracy=0.8970\n",
            "INFO flower 2024-01-14 15:49:00,334 | server.py:116 | fit progress: (8, 0.012487781958033642, {'accuracy': 0.897}, 3477.86976634)\n",
            "DEBUG flower 2024-01-14 15:49:00,334 | server.py:165 | evaluate_round 8: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=59418)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0122, accuracy=0.7704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=59417)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0102, accuracy=0.8000\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=59417)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0143, accuracy=0.7370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=59418)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0115, accuracy=0.8111\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=59417)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0054, accuracy=0.8926\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=59418)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0127, accuracy=0.7796\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=59418)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0126, accuracy=0.7704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=59417)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0123, accuracy=0.7981\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=59417)\u001b[0m E0114 15:49:07.481442792   59433 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=59418)\u001b[0m E0114 15:49:07.677609098   59436 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=61417)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0111, accuracy=0.7870\n",
            "DEBUG flower 2024-01-14 15:49:13,121 | server.py:179 | evaluate_round 8 received 10 results and 0 failures\n",
            "Configuring round 9\n",
            "DEBUG flower 2024-01-14 15:49:13,121 | server.py:215 | fit_round 9: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=61464)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0138, accuracy=0.7444\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61464)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61417)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61567)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61568)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61464)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61464)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61417)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61417)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61567)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61567)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61567)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61568)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61568)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61464)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61464)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61417)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61417)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61567)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61568)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61464)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 15:56:10,411 | server.py:229 | fit_round 9 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=61417)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0123, test_accuracy=0.9000\n",
            "INFO flower 2024-01-14 15:56:12,420 | server.py:116 | fit progress: (9, 0.012261535725866754, {'accuracy': 0.9}, 3909.9557196349997)\n",
            "DEBUG flower 2024-01-14 15:56:12,420 | server.py:165 | evaluate_round 9: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=61464)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0127, accuracy=0.7704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=61417)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0136, accuracy=0.7667\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=61464)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0148, accuracy=0.7370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=61417)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0152, accuracy=0.7370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=61464)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0122, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=61417)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0106, accuracy=0.8019\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=61464)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0129, accuracy=0.7741\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=61417)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0134, accuracy=0.7759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=63515)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0056, accuracy=0.8889\n",
            "DEBUG flower 2024-01-14 15:56:26,134 | server.py:179 | evaluate_round 9 received 10 results and 0 failures\n",
            "Configuring round 10\n",
            "DEBUG flower 2024-01-14 15:56:26,134 | server.py:215 | fit_round 10: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=63516)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0122, accuracy=0.8000\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63515)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63516)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63642)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63698)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63516)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63516)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63515)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63515)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63642)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63642)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63698)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63698)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63516)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63516)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63515)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63515)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63698)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63642)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63642)\u001b[0m E0114 16:02:34.279277119   63656 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63516)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=63515)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 16:03:51,830 | server.py:229 | fit_round 10 received 10 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0118, test_accuracy=0.9073\n",
            "INFO flower 2024-01-14 16:03:53,840 | server.py:116 | fit progress: (10, 0.011779481632634998, {'accuracy': 0.9073333333333333}, 4371.375371374001)\n",
            "DEBUG flower 2024-01-14 16:03:53,840 | server.py:165 | evaluate_round 10: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=63515)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0060, accuracy=0.8815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=63516)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0140, accuracy=0.7648\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=63515)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0129, accuracy=0.7833\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=63516)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0128, accuracy=0.7796\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=63515)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0123, accuracy=0.8037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=63516)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0140, accuracy=0.7704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=63515)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0123, accuracy=0.7722\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=63516)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0145, accuracy=0.7426\n",
            "DEBUG flower 2024-01-14 16:04:06,489 | server.py:179 | evaluate_round 10 received 10 results and 0 failures\n",
            "INFO flower 2024-01-14 16:04:06,490 | server.py:144 | FL finished in 4384.025444348001\n",
            "INFO flower 2024-01-14 16:04:06,491 | app.py:180 | app_fit: losses_distributed [(1, 0.01402878252444444), (2, 0.00977903239428997), (3, 0.010071794313413126), (4, 0.010277671372448956), (5, 0.010644542387238255), (6, 0.01068680144018597), (7, 0.011532217512528102), (8, 0.011605280273490481), (9, 0.012313689992383674), (10, 0.012403482016589907)]\n",
            "INFO flower 2024-01-14 16:04:06,491 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2024-01-14 16:04:06,491 | app.py:182 | app_fit: losses_centralized [(0, 0.07220167748133341), (1, 0.03908469339211782), (2, 0.02305999934176604), (3, 0.020494024413327375), (4, 0.01775965634236733), (5, 0.01583532525971532), (6, 0.013675314222152034), (7, 0.013885804576799273), (8, 0.012487781958033642), (9, 0.012261535725866754), (10, 0.011779481632634998)]\n",
            "INFO flower 2024-01-14 16:04:06,491 | app.py:183 | app_fit: metrics_centralized {'accuracy': [(0, 0.05733333333333333), (1, 0.504), (2, 0.7723333333333333), (3, 0.815), (4, 0.836), (5, 0.858), (6, 0.879), (7, 0.8796666666666667), (8, 0.897), (9, 0.9), (10, 0.9073333333333333)]}\n",
            "History (loss, distributed):\n",
            "\tround 1: 0.01402878252444444\n",
            "\tround 2: 0.00977903239428997\n",
            "\tround 3: 0.010071794313413126\n",
            "\tround 4: 0.010277671372448956\n",
            "\tround 5: 0.010644542387238255\n",
            "\tround 6: 0.01068680144018597\n",
            "\tround 7: 0.011532217512528102\n",
            "\tround 8: 0.011605280273490481\n",
            "\tround 9: 0.012313689992383674\n",
            "\tround 10: 0.012403482016589907\n",
            "History (loss, centralized):\n",
            "\tround 0: 0.07220167748133341\n",
            "\tround 1: 0.03908469339211782\n",
            "\tround 2: 0.02305999934176604\n",
            "\tround 3: 0.020494024413327375\n",
            "\tround 4: 0.01775965634236733\n",
            "\tround 5: 0.01583532525971532\n",
            "\tround 6: 0.013675314222152034\n",
            "\tround 7: 0.013885804576799273\n",
            "\tround 8: 0.012487781958033642\n",
            "\tround 9: 0.012261535725866754\n",
            "\tround 10: 0.011779481632634998\n",
            "History (metrics, centralized):\n",
            "{'accuracy': [(0, 0.05733333333333333), (1, 0.504), (2, 0.7723333333333333), (3, 0.815), (4, 0.836), (5, 0.858), (6, 0.879), (7, 0.8796666666666667), (8, 0.897), (9, 0.9), (10, 0.9073333333333333)]}\n",
            "\u001b[0m\u001b[2m\u001b[36m(launch_and_evaluate pid=65737)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0148, accuracy=0.7352\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=65738)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0106, accuracy=0.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --iid-alpha 100 --fraction-fit 1.0 --client-pool-size 10 --num-iterations 1000 --num-rounds 10 --val-ratio 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4cz-GcXE0w4",
        "outputId": "afc306ca-221b-4e77-8db2-0320873f2b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=100.0, 10 classes): [279 272 281 248 292 276 243 292 244 273]\n",
            "Data partitioned across 10 clients, with IID alpha = 100.0 and 0.2 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 10 client in the pool.\n",
            "FL round will proceed with 100.0% of clients sampled, at least 2.\n",
            "INFO flower 2024-01-14 16:04:38,731 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-14 16:04:42,755 | app.py:176 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'object_store_memory': 3572390707.0, 'CPU': 2.0, 'accelerator_type:V100': 1.0, 'node:172.28.0.12': 1.0, 'memory': 7144781415.0}\n",
            "INFO flower 2024-01-14 16:04:42,756 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-14 16:04:42,756 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-14 16:04:45,564 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-14 16:04:45,564 | server.py:88 | Evaluating initial parameters\n",
            "Evaluation on the server: test_loss=0.0722, test_accuracy=0.1127\n",
            "INFO flower 2024-01-14 16:04:47,760 | server.py:91 | initial parameters (loss, other metrics): 0.07223615272839864, {'accuracy': 0.11266666666666666}\n",
            "INFO flower 2024-01-14 16:04:47,760 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-14 16:04:47,761 | server.py:215 | fit_round 1: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66107)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66108)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66230)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66263)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66107)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66107)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66108)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66230)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66108)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66230)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66263)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66263)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66107)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66107)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66108)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66230)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66108)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66263)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66107)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 16:11:56,879 | server.py:229 | fit_round 1 received 10 results and 0 failures\n",
            "WARNING flower 2024-01-14 16:11:56,921 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66108)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0456, test_accuracy=0.4583\n",
            "INFO flower 2024-01-14 16:11:58,780 | server.py:116 | fit progress: (1, 0.045643222053845724, {'accuracy': 0.4583333333333333}, 431.0190386970007)\n",
            "DEBUG flower 2024-01-14 16:11:58,780 | server.py:165 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66107)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0166, accuracy=0.4852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66108)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0129, accuracy=0.6148\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66107)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0172, accuracy=0.4278\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66108)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0173, accuracy=0.4278\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66107)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0174, accuracy=0.4444\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66108)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0178, accuracy=0.4204\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66107)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0177, accuracy=0.3889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66108)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0171, accuracy=0.4167\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=68248)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0173, accuracy=0.4444\n",
            "DEBUG flower 2024-01-14 16:12:11,673 | server.py:179 | evaluate_round 1 received 10 results and 0 failures\n",
            "WARNING flower 2024-01-14 16:12:11,673 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-14 16:12:11,673 | server.py:215 | fit_round 2: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=68299)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0168, accuracy=0.4407\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68248)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68299)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68401)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68453)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68299)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68248)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68299)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68248)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68401)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68401)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68453)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68453)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68299)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68299)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68248)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68248)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68401)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68453)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68299)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=68248)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 16:19:27,354 | server.py:229 | fit_round 2 received 10 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0243, test_accuracy=0.7607\n",
            "INFO flower 2024-01-14 16:19:29,656 | server.py:116 | fit progress: (2, 0.024334576760729153, {'accuracy': 0.7606666666666667}, 881.895314546)\n",
            "DEBUG flower 2024-01-14 16:19:29,656 | server.py:165 | evaluate_round 2: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=68299)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0119, accuracy=0.7056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=68248)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0108, accuracy=0.7333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=68248)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0106, accuracy=0.7296\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=68299)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0116, accuracy=0.6852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=68299)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0096, accuracy=0.7759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=68248)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0062, accuracy=0.8315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=68299)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0108, accuracy=0.7019\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=68248)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0113, accuracy=0.7222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=70452)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0119, accuracy=0.7037\n",
            "DEBUG flower 2024-01-14 16:19:42,034 | server.py:179 | evaluate_round 2 received 10 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-14 16:19:42,035 | server.py:215 | fit_round 3: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=70451)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0137, accuracy=0.6704\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70451)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70452)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70577)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70575)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70452)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70452)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70451)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70451)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70575)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70575)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70577)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70577)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70451)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70451)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70452)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70452)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70575)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70577)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70577)\u001b[0m E0114 16:25:28.613833120   70645 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70451)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 16:26:39,796 | server.py:229 | fit_round 3 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=70452)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0200, test_accuracy=0.8217\n",
            "INFO flower 2024-01-14 16:26:41,899 | server.py:116 | fit progress: (3, 0.01998103838910659, {'accuracy': 0.8216666666666667}, 1314.138786900001)\n",
            "DEBUG flower 2024-01-14 16:26:41,900 | server.py:165 | evaluate_round 3: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=70451)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0105, accuracy=0.7611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=70452)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0104, accuracy=0.7667\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=70451)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0127, accuracy=0.7481\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=70452)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0114, accuracy=0.7537\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=70451)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0101, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=70452)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0103, accuracy=0.7352\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=70451)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0061, accuracy=0.8500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=70452)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0112, accuracy=0.7556\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=72523)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0101, accuracy=0.7796\n",
            "DEBUG flower 2024-01-14 16:26:53,234 | server.py:179 | evaluate_round 3 received 10 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-14 16:26:53,235 | server.py:215 | fit_round 4: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=72559)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0122, accuracy=0.7630\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72523)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72559)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72668)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72726)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72559)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72559)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72523)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72523)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72668)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72668)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72726)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72726)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72559)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72559)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72523)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72523)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72726)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72668)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72559)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 16:33:57,910 | server.py:229 | fit_round 4 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=72523)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0184, test_accuracy=0.8327\n",
            "INFO flower 2024-01-14 16:33:59,746 | server.py:116 | fit progress: (4, 0.018385770867268246, {'accuracy': 0.8326666666666667}, 1751.985065717001)\n",
            "DEBUG flower 2024-01-14 16:33:59,746 | server.py:165 | evaluate_round 4: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=72523)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0112, accuracy=0.7815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=72559)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0111, accuracy=0.7667\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=72523)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0107, accuracy=0.8093\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=72559)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0127, accuracy=0.7611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=72523)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0128, accuracy=0.7519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=72559)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0075, accuracy=0.8333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=72523)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0104, accuracy=0.7667\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=72559)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0107, accuracy=0.7667\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=72523)\u001b[0m E0114 16:34:06.517012999   72561 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=72559)\u001b[0m E0114 16:34:06.570087165   72599 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=74666)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0112, accuracy=0.7574\n",
            "DEBUG flower 2024-01-14 16:34:12,534 | server.py:179 | evaluate_round 4 received 10 results and 0 failures\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-14 16:34:12,534 | server.py:215 | fit_round 5: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=74719)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0103, accuracy=0.7519\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74719)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74666)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74823)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74824)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74719)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74666)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74719)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74666)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74824)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74824)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74823)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74823)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74719)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74666)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74719)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74666)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74824)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74823)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74666)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 16:41:33,505 | server.py:229 | fit_round 5 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=74719)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0170, test_accuracy=0.8517\n",
            "INFO flower 2024-01-14 16:41:35,459 | server.py:116 | fit progress: (5, 0.01698973408838113, {'accuracy': 0.8516666666666667}, 2207.6986785810004)\n",
            "DEBUG flower 2024-01-14 16:41:35,460 | server.py:165 | evaluate_round 5: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=74719)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0114, accuracy=0.7574\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=74666)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0116, accuracy=0.7759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=74719)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0072, accuracy=0.8426\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=74666)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0118, accuracy=0.7574\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=74666)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0108, accuracy=0.8130\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=74719)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0110, accuracy=0.7630\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=74666)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0131, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=74719)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0106, accuracy=0.7833\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=76872)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0126, accuracy=0.7556\n",
            "DEBUG flower 2024-01-14 16:41:48,957 | server.py:179 | evaluate_round 5 received 10 results and 0 failures\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-14 16:41:48,958 | server.py:215 | fit_round 6: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=76925)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0112, accuracy=0.7648\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=76925)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=76872)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=77029)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=77081)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=76925)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=76925)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=76872)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=76872)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=77029)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=77029)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=77081)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=77081)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=76872)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=76925)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=76872)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=76925)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=77029)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=77081)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=77081)\u001b[0m E0114 16:47:44.544559202   77128 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=76872)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 16:48:53,850 | server.py:229 | fit_round 6 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=76925)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0156, test_accuracy=0.8567\n",
            "INFO flower 2024-01-14 16:48:55,685 | server.py:116 | fit progress: (6, 0.015628535063316424, {'accuracy': 0.8566666666666667}, 2647.9243455060005)\n",
            "DEBUG flower 2024-01-14 16:48:55,685 | server.py:165 | evaluate_round 6: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=76925)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0115, accuracy=0.7648\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=76872)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0129, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=76925)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0108, accuracy=0.7759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=76872)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0106, accuracy=0.8093\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=76925)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0115, accuracy=0.7796\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=76872)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0107, accuracy=0.7611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=76925)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0079, accuracy=0.8315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=76872)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0125, accuracy=0.7481\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=76925)\u001b[0m E0114 16:49:04.604194665   76974 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=79030)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0105, accuracy=0.7833\n",
            "DEBUG flower 2024-01-14 16:49:08,209 | server.py:179 | evaluate_round 6 received 10 results and 0 failures\n",
            "Configuring round 7\n",
            "DEBUG flower 2024-01-14 16:49:08,209 | server.py:215 | fit_round 7: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=79029)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0113, accuracy=0.7704\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79029)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79030)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79153)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79155)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79029)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79029)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79030)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79030)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79155)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79155)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79153)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79153)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79029)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79029)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79030)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79030)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79155)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=79153)\u001b[0m Client 1: training round complete, 31776 examples processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --iid-alpha 1000 --fraction-fit 1.0 --client-pool-size 10 --num-iterations 1000 --num-rounds 10 --val-ratio 0.2"
      ],
      "metadata": {
        "id": "yUJ8ETKhE0zK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deab7e0a-e28f-46a1-c145-7bf02b26932b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=1000.0, 10 classes): [268 273 279 261 270 265 260 280 272 272]\n",
            "Data partitioned across 10 clients, with IID alpha = 1000.0 and 0.2 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 10 client in the pool.\n",
            "FL round will proceed with 100.0% of clients sampled, at least 2.\n",
            "INFO flower 2024-01-14 16:58:43,446 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-14 16:58:47,541 | app.py:176 | Flower VCE: Ray initialized with resources: {'memory': 6975873024.0, 'CPU': 2.0, 'node:172.28.0.12': 1.0, 'object_store_memory': 3487936512.0, 'GPU': 1.0, 'accelerator_type:V100': 1.0}\n",
            "INFO flower 2024-01-14 16:58:47,542 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-14 16:58:47,542 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-14 16:58:50,191 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-14 16:58:50,191 | server.py:88 | Evaluating initial parameters\n",
            "Evaluation on the server: test_loss=0.0723, test_accuracy=0.1233\n",
            "INFO flower 2024-01-14 16:58:52,984 | server.py:91 | initial parameters (loss, other metrics): 0.07225813317298889, {'accuracy': 0.12333333333333334}\n",
            "INFO flower 2024-01-14 16:58:52,984 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-14 16:58:52,984 | server.py:215 | fit_round 1: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4975)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4974)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5100)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5137)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4975)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4975)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4974)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4974)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5100)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5100)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5137)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5137)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4975)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4975)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4974)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4974)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5100)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5137)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5137)\u001b[0m E0114 17:04:14.130165320    5181 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4975)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 17:05:20,968 | server.py:229 | fit_round 1 received 10 results and 0 failures\n",
            "WARNING flower 2024-01-14 17:05:21,007 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4974)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0388, test_accuracy=0.5627\n",
            "INFO flower 2024-01-14 17:05:22,602 | server.py:116 | fit progress: (1, 0.038783253212769826, {'accuracy': 0.5626666666666666}, 389.61753967100003)\n",
            "DEBUG flower 2024-01-14 17:05:22,602 | server.py:165 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=4975)\u001b[0m E0114 17:05:22.634818477    5066 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=4974)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0153, accuracy=0.5222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=4974)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0138, accuracy=0.5815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=4975)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0154, accuracy=0.5278\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=4974)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0127, accuracy=0.5981\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=4975)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0147, accuracy=0.5370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=4974)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0151, accuracy=0.5315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=4975)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0149, accuracy=0.5370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=4974)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0151, accuracy=0.5333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6866)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0155, accuracy=0.5093\n",
            "DEBUG flower 2024-01-14 17:05:34,677 | server.py:179 | evaluate_round 1 received 10 results and 0 failures\n",
            "WARNING flower 2024-01-14 17:05:34,677 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-14 17:05:34,677 | server.py:215 | fit_round 2: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6917)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0115, accuracy=0.6481\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6866)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6917)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7015)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7067)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6866)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6866)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6917)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6917)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7015)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7015)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7067)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7067)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6866)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6866)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6917)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6917)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7015)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7067)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7067)\u001b[0m E0114 17:10:54.730914530    7114 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6866)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 17:11:58,942 | server.py:229 | fit_round 2 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6917)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0218, test_accuracy=0.7777\n",
            "INFO flower 2024-01-14 17:12:01,250 | server.py:116 | fit progress: (2, 0.02175638713936011, {'accuracy': 0.7776666666666666}, 788.2657370640002)\n",
            "DEBUG flower 2024-01-14 17:12:01,250 | server.py:165 | evaluate_round 2: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6866)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0113, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6917)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0092, accuracy=0.7519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6866)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0079, accuracy=0.7852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6917)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0106, accuracy=0.7056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6866)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0110, accuracy=0.7315\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6917)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0072, accuracy=0.7889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6866)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0099, accuracy=0.7444\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6917)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0104, accuracy=0.7389\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6917)\u001b[0m E0114 17:12:08.402867972    6937 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8764)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0091, accuracy=0.7278\n",
            "DEBUG flower 2024-01-14 17:12:11,642 | server.py:179 | evaluate_round 2 received 10 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-14 17:12:11,643 | server.py:215 | fit_round 3: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8821)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0094, accuracy=0.7407\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8764)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8821)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8907)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8906)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8764)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8764)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8821)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8821)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8907)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8907)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8906)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8906)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8764)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8764)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8821)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8821)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8907)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8906)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8764)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 17:18:35,355 | server.py:229 | fit_round 3 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8821)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0176, test_accuracy=0.8190\n",
            "INFO flower 2024-01-14 17:18:37,033 | server.py:116 | fit progress: (3, 0.017644575737416745, {'accuracy': 0.819}, 1184.0485990920001)\n",
            "DEBUG flower 2024-01-14 17:18:37,033 | server.py:165 | evaluate_round 3: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8764)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0081, accuracy=0.7981\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8821)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0101, accuracy=0.7519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8764)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0090, accuracy=0.7611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8821)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0089, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8764)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0109, accuracy=0.7444\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8821)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0100, accuracy=0.7611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8821)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0064, accuracy=0.8333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8764)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0079, accuracy=0.7556\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8764)\u001b[0m E0114 17:18:43.307034265    8783 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8821)\u001b[0m E0114 17:18:43.253781269    8841 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10625)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0093, accuracy=0.7630\n",
            "DEBUG flower 2024-01-14 17:18:47,655 | server.py:179 | evaluate_round 3 received 10 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-14 17:18:47,655 | server.py:215 | fit_round 4: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10626)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0098, accuracy=0.7537\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10625)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10626)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10739)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10740)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10626)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10626)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10625)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10625)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10740)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10740)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10739)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10739)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10626)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10626)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10625)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10625)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10740)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10740)\u001b[0m E0114 17:24:01.592144047   10760 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10739)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10739)\u001b[0m E0114 17:24:07.106050779   10763 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10625)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 17:25:12,082 | server.py:229 | fit_round 4 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10626)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0161, test_accuracy=0.8450\n",
            "INFO flower 2024-01-14 17:25:13,756 | server.py:116 | fit progress: (4, 0.016097461760044098, {'accuracy': 0.845}, 1580.77125758)\n",
            "DEBUG flower 2024-01-14 17:25:13,756 | server.py:165 | evaluate_round 4: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10626)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0099, accuracy=0.7741\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10625)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0076, accuracy=0.8333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10626)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0089, accuracy=0.8037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10625)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0098, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10626)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0107, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10625)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0094, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10626)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0082, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10625)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0103, accuracy=0.7815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12464)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0084, accuracy=0.8222\n",
            "DEBUG flower 2024-01-14 17:25:25,246 | server.py:179 | evaluate_round 4 received 10 results and 0 failures\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-14 17:25:25,247 | server.py:215 | fit_round 5: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12465)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0114, accuracy=0.7593\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12464)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12465)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12581)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12632)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12464)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12464)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12465)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12465)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12581)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12581)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12632)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12632)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12465)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12465)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12464)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12464)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12581)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12632)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12464)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 17:31:57,947 | server.py:229 | fit_round 5 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12465)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0152, test_accuracy=0.8580\n",
            "INFO flower 2024-01-14 17:31:59,622 | server.py:116 | fit progress: (5, 0.015243295520544053, {'accuracy': 0.858}, 1986.637406059)\n",
            "DEBUG flower 2024-01-14 17:31:59,622 | server.py:165 | evaluate_round 5: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12464)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0096, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12465)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0120, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12464)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0085, accuracy=0.8296\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12465)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0129, accuracy=0.7611\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12464)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0110, accuracy=0.7833\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12465)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0098, accuracy=0.7741\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12464)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0083, accuracy=0.8222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12465)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0097, accuracy=0.7926\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12464)\u001b[0m E0114 17:32:05.487028795   12473 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12465)\u001b[0m E0114 17:32:06.328051871   12528 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14363)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0101, accuracy=0.7870\n",
            "DEBUG flower 2024-01-14 17:32:11,859 | server.py:179 | evaluate_round 5 received 10 results and 0 failures\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-14 17:32:11,859 | server.py:215 | fit_round 6: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14415)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0102, accuracy=0.7926\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14363)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14415)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14510)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14511)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14415)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14415)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14363)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14363)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14510)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14510)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14511)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14511)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14415)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14415)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14363)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14363)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14511)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14510)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14510)\u001b[0m E0114 17:37:41.803742675   14525 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14415)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 17:38:51,511 | server.py:229 | fit_round 6 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14363)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0128, test_accuracy=0.8720\n",
            "INFO flower 2024-01-14 17:38:53,241 | server.py:116 | fit progress: (6, 0.01283630229284366, {'accuracy': 0.872}, 2400.256482262)\n",
            "DEBUG flower 2024-01-14 17:38:53,241 | server.py:165 | evaluate_round 6: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14363)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0081, accuracy=0.8222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14415)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0095, accuracy=0.7852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14363)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0115, accuracy=0.7852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14415)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0077, accuracy=0.8333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14363)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0120, accuracy=0.7704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14415)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0101, accuracy=0.8000\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14363)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0089, accuracy=0.7741\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14415)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0100, accuracy=0.7796\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16302)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0103, accuracy=0.7815\n",
            "DEBUG flower 2024-01-14 17:39:05,618 | server.py:179 | evaluate_round 6 received 10 results and 0 failures\n",
            "Configuring round 7\n",
            "DEBUG flower 2024-01-14 17:39:05,619 | server.py:215 | fit_round 7: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16339)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0097, accuracy=0.7741\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16339)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16302)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16454)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16506)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16339)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16339)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16302)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16302)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16454)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16454)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16506)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16506)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16339)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16339)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16302)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16302)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16506)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16506)\u001b[0m E0114 17:44:39.280520725   16552 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16454)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16339)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 17:45:49,390 | server.py:229 | fit_round 7 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=16302)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0129, test_accuracy=0.8827\n",
            "INFO flower 2024-01-14 17:45:51,636 | server.py:116 | fit progress: (7, 0.012939079436163108, {'accuracy': 0.8826666666666667}, 2818.6521202940003)\n",
            "DEBUG flower 2024-01-14 17:45:51,637 | server.py:165 | evaluate_round 7: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16302)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0111, accuracy=0.7796\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16339)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0128, accuracy=0.7630\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16302)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0094, accuracy=0.8074\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16339)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0122, accuracy=0.7630\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16302)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0084, accuracy=0.8222\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16339)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0102, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16302)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0100, accuracy=0.7981\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16339)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0110, accuracy=0.7926\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16302)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=16339)\u001b[0m E0114 17:45:59.360751361   16403 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18283)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0096, accuracy=0.7907\n",
            "DEBUG flower 2024-01-14 17:46:03,024 | server.py:179 | evaluate_round 7 received 10 results and 0 failures\n",
            "Configuring round 8\n",
            "DEBUG flower 2024-01-14 17:46:03,024 | server.py:215 | fit_round 8: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18341)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0109, accuracy=0.7870\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18341)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18283)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18430)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18482)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18341)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18341)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18283)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18283)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18430)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18430)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18482)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18482)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18341)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18341)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18283)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18283)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18430)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18482)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18341)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=18283)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 17:52:44,997 | server.py:229 | fit_round 8 received 10 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0125, test_accuracy=0.8823\n",
            "INFO flower 2024-01-14 17:52:46,873 | server.py:116 | fit progress: (8, 0.01248957589889566, {'accuracy': 0.8823333333333333}, 3233.888447778)\n",
            "DEBUG flower 2024-01-14 17:52:46,873 | server.py:165 | evaluate_round 8: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18341)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0109, accuracy=0.7926\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18283)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0082, accuracy=0.8278\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18341)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0117, accuracy=0.7852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18283)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0106, accuracy=0.7722\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18341)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0103, accuracy=0.7815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18283)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0099, accuracy=0.7852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18341)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0092, accuracy=0.8037\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18283)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0132, accuracy=0.7500\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18341)\u001b[0m E0114 17:52:53.013998858   18388 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=18283)\u001b[0m E0114 17:52:53.528079927   18344 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20253)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0114, accuracy=0.7685\n",
            "DEBUG flower 2024-01-14 17:52:57,105 | server.py:179 | evaluate_round 8 received 10 results and 0 failures\n",
            "Configuring round 9\n",
            "DEBUG flower 2024-01-14 17:52:57,105 | server.py:215 | fit_round 9: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20254)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0127, accuracy=0.7556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20253)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20254)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20367)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20366)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20254)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20253)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20254)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20253)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20367)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20367)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20366)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20366)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20254)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20254)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20253)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20253)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20367)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20366)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20366)\u001b[0m E0114 17:58:27.035073300   20385 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20254)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 17:59:35,571 | server.py:229 | fit_round 9 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=20253)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0117, test_accuracy=0.8947\n",
            "INFO flower 2024-01-14 17:59:37,325 | server.py:116 | fit progress: (9, 0.011688303685436646, {'accuracy': 0.8946666666666667}, 3644.340504926)\n",
            "DEBUG flower 2024-01-14 17:59:37,325 | server.py:165 | evaluate_round 9: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20253)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0118, accuracy=0.7704\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20254)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0128, accuracy=0.7556\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20253)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0134, accuracy=0.7519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20254)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0116, accuracy=0.7759\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20253)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0078, accuracy=0.8370\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20254)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0103, accuracy=0.7796\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20253)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0102, accuracy=0.7889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=20254)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0101, accuracy=0.7944\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22148)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0091, accuracy=0.7907\n",
            "DEBUG flower 2024-01-14 17:59:48,612 | server.py:179 | evaluate_round 9 received 10 results and 0 failures\n",
            "Configuring round 10\n",
            "DEBUG flower 2024-01-14 17:59:48,612 | server.py:215 | fit_round 10: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22150)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0114, accuracy=0.7778\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22150)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22148)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22265)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22305)\u001b[0m Client 9: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22150)\u001b[0m Client 7: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22150)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22148)\u001b[0m Client 6: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22148)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22265)\u001b[0m Client 1: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22265)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22305)\u001b[0m Client 9: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22305)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22148)\u001b[0m Client 4: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22150)\u001b[0m Client 3: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22148)\u001b[0m Client 8: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22150)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22265)\u001b[0m Client 5: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22305)\u001b[0m Client 2: training round complete, 31776 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22305)\u001b[0m E0114 18:05:16.994058490   22340 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22148)\u001b[0m Client 8: training round complete, 31776 examples processed\n",
            "DEBUG flower 2024-01-14 18:06:26,894 | server.py:229 | fit_round 10 received 10 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=22150)\u001b[0m Client 0: training round complete, 31776 examples processed\n",
            "Evaluation on the server: test_loss=0.0115, test_accuracy=0.8933\n",
            "INFO flower 2024-01-14 18:06:28,661 | server.py:116 | fit progress: (10, 0.011455100043366353, {'accuracy': 0.8933333333333333}, 4055.6766613669997)\n",
            "DEBUG flower 2024-01-14 18:06:28,661 | server.py:165 | evaluate_round 10: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22148)\u001b[0m Client 5: evaluation on 540 examples: loss=0.0103, accuracy=0.7815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22150)\u001b[0m Client 4: evaluation on 540 examples: loss=0.0118, accuracy=0.7685\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22148)\u001b[0m Client 8: evaluation on 540 examples: loss=0.0113, accuracy=0.7889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22150)\u001b[0m Client 3: evaluation on 540 examples: loss=0.0102, accuracy=0.8056\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22148)\u001b[0m Client 2: evaluation on 540 examples: loss=0.0105, accuracy=0.7815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22150)\u001b[0m Client 7: evaluation on 540 examples: loss=0.0136, accuracy=0.7519\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22148)\u001b[0m Client 9: evaluation on 540 examples: loss=0.0081, accuracy=0.8463\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22150)\u001b[0m Client 0: evaluation on 540 examples: loss=0.0093, accuracy=0.7852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22148)\u001b[0m E0114 18:06:35.117441348   22159 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=22150)\u001b[0m E0114 18:06:35.189350504   22167 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=24120)\u001b[0m Client 6: evaluation on 540 examples: loss=0.0116, accuracy=0.7611\n",
            "DEBUG flower 2024-01-14 18:06:40,587 | server.py:179 | evaluate_round 10 received 10 results and 0 failures\n",
            "INFO flower 2024-01-14 18:06:40,588 | server.py:144 | FL finished in 4067.6033049730004\n",
            "INFO flower 2024-01-14 18:06:40,589 | app.py:180 | app_fit: losses_distributed [(1, 0.014408265859992416), (2, 0.00960040086949313), (3, 0.009039257466793061), (4, 0.009473287559769773), (5, 0.010197786136909767), (6, 0.009787784185674456), (7, 0.010559742279626704), (8, 0.010805113497707578), (9, 0.010860599922361198), (10, 0.011056642962826622)]\n",
            "INFO flower 2024-01-14 18:06:40,589 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2024-01-14 18:06:40,589 | app.py:182 | app_fit: losses_centralized [(0, 0.07225813317298889), (1, 0.038783253212769826), (2, 0.02175638713936011), (3, 0.017644575737416745), (4, 0.016097461760044098), (5, 0.015243295520544053), (6, 0.01283630229284366), (7, 0.012939079436163108), (8, 0.01248957589889566), (9, 0.011688303685436646), (10, 0.011455100043366353)]\n",
            "INFO flower 2024-01-14 18:06:40,589 | app.py:183 | app_fit: metrics_centralized {'accuracy': [(0, 0.12333333333333334), (1, 0.5626666666666666), (2, 0.7776666666666666), (3, 0.819), (4, 0.845), (5, 0.858), (6, 0.872), (7, 0.8826666666666667), (8, 0.8823333333333333), (9, 0.8946666666666667), (10, 0.8933333333333333)]}\n",
            "History (loss, distributed):\n",
            "\tround 1: 0.014408265859992416\n",
            "\tround 2: 0.00960040086949313\n",
            "\tround 3: 0.009039257466793061\n",
            "\tround 4: 0.009473287559769773\n",
            "\tround 5: 0.010197786136909767\n",
            "\tround 6: 0.009787784185674456\n",
            "\tround 7: 0.010559742279626704\n",
            "\tround 8: 0.010805113497707578\n",
            "\tround 9: 0.010860599922361198\n",
            "\tround 10: 0.011056642962826622\n",
            "History (loss, centralized):\n",
            "\tround 0: 0.07225813317298889\n",
            "\tround 1: 0.038783253212769826\n",
            "\tround 2: 0.02175638713936011\n",
            "\tround 3: 0.017644575737416745\n",
            "\tround 4: 0.016097461760044098\n",
            "\tround 5: 0.015243295520544053\n",
            "\tround 6: 0.01283630229284366\n",
            "\tround 7: 0.012939079436163108\n",
            "\tround 8: 0.01248957589889566\n",
            "\tround 9: 0.011688303685436646\n",
            "\tround 10: 0.011455100043366353\n",
            "History (metrics, centralized):\n",
            "{'accuracy': [(0, 0.12333333333333334), (1, 0.5626666666666666), (2, 0.7776666666666666), (3, 0.819), (4, 0.845), (5, 0.858), (6, 0.872), (7, 0.8826666666666667), (8, 0.8823333333333333), (9, 0.8946666666666667), (10, 0.8933333333333333)]}\n",
            "\u001b[0m\u001b[2m\u001b[36m(launch_and_evaluate pid=24121)\u001b[0m Client 1: evaluation on 540 examples: loss=0.0140, accuracy=0.7463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zaAuaRTEE5J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --iid-alpha 10 --fraction-fit 0.3 --client-pool-size 10 --num-iterations 1000 --num-rounds 10 --val-ratio 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIY33o87QLa5",
        "outputId": "beae61ee-925a-4dd6-f3b2-400233452d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=10.0, 10 classes): [238 191 289 319 380 389 143 353 220 178]\n",
            "Data partitioned across 10 clients, with IID alpha = 10.0 and 0.2 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 10 client in the pool.\n",
            "FL round will proceed with 30.0% of clients sampled, at least 2.\n",
            "INFO flower 2024-01-15 16:59:31,688 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-15 16:59:36,521 | app.py:176 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'accelerator_type:V100': 1.0, 'CPU': 2.0, 'node:172.28.0.12': 1.0, 'object_store_memory': 3484237824.0, 'memory': 6968475648.0}\n",
            "INFO flower 2024-01-15 16:59:36,521 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-15 16:59:36,521 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-15 16:59:39,592 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-15 16:59:39,592 | server.py:88 | Evaluating initial parameters\n",
            "INFO flower 2024-01-15 16:59:39,592 | server.py:101 | FL starting\n",
            "DEBUG flower 2024-01-15 16:59:39,592 | server.py:215 | fit_round 1: strategy sampled 7 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 16:59:45,435 | server.py:229 | fit_round 1 received 0 results and 7 failures\n",
            "DEBUG flower 2024-01-15 16:59:45,435 | server.py:165 | evaluate_round 1: strategy sampled 3 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 16:59:50,819 | server.py:179 | evaluate_round 1 received 0 results and 3 failures\n",
            "DEBUG flower 2024-01-15 16:59:50,819 | server.py:215 | fit_round 2: strategy sampled 7 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 16:59:56,768 | server.py:229 | fit_round 2 received 0 results and 7 failures\n",
            "DEBUG flower 2024-01-15 16:59:56,768 | server.py:165 | evaluate_round 2: strategy sampled 3 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 17:00:00,836 | server.py:179 | evaluate_round 2 received 0 results and 3 failures\n",
            "DEBUG flower 2024-01-15 17:00:00,836 | server.py:215 | fit_round 3: strategy sampled 3 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 17:00:08,480 | server.py:229 | fit_round 3 received 0 results and 3 failures\n",
            "DEBUG flower 2024-01-15 17:00:08,480 | server.py:165 | evaluate_round 3: strategy sampled 3 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 17:00:12,566 | server.py:179 | evaluate_round 3 received 0 results and 3 failures\n",
            "DEBUG flower 2024-01-15 17:00:12,567 | server.py:215 | fit_round 4: strategy sampled 5 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 17:00:18,665 | server.py:229 | fit_round 4 received 0 results and 5 failures\n",
            "DEBUG flower 2024-01-15 17:00:18,665 | server.py:165 | evaluate_round 4: strategy sampled 3 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 17:00:24,133 | server.py:179 | evaluate_round 4 received 0 results and 3 failures\n",
            "DEBUG flower 2024-01-15 17:00:24,134 | server.py:215 | fit_round 5: strategy sampled 7 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 17:00:29,684 | server.py:229 | fit_round 5 received 0 results and 7 failures\n",
            "DEBUG flower 2024-01-15 17:00:29,684 | server.py:165 | evaluate_round 5: strategy sampled 3 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 17:00:34,868 | server.py:179 | evaluate_round 5 received 0 results and 3 failures\n",
            "DEBUG flower 2024-01-15 17:00:34,868 | server.py:215 | fit_round 6: strategy sampled 4 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 17:00:41,224 | server.py:229 | fit_round 6 received 0 results and 4 failures\n",
            "DEBUG flower 2024-01-15 17:00:41,225 | server.py:165 | evaluate_round 6: strategy sampled 3 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 17:00:45,332 | server.py:179 | evaluate_round 6 received 0 results and 3 failures\n",
            "DEBUG flower 2024-01-15 17:00:45,333 | server.py:215 | fit_round 7: strategy sampled 3 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 17:00:52,715 | server.py:229 | fit_round 7 received 0 results and 3 failures\n",
            "DEBUG flower 2024-01-15 17:00:52,716 | server.py:165 | evaluate_round 7: strategy sampled 3 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 17:00:56,710 | server.py:179 | evaluate_round 7 received 0 results and 3 failures\n",
            "DEBUG flower 2024-01-15 17:00:56,710 | server.py:215 | fit_round 8: strategy sampled 7 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 17:01:02,560 | server.py:229 | fit_round 8 received 0 results and 7 failures\n",
            "DEBUG flower 2024-01-15 17:01:02,560 | server.py:165 | evaluate_round 8: strategy sampled 3 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 17:01:08,285 | server.py:179 | evaluate_round 8 received 0 results and 3 failures\n",
            "DEBUG flower 2024-01-15 17:01:08,285 | server.py:215 | fit_round 9: strategy sampled 6 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 17:01:13,775 | server.py:229 | fit_round 9 received 0 results and 6 failures\n",
            "DEBUG flower 2024-01-15 17:01:13,775 | server.py:165 | evaluate_round 9: strategy sampled 3 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 17:01:20,340 | server.py:179 | evaluate_round 9 received 0 results and 3 failures\n",
            "DEBUG flower 2024-01-15 17:01:20,340 | server.py:215 | fit_round 10: strategy sampled 9 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 17:01:26,264 | server.py:229 | fit_round 10 received 0 results and 9 failures\n",
            "DEBUG flower 2024-01-15 17:01:26,265 | server.py:165 | evaluate_round 10: strategy sampled 3 clients (out of 10)\n",
            "DEBUG flower 2024-01-15 17:01:30,277 | server.py:179 | evaluate_round 10 received 0 results and 3 failures\n",
            "INFO flower 2024-01-15 17:01:30,277 | server.py:144 | FL finished in 110.68556916800003\n",
            "INFO flower 2024-01-15 17:01:30,278 | app.py:180 | app_fit: losses_distributed []\n",
            "INFO flower 2024-01-15 17:01:30,278 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2024-01-15 17:01:30,279 | app.py:182 | app_fit: losses_centralized []\n",
            "INFO flower 2024-01-15 17:01:30,279 | app.py:183 | app_fit: metrics_centralized {}\n",
            "\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F_wye5mpQKPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HekdCwslCyf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tKTy-KtbCzha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --iid-alpha 10 --fraction-fit 0.3 --client-pool-size 8 --num-iterations 1000 --num-rounds 10 --val-ratio 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RqQs8IfCykT",
        "outputId": "4b071908-3570-4da3-b02b-d71ead1fa279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=10.0, 10 classes): [515 197 362 130 318 386 414 216 449 388]\n",
            "Data partitioned across 8 clients, with IID alpha = 10.0 and 0.2 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 8 client in the pool.\n",
            "FL round will proceed with 30.0% of clients sampled, at least 2.\n",
            "INFO flower 2024-01-15 18:09:32,568 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-15 18:09:36,448 | app.py:176 | Flower VCE: Ray initialized with resources: {'accelerator_type:V100': 1.0, 'object_store_memory': 3495331430.0, 'memory': 6990662862.0, 'GPU': 1.0, 'CPU': 2.0, 'node:172.28.0.12': 1.0}\n",
            "INFO flower 2024-01-15 18:09:36,450 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-15 18:09:36,450 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-15 18:09:39,375 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-15 18:09:39,375 | server.py:88 | Evaluating initial parameters\n",
            "Evaluation on the server: test_loss=0.0722, test_accuracy=0.0557\n",
            "INFO flower 2024-01-15 18:09:41,551 | server.py:91 | initial parameters (loss, other metrics): 0.07224418107668559, {'accuracy': 0.05566666666666667}\n",
            "INFO flower 2024-01-15 18:09:41,552 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-15 18:09:41,552 | server.py:215 | fit_round 1: strategy sampled 5 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6554)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6555)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6692)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6693)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6554)\u001b[0m Client 2: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6554)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6555)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6693)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6692)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 18:13:27,053 | server.py:229 | fit_round 1 received 5 results and 0 failures\n",
            "WARNING flower 2024-01-15 18:13:27,070 | fedavg.py:234 | No fit_metrics_aggregation_fn provided\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6554)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0442, test_accuracy=0.4490\n",
            "INFO flower 2024-01-15 18:13:29,475 | server.py:116 | fit progress: (1, 0.04415146827697754, {'accuracy': 0.449}, 227.92357276500002)\n",
            "DEBUG flower 2024-01-15 18:13:29,476 | server.py:165 | evaluate_round 1: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6692)\u001b[0m E0115 18:13:29.496037528    6724 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6554)\u001b[0m Client 7: evaluation on 675 examples: loss=0.0108, accuracy=0.5941\n",
            "DEBUG flower 2024-01-15 18:13:31,271 | server.py:179 | evaluate_round 1 received 2 results and 0 failures\n",
            "WARNING flower 2024-01-15 18:13:31,271 | fedavg.py:265 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-15 18:13:31,271 | server.py:215 | fit_round 2: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6692)\u001b[0m Client 0: evaluation on 675 examples: loss=0.0163, accuracy=0.4222\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6692)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6554)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6692)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 18:14:50,639 | server.py:229 | fit_round 2 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6554)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0516, test_accuracy=0.7117\n",
            "INFO flower 2024-01-15 18:14:52,951 | server.py:116 | fit progress: (2, 0.051559617161750795, {'accuracy': 0.7116666666666667}, 311.39933556999995)\n",
            "DEBUG flower 2024-01-15 18:14:52,951 | server.py:165 | evaluate_round 2: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-15 18:14:53,813 | server.py:179 | evaluate_round 2 received 2 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-15 18:14:53,813 | server.py:215 | fit_round 3: strategy sampled 4 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6554)\u001b[0m Client 2: evaluation on 675 examples: loss=0.0228, accuracy=0.6400\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6692)\u001b[0m Client 4: evaluation on 675 examples: loss=0.0257, accuracy=0.6044\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6554)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6692)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8156)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8210)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6554)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6692)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6554)\u001b[0m E0115 18:17:41.119803127    6600 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8156)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 18:17:50,181 | server.py:229 | fit_round 3 received 4 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8210)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0314, test_accuracy=0.7603\n",
            "INFO flower 2024-01-15 18:17:52,347 | server.py:116 | fit progress: (3, 0.03142962640772263, {'accuracy': 0.7603333333333333}, 490.7949134999999)\n",
            "DEBUG flower 2024-01-15 18:17:52,347 | server.py:165 | evaluate_round 3: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8156)\u001b[0m Client 0: evaluation on 675 examples: loss=0.0144, accuracy=0.7111\n",
            "DEBUG flower 2024-01-15 18:17:53,205 | server.py:179 | evaluate_round 3 received 2 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-15 18:17:53,205 | server.py:215 | fit_round 4: strategy sampled 5 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8210)\u001b[0m Client 6: evaluation on 675 examples: loss=0.0073, accuracy=0.8341\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8210)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8156)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9049)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9050)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8156)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8156)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8210)\u001b[0m Client 0: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9049)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9050)\u001b[0m Client 2: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 18:21:33,149 | server.py:229 | fit_round 4 received 5 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8156)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0278, test_accuracy=0.7867\n",
            "INFO flower 2024-01-15 18:21:35,607 | server.py:116 | fit progress: (4, 0.027762552931904792, {'accuracy': 0.7866666666666666}, 714.0555788419999)\n",
            "DEBUG flower 2024-01-15 18:21:35,608 | server.py:165 | evaluate_round 4: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9050)\u001b[0m E0115 18:21:35.616884125    9115 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8156)\u001b[0m Client 1: evaluation on 675 examples: loss=0.0180, accuracy=0.6400\n",
            "DEBUG flower 2024-01-15 18:21:37,152 | server.py:179 | evaluate_round 4 received 2 results and 0 failures\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-15 18:21:37,153 | server.py:215 | fit_round 5: strategy sampled 4 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=9050)\u001b[0m Client 6: evaluation on 675 examples: loss=0.0061, accuracy=0.8711\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9050)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8156)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10115)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10116)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8156)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8156)\u001b[0m E0115 18:24:20.643164344    8171 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9050)\u001b[0m Client 0: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10116)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 18:24:31,155 | server.py:229 | fit_round 5 received 4 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10115)\u001b[0m Client 2: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0203, test_accuracy=0.8280\n",
            "INFO flower 2024-01-15 18:24:33,629 | server.py:116 | fit progress: (5, 0.020294111616909503, {'accuracy': 0.828}, 892.0776136769998)\n",
            "DEBUG flower 2024-01-15 18:24:33,630 | server.py:165 | evaluate_round 5: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-15 18:24:34,875 | server.py:179 | evaluate_round 5 received 2 results and 0 failures\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-15 18:24:34,875 | server.py:215 | fit_round 6: strategy sampled 5 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10115)\u001b[0m Client 3: evaluation on 675 examples: loss=0.0126, accuracy=0.7333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10116)\u001b[0m Client 1: evaluation on 675 examples: loss=0.0131, accuracy=0.7156\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10115)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10116)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10976)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10977)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10116)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10116)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10115)\u001b[0m Client 2: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10977)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10976)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 18:28:15,366 | server.py:229 | fit_round 6 received 5 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10116)\u001b[0m Client 0: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0174, test_accuracy=0.8653\n",
            "INFO flower 2024-01-15 18:28:17,960 | server.py:116 | fit progress: (6, 0.0173992945017914, {'accuracy': 0.8653333333333333}, 1116.408557513)\n",
            "DEBUG flower 2024-01-15 18:28:17,961 | server.py:165 | evaluate_round 6: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10116)\u001b[0m Client 1: evaluation on 675 examples: loss=0.0129, accuracy=0.7615\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10976)\u001b[0m Client 4: evaluation on 675 examples: loss=0.0115, accuracy=0.7719\n",
            "DEBUG flower 2024-01-15 18:28:19,253 | server.py:179 | evaluate_round 6 received 2 results and 0 failures\n",
            "Configuring round 7\n",
            "DEBUG flower 2024-01-15 18:28:19,253 | server.py:215 | fit_round 7: strategy sampled 4 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10976)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10116)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12047)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12048)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10116)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10976)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12047)\u001b[0m Client 0: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 18:31:17,239 | server.py:229 | fit_round 7 received 4 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12048)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0185, test_accuracy=0.8533\n",
            "INFO flower 2024-01-15 18:31:19,744 | server.py:116 | fit progress: (7, 0.018514910149077576, {'accuracy': 0.8533333333333334}, 1298.192029858)\n",
            "DEBUG flower 2024-01-15 18:31:19,744 | server.py:165 | evaluate_round 7: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-15 18:31:20,732 | server.py:179 | evaluate_round 7 received 2 results and 0 failures\n",
            "Configuring round 8\n",
            "DEBUG flower 2024-01-15 18:31:20,733 | server.py:215 | fit_round 8: strategy sampled 4 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12047)\u001b[0m Client 0: evaluation on 675 examples: loss=0.0122, accuracy=0.7615\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12048)\u001b[0m Client 1: evaluation on 675 examples: loss=0.0128, accuracy=0.7585\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12047)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12048)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12926)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12927)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12048)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12047)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12926)\u001b[0m Client 2: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 18:34:18,656 | server.py:229 | fit_round 8 received 4 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12927)\u001b[0m Client 0: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0171, test_accuracy=0.8737\n",
            "INFO flower 2024-01-15 18:34:20,939 | server.py:116 | fit progress: (8, 0.017125869262342653, {'accuracy': 0.8736666666666667}, 1479.3872168350001)\n",
            "DEBUG flower 2024-01-15 18:34:20,939 | server.py:165 | evaluate_round 8: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-15 18:34:21,827 | server.py:179 | evaluate_round 8 received 2 results and 0 failures\n",
            "Configuring round 9\n",
            "DEBUG flower 2024-01-15 18:34:21,827 | server.py:215 | fit_round 9: strategy sampled 6 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12927)\u001b[0m Client 1: evaluation on 675 examples: loss=0.0127, accuracy=0.7748\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12926)\u001b[0m Client 7: evaluation on 675 examples: loss=0.0106, accuracy=0.7867\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12927)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12926)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13801)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13836)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12927)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12927)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12926)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12926)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13801)\u001b[0m Client 2: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=13836)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12927)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 18:38:45,408 | server.py:229 | fit_round 9 received 6 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12926)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0151, test_accuracy=0.8900\n",
            "INFO flower 2024-01-15 18:38:47,354 | server.py:116 | fit progress: (9, 0.015127345934820673, {'accuracy': 0.89}, 1745.8020928950002)\n",
            "DEBUG flower 2024-01-15 18:38:47,354 | server.py:165 | evaluate_round 9: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-15 18:38:48,202 | server.py:179 | evaluate_round 9 received 2 results and 0 failures\n",
            "Configuring round 10\n",
            "DEBUG flower 2024-01-15 18:38:48,202 | server.py:215 | fit_round 10: strategy sampled 6 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12927)\u001b[0m Client 2: evaluation on 675 examples: loss=0.0164, accuracy=0.7333\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12926)\u001b[0m Client 7: evaluation on 675 examples: loss=0.0068, accuracy=0.8593\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12927)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12926)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15080)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15142)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12926)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12927)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12926)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12927)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15080)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15142)\u001b[0m Client 0: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12927)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 18:43:12,414 | server.py:229 | fit_round 10 received 6 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12926)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0154, test_accuracy=0.8827\n",
            "INFO flower 2024-01-15 18:43:14,443 | server.py:116 | fit progress: (10, 0.015411462462196747, {'accuracy': 0.8826666666666667}, 2012.891698785)\n",
            "DEBUG flower 2024-01-15 18:43:14,444 | server.py:165 | evaluate_round 10: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12927)\u001b[0m Client 6: evaluation on 675 examples: loss=0.0084, accuracy=0.8341\n",
            "DEBUG flower 2024-01-15 18:43:15,945 | server.py:179 | evaluate_round 10 received 2 results and 0 failures\n",
            "INFO flower 2024-01-15 18:43:15,945 | server.py:144 | FL finished in 2014.393660678\n",
            "INFO flower 2024-01-15 18:43:15,946 | app.py:180 | app_fit: losses_distributed [(1, 0.013548007452929462), (2, 0.02425503615979795), (3, 0.010838620177021733), (4, 0.0120481464377156), (5, 0.012865338634561609), (6, 0.0122026201972255), (7, 0.012533963123957315), (8, 0.011634200149112277), (9, 0.01155996311593939), (10, 0.01127003969969573)]\n",
            "INFO flower 2024-01-15 18:43:15,947 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2024-01-15 18:43:15,947 | app.py:182 | app_fit: losses_centralized [(0, 0.07224418107668559), (1, 0.04415146827697754), (2, 0.051559617161750795), (3, 0.03142962640772263), (4, 0.027762552931904792), (5, 0.020294111616909503), (6, 0.0173992945017914), (7, 0.018514910149077576), (8, 0.017125869262342653), (9, 0.015127345934820673), (10, 0.015411462462196747)]\n",
            "INFO flower 2024-01-15 18:43:15,947 | app.py:183 | app_fit: metrics_centralized {'accuracy': [(0, 0.05566666666666667), (1, 0.449), (2, 0.7116666666666667), (3, 0.7603333333333333), (4, 0.7866666666666666), (5, 0.828), (6, 0.8653333333333333), (7, 0.8533333333333334), (8, 0.8736666666666667), (9, 0.89), (10, 0.8826666666666667)]}\n",
            "History (loss, distributed):\n",
            "\tround 1: 0.013548007452929462\n",
            "\tround 2: 0.02425503615979795\n",
            "\tround 3: 0.010838620177021733\n",
            "\tround 4: 0.0120481464377156\n",
            "\tround 5: 0.012865338634561609\n",
            "\tround 6: 0.0122026201972255\n",
            "\tround 7: 0.012533963123957315\n",
            "\tround 8: 0.011634200149112277\n",
            "\tround 9: 0.01155996311593939\n",
            "\tround 10: 0.01127003969969573\n",
            "History (loss, centralized):\n",
            "\tround 0: 0.07224418107668559\n",
            "\tround 1: 0.04415146827697754\n",
            "\tround 2: 0.051559617161750795\n",
            "\tround 3: 0.03142962640772263\n",
            "\tround 4: 0.027762552931904792\n",
            "\tround 5: 0.020294111616909503\n",
            "\tround 6: 0.0173992945017914\n",
            "\tround 7: 0.018514910149077576\n",
            "\tround 8: 0.017125869262342653\n",
            "\tround 9: 0.015127345934820673\n",
            "\tround 10: 0.015411462462196747\n",
            "History (metrics, centralized):\n",
            "{'accuracy': [(0, 0.05566666666666667), (1, 0.449), (2, 0.7116666666666667), (3, 0.7603333333333333), (4, 0.7866666666666666), (5, 0.828), (6, 0.8653333333333333), (7, 0.8533333333333334), (8, 0.8736666666666667), (9, 0.89), (10, 0.8826666666666667)]}\n",
            "\u001b[0m\u001b[2m\u001b[36m(launch_and_evaluate pid=12926)\u001b[0m Client 3: evaluation on 675 examples: loss=0.0141, accuracy=0.7422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --iid-alpha 10 --fraction-fit 0.3 --client-pool-size 8 --num-iterations 1000 --num-rounds 10 --val-ratio 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ3mVW4LDR9V",
        "outputId": "995d35f1-0c8a-4013-c2c2-f868f7f123ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=10.0, 10 classes): [296 302 277 350 270 353 457 333 167 570]\n",
            "Data partitioned across 8 clients, with IID alpha = 10.0 and 0.2 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 8 client in the pool.\n",
            "FL round will proceed with 30.0% of clients sampled, at least 2.\n",
            "INFO flower 2024-01-15 21:47:19,565 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-15 21:47:23,842 | app.py:176 | Flower VCE: Ray initialized with resources: {'object_store_memory': 3485057433.0, 'accelerator_type:V100': 1.0, 'memory': 6970114868.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0, 'CPU': 2.0}\n",
            "INFO flower 2024-01-15 21:47:23,843 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-15 21:47:23,843 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-15 21:47:26,890 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-15 21:47:26,890 | server.py:88 | Evaluating initial parameters\n",
            "/content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "  precisions = total_tp / total_pred\n",
            "Evaluation on the server: test_loss=0.0723, test_accuracy=0.1053\n",
            "INFO flower 2024-01-15 21:47:30,318 | server.py:91 | initial parameters (loss, other metrics): 0.07225859729448954, {'accuracy': 0.10533333333333333, 'precisions': array([       nan,        nan,        nan,        nan,        nan,\n",
            "       0.03322259,        nan, 0.1234362 ,        nan,        nan]), 'recalls': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.09615385, 0.        , 0.86046512, 0.        , 0.        ]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}\n",
            "INFO flower 2024-01-15 21:47:30,319 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-15 21:47:30,320 | server.py:215 | fit_round 1: strategy sampled 7 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7027)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7028)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7155)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7212)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7027)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7027)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7155)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7155)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7028)\u001b[0m Client 2: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7212)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7028)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7027)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7028)\u001b[0m Client 0: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 21:52:42,726 | server.py:229 | fit_round 1 received 7 results and 0 failures\n",
            "WARNING flower 2024-01-15 21:52:42,755 | fedavg.py:234 | No fit_metrics_aggregation_fn provided\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7155)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0479, test_accuracy=0.3623\n",
            "INFO flower 2024-01-15 21:52:45,428 | server.py:116 | fit progress: (1, 0.0479035484790802, {'accuracy': 0.36233333333333334, 'precisions': array([0.79545455, 0.49090909, 0.44444444, 0.37132353, 0.29166667,\n",
            "       0.5862069 , 0.06382979, 0.30720721, 0.40983607, 0.40847201]), 'recalls': array([0.1035503 , 0.08181818, 0.24705882, 0.33443709, 0.29787234,\n",
            "       0.08173077, 0.01086957, 0.99127907, 0.45454545, 0.8852459 ]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 315.1090521860001)\n",
            "DEBUG flower 2024-01-15 21:52:45,430 | server.py:165 | evaluate_round 1: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7155)\u001b[0m Client 3: evaluation on 675 examples: loss=0.0174, accuracy=0.2563\n",
            "DEBUG flower 2024-01-15 21:52:46,513 | server.py:179 | evaluate_round 1 received 2 results and 0 failures\n",
            "WARNING flower 2024-01-15 21:52:46,513 | fedavg.py:265 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-15 21:52:46,514 | server.py:215 | fit_round 2: strategy sampled 4 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=7028)\u001b[0m Client 2: evaluation on 675 examples: loss=0.0150, accuracy=0.4000\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7028)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7155)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8659)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8707)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7028)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=7155)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8659)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 21:55:44,402 | server.py:229 | fit_round 2 received 4 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8707)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0294, test_accuracy=0.7147\n",
            "INFO flower 2024-01-15 21:55:46,533 | server.py:116 | fit progress: (2, 0.029389067202806474, {'accuracy': 0.7146666666666667, 'precisions': array([0.73067916, 0.78851175, 0.72340426, 0.82089552, 0.96256684,\n",
            "       0.9       , 0.60120846, 0.68263473, 0.49044586, 0.910299  ]), 'recalls': array([0.92307692, 0.91515152, 0.6       , 0.18211921, 0.63829787,\n",
            "       0.21634615, 0.72101449, 0.99418605, 0.84      , 0.89836066]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 496.2134494249999)\n",
            "DEBUG flower 2024-01-15 21:55:46,534 | server.py:165 | evaluate_round 2: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8707)\u001b[0m Client 0: evaluation on 675 examples: loss=0.0114, accuracy=0.6800\n",
            "DEBUG flower 2024-01-15 21:55:47,429 | server.py:179 | evaluate_round 2 received 2 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-15 21:55:47,430 | server.py:215 | fit_round 3: strategy sampled 6 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8659)\u001b[0m Client 1: evaluation on 675 examples: loss=0.0116, accuracy=0.6830\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8707)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8659)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9556)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9554)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8659)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8659)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8707)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8707)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9554)\u001b[0m Client 2: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=9556)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8659)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 22:00:06,086 | server.py:229 | fit_round 3 received 6 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8707)\u001b[0m Client 0: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0201, test_accuracy=0.8217\n",
            "INFO flower 2024-01-15 22:00:08,084 | server.py:116 | fit progress: (3, 0.020094477330644924, {'accuracy': 0.8216666666666667, 'precisions': array([0.82933333, 0.82767624, 0.74269006, 0.84615385, 0.94921875,\n",
            "       0.88      , 0.65765766, 0.84615385, 0.75531915, 0.95578231]), 'recalls': array([0.92011834, 0.96060606, 0.74705882, 0.50993377, 0.86170213,\n",
            "       0.63461538, 0.79347826, 0.99127907, 0.77454545, 0.92131148]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 757.764423654)\n",
            "DEBUG flower 2024-01-15 22:00:08,085 | server.py:165 | evaluate_round 3: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-15 22:00:08,953 | server.py:179 | evaluate_round 3 received 2 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-15 22:00:08,954 | server.py:215 | fit_round 4: strategy sampled 4 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8659)\u001b[0m Client 6: evaluation on 675 examples: loss=0.0094, accuracy=0.7600\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=8707)\u001b[0m Client 4: evaluation on 675 examples: loss=0.0107, accuracy=0.7689\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8659)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8707)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10792)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10795)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8707)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=8659)\u001b[0m Client 0: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10795)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 22:03:08,084 | server.py:229 | fit_round 4 received 4 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10792)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0230, test_accuracy=0.8110\n",
            "INFO flower 2024-01-15 22:03:10,166 | server.py:116 | fit progress: (4, 0.023049606934189795, {'accuracy': 0.811, 'precisions': array([0.80310881, 0.84168865, 0.72679045, 0.91851852, 0.96943231,\n",
            "       0.92622951, 0.65644172, 0.83538084, 0.67826087, 0.96258503]), 'recalls': array([0.91715976, 0.96666667, 0.80588235, 0.41059603, 0.78723404,\n",
            "       0.54326923, 0.77536232, 0.98837209, 0.85090909, 0.92786885]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 939.8462849100001)\n",
            "DEBUG flower 2024-01-15 22:03:10,167 | server.py:165 | evaluate_round 4: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-15 22:03:11,061 | server.py:179 | evaluate_round 4 received 2 results and 0 failures\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-15 22:03:11,061 | server.py:215 | fit_round 5: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10792)\u001b[0m Client 0: evaluation on 675 examples: loss=0.0114, accuracy=0.7600\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10795)\u001b[0m Client 3: evaluation on 675 examples: loss=0.0136, accuracy=0.6933\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10792)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10795)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10795)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10792)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 22:04:34,557 | server.py:229 | fit_round 5 received 2 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0392, test_accuracy=0.7347\n",
            "INFO flower 2024-01-15 22:04:36,950 | server.py:116 | fit progress: (5, 0.03918617114424706, {'accuracy': 0.7346666666666667, 'precisions': array([0.68134172, 0.88767123, 0.62061404, 0.98245614, 0.99280576,\n",
            "       1.        , 0.57361963, 0.8630491 , 0.50955414, 0.9825784 ]), 'recalls': array([0.96153846, 0.98181818, 0.83235294, 0.18543046, 0.4893617 ,\n",
            "       0.16826923, 0.67753623, 0.97093023, 0.87272727, 0.92459016]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 1026.630163887)\n",
            "DEBUG flower 2024-01-15 22:04:36,951 | server.py:165 | evaluate_round 5: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10792)\u001b[0m Client 1: evaluation on 675 examples: loss=0.0197, accuracy=0.6696\n",
            "DEBUG flower 2024-01-15 22:04:38,447 | server.py:179 | evaluate_round 5 received 2 results and 0 failures\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-15 22:04:38,447 | server.py:215 | fit_round 6: strategy sampled 4 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=10795)\u001b[0m Client 5: evaluation on 675 examples: loss=0.0164, accuracy=0.6859\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10795)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10792)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12071)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12072)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10795)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=10792)\u001b[0m Client 2: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12072)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 22:07:43,565 | server.py:229 | fit_round 6 received 4 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12071)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0210, test_accuracy=0.8297\n",
            "INFO flower 2024-01-15 22:07:45,692 | server.py:116 | fit progress: (6, 0.021028174464901288, {'accuracy': 0.8296666666666667, 'precisions': array([0.82085561, 0.89166667, 0.78323699, 0.92248062, 0.93014706,\n",
            "       0.9       , 0.6746988 , 0.925     , 0.63471503, 0.96563574]), 'recalls': array([0.90828402, 0.97272727, 0.79705882, 0.39403974, 0.89716312,\n",
            "       0.64903846, 0.8115942 , 0.96802326, 0.89090909, 0.92131148]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 1215.3723440210001)\n",
            "DEBUG flower 2024-01-15 22:07:45,693 | server.py:165 | evaluate_round 6: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12072)\u001b[0m Client 7: evaluation on 675 examples: loss=0.0077, accuracy=0.8252\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12072)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12072)\u001b[0m   recalls = total_tp / total_true\n",
            "DEBUG flower 2024-01-15 22:07:46,644 | server.py:179 | evaluate_round 6 received 2 results and 0 failures\n",
            "Configuring round 7\n",
            "DEBUG flower 2024-01-15 22:07:46,645 | server.py:215 | fit_round 7: strategy sampled 6 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12071)\u001b[0m Client 4: evaluation on 675 examples: loss=0.0140, accuracy=0.7304\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12071)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12072)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12985)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12983)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12072)\u001b[0m Client 2: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12072)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12071)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12071)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12983)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12985)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12983)\u001b[0m E0115 22:11:00.409931798   13023 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12985)\u001b[0m E0115 22:11:00.735670051   13024 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12072)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 22:12:15,630 | server.py:229 | fit_round 7 received 6 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12071)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0161, test_accuracy=0.8757\n",
            "INFO flower 2024-01-15 22:12:18,490 | server.py:116 | fit progress: (7, 0.016104901767025392, {'accuracy': 0.8756666666666667, 'precisions': array([0.89942529, 0.9047619 , 0.83727811, 0.8974359 , 0.94464945,\n",
            "       0.87192118, 0.72477064, 0.89361702, 0.82214765, 0.9825784 ]), 'recalls': array([0.9260355 , 0.97878788, 0.83235294, 0.5794702 , 0.90780142,\n",
            "       0.85096154, 0.85869565, 0.97674419, 0.89090909, 0.92459016]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 1488.1709660709998)\n",
            "DEBUG flower 2024-01-15 22:12:18,492 | server.py:165 | evaluate_round 7: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12071)\u001b[0m Client 5: evaluation on 675 examples: loss=0.0119, accuracy=0.7674\n",
            "DEBUG flower 2024-01-15 22:12:19,810 | server.py:179 | evaluate_round 7 received 2 results and 0 failures\n",
            "Configuring round 8\n",
            "DEBUG flower 2024-01-15 22:12:19,810 | server.py:215 | fit_round 8: strategy sampled 7 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12072)\u001b[0m Client 0: evaluation on 675 examples: loss=0.0115, accuracy=0.7733\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12071)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12072)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14274)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14272)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12072)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12072)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12071)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12071)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14274)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14272)\u001b[0m Client 2: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14274)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14272)\u001b[0m E0115 22:15:33.191267644   14288 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12072)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12071)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 22:17:34,472 | server.py:229 | fit_round 8 received 7 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14274)\u001b[0m Client 0: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0139, test_accuracy=0.8880\n",
            "INFO flower 2024-01-15 22:17:36,582 | server.py:116 | fit progress: (8, 0.013890858028704921, {'accuracy': 0.888, 'precisions': array([0.90462428, 0.93103448, 0.85043988, 0.92039801, 0.97014925,\n",
            "       0.88383838, 0.74018127, 0.89005236, 0.83848797, 0.97959184]), 'recalls': array([0.9260355 , 0.98181818, 0.85294118, 0.61258278, 0.92198582,\n",
            "       0.84134615, 0.88768116, 0.98837209, 0.88727273, 0.9442623 ]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 1806.2624107249999)\n",
            "DEBUG flower 2024-01-15 22:17:36,583 | server.py:165 | evaluate_round 8: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-15 22:17:37,504 | server.py:179 | evaluate_round 8 received 2 results and 0 failures\n",
            "Configuring round 9\n",
            "DEBUG flower 2024-01-15 22:17:37,504 | server.py:215 | fit_round 9: strategy sampled 6 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12071)\u001b[0m Client 5: evaluation on 675 examples: loss=0.0125, accuracy=0.7689\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14274)\u001b[0m Client 0: evaluation on 675 examples: loss=0.0112, accuracy=0.7822\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12071)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14274)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15760)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15795)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14274)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14274)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12071)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12071)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15760)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=15795)\u001b[0m Client 2: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14274)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 22:22:04,507 | server.py:229 | fit_round 9 received 6 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12071)\u001b[0m Client 0: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0124, test_accuracy=0.9043\n",
            "INFO flower 2024-01-15 22:22:07,282 | server.py:116 | fit progress: (9, 0.012396462398270766, {'accuracy': 0.9043333333333333, 'precisions': array([0.93712575, 0.90304709, 0.84195402, 0.91164659, 0.97416974,\n",
            "       0.90673575, 0.78501629, 0.92411924, 0.89298893, 0.97979798]), 'recalls': array([0.9260355 , 0.98787879, 0.86176471, 0.75165563, 0.93617021,\n",
            "       0.84134615, 0.87318841, 0.99127907, 0.88      , 0.95409836]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 2076.962412501)\n",
            "DEBUG flower 2024-01-15 22:22:07,284 | server.py:165 | evaluate_round 9: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-15 22:22:08,360 | server.py:179 | evaluate_round 9 received 2 results and 0 failures\n",
            "Configuring round 10\n",
            "DEBUG flower 2024-01-15 22:22:08,360 | server.py:215 | fit_round 10: strategy sampled 3 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=12071)\u001b[0m Client 5: evaluation on 675 examples: loss=0.0137, accuracy=0.7630\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=14274)\u001b[0m Client 0: evaluation on 675 examples: loss=0.0118, accuracy=0.7837\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12071)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14274)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=17056)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=14274)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=12071)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 22:24:19,350 | server.py:229 | fit_round 10 received 3 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=17056)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0216, test_accuracy=0.8610\n",
            "INFO flower 2024-01-15 22:24:21,415 | server.py:116 | fit progress: (10, 0.02164036247630914, {'accuracy': 0.861, 'precisions': array([0.89044944, 0.90807799, 0.7398568 , 0.96103896, 0.99570815,\n",
            "       0.94776119, 0.71428571, 0.87855297, 0.76363636, 0.99657534]), 'recalls': array([0.93786982, 0.98787879, 0.91176471, 0.49006623, 0.82269504,\n",
            "       0.61057692, 0.86956522, 0.98837209, 0.91636364, 0.95409836]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 2211.09570393)\n",
            "DEBUG flower 2024-01-15 22:24:21,416 | server.py:165 | evaluate_round 10: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-15 22:24:22,361 | server.py:179 | evaluate_round 10 received 2 results and 0 failures\n",
            "INFO flower 2024-01-15 22:24:22,362 | server.py:144 | FL finished in 2212.04229975\n",
            "INFO flower 2024-01-15 22:24:22,362 | app.py:180 | app_fit: losses_distributed [(1, 0.01621603806813558), (2, 0.011480950426172327), (3, 0.01007545789082845), (4, 0.012501747519881637), (5, 0.01804891206600048), (6, 0.010860223284474125), (7, 0.011668372330842195), (8, 0.011854945023854573), (9, 0.012756398739638151), (10, 0.018012029859754773)]\n",
            "INFO flower 2024-01-15 22:24:22,363 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2024-01-15 22:24:22,363 | app.py:182 | app_fit: losses_centralized [(0, 0.07225859729448954), (1, 0.0479035484790802), (2, 0.029389067202806474), (3, 0.020094477330644924), (4, 0.023049606934189795), (5, 0.03918617114424706), (6, 0.021028174464901288), (7, 0.016104901767025392), (8, 0.013890858028704921), (9, 0.012396462398270766), (10, 0.02164036247630914)]\n",
            "INFO flower 2024-01-15 22:24:22,367 | app.py:183 | app_fit: metrics_centralized {'accuracy': [(0, 0.10533333333333333), (1, 0.36233333333333334), (2, 0.7146666666666667), (3, 0.8216666666666667), (4, 0.811), (5, 0.7346666666666667), (6, 0.8296666666666667), (7, 0.8756666666666667), (8, 0.888), (9, 0.9043333333333333), (10, 0.861)], 'precisions': [(0, array([       nan,        nan,        nan,        nan,        nan,\n",
            "       0.03322259,        nan, 0.1234362 ,        nan,        nan])), (1, array([0.79545455, 0.49090909, 0.44444444, 0.37132353, 0.29166667,\n",
            "       0.5862069 , 0.06382979, 0.30720721, 0.40983607, 0.40847201])), (2, array([0.73067916, 0.78851175, 0.72340426, 0.82089552, 0.96256684,\n",
            "       0.9       , 0.60120846, 0.68263473, 0.49044586, 0.910299  ])), (3, array([0.82933333, 0.82767624, 0.74269006, 0.84615385, 0.94921875,\n",
            "       0.88      , 0.65765766, 0.84615385, 0.75531915, 0.95578231])), (4, array([0.80310881, 0.84168865, 0.72679045, 0.91851852, 0.96943231,\n",
            "       0.92622951, 0.65644172, 0.83538084, 0.67826087, 0.96258503])), (5, array([0.68134172, 0.88767123, 0.62061404, 0.98245614, 0.99280576,\n",
            "       1.        , 0.57361963, 0.8630491 , 0.50955414, 0.9825784 ])), (6, array([0.82085561, 0.89166667, 0.78323699, 0.92248062, 0.93014706,\n",
            "       0.9       , 0.6746988 , 0.925     , 0.63471503, 0.96563574])), (7, array([0.89942529, 0.9047619 , 0.83727811, 0.8974359 , 0.94464945,\n",
            "       0.87192118, 0.72477064, 0.89361702, 0.82214765, 0.9825784 ])), (8, array([0.90462428, 0.93103448, 0.85043988, 0.92039801, 0.97014925,\n",
            "       0.88383838, 0.74018127, 0.89005236, 0.83848797, 0.97959184])), (9, array([0.93712575, 0.90304709, 0.84195402, 0.91164659, 0.97416974,\n",
            "       0.90673575, 0.78501629, 0.92411924, 0.89298893, 0.97979798])), (10, array([0.89044944, 0.90807799, 0.7398568 , 0.96103896, 0.99570815,\n",
            "       0.94776119, 0.71428571, 0.87855297, 0.76363636, 0.99657534]))], 'recalls': [(0, array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.09615385, 0.        , 0.86046512, 0.        , 0.        ])), (1, array([0.1035503 , 0.08181818, 0.24705882, 0.33443709, 0.29787234,\n",
            "       0.08173077, 0.01086957, 0.99127907, 0.45454545, 0.8852459 ])), (2, array([0.92307692, 0.91515152, 0.6       , 0.18211921, 0.63829787,\n",
            "       0.21634615, 0.72101449, 0.99418605, 0.84      , 0.89836066])), (3, array([0.92011834, 0.96060606, 0.74705882, 0.50993377, 0.86170213,\n",
            "       0.63461538, 0.79347826, 0.99127907, 0.77454545, 0.92131148])), (4, array([0.91715976, 0.96666667, 0.80588235, 0.41059603, 0.78723404,\n",
            "       0.54326923, 0.77536232, 0.98837209, 0.85090909, 0.92786885])), (5, array([0.96153846, 0.98181818, 0.83235294, 0.18543046, 0.4893617 ,\n",
            "       0.16826923, 0.67753623, 0.97093023, 0.87272727, 0.92459016])), (6, array([0.90828402, 0.97272727, 0.79705882, 0.39403974, 0.89716312,\n",
            "       0.64903846, 0.8115942 , 0.96802326, 0.89090909, 0.92131148])), (7, array([0.9260355 , 0.97878788, 0.83235294, 0.5794702 , 0.90780142,\n",
            "       0.85096154, 0.85869565, 0.97674419, 0.89090909, 0.92459016])), (8, array([0.9260355 , 0.98181818, 0.85294118, 0.61258278, 0.92198582,\n",
            "       0.84134615, 0.88768116, 0.98837209, 0.88727273, 0.9442623 ])), (9, array([0.9260355 , 0.98787879, 0.86176471, 0.75165563, 0.93617021,\n",
            "       0.84134615, 0.87318841, 0.99127907, 0.88      , 0.95409836])), (10, array([0.93786982, 0.98787879, 0.91176471, 0.49006623, 0.82269504,\n",
            "       0.61057692, 0.86956522, 0.98837209, 0.91636364, 0.95409836]))], 'class proportions': [(0, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (1, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (2, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (3, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (4, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (5, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (6, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (7, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (8, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (9, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (10, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667]))]}\n",
            "History (loss, distributed):\n",
            "\tround 1: 0.01621603806813558\n",
            "\tround 2: 0.011480950426172327\n",
            "\tround 3: 0.01007545789082845\n",
            "\tround 4: 0.012501747519881637\n",
            "\tround 5: 0.01804891206600048\n",
            "\tround 6: 0.010860223284474125\n",
            "\tround 7: 0.011668372330842195\n",
            "\tround 8: 0.011854945023854573\n",
            "\tround 9: 0.012756398739638151\n",
            "\tround 10: 0.018012029859754773\n",
            "History (loss, centralized):\n",
            "\tround 0: 0.07225859729448954\n",
            "\tround 1: 0.0479035484790802\n",
            "\tround 2: 0.029389067202806474\n",
            "\tround 3: 0.020094477330644924\n",
            "\tround 4: 0.023049606934189795\n",
            "\tround 5: 0.03918617114424706\n",
            "\tround 6: 0.021028174464901288\n",
            "\tround 7: 0.016104901767025392\n",
            "\tround 8: 0.013890858028704921\n",
            "\tround 9: 0.012396462398270766\n",
            "\tround 10: 0.02164036247630914\n",
            "History (metrics, centralized):\n",
            "{'accuracy': [(0, 0.10533333333333333), (1, 0.36233333333333334), (2, 0.7146666666666667), (3, 0.8216666666666667), (4, 0.811), (5, 0.7346666666666667), (6, 0.8296666666666667), (7, 0.8756666666666667), (8, 0.888), (9, 0.9043333333333333), (10, 0.861)], 'precisions': [(0, array([       nan,        nan,        nan,        nan,        nan,\n",
            "       0.03322259,        nan, 0.1234362 ,        nan,        nan])), (1, array([0.79545455, 0.49090909, 0.44444444, 0.37132353, 0.29166667,\n",
            "       0.5862069 , 0.06382979, 0.30720721, 0.40983607, 0.40847201])), (2, array([0.73067916, 0.78851175, 0.72340426, 0.82089552, 0.96256684,\n",
            "       0.9       , 0.60120846, 0.68263473, 0.49044586, 0.910299  ])), (3, array([0.82933333, 0.82767624, 0.74269006, 0.84615385, 0.94921875,\n",
            "       0.88      , 0.65765766, 0.84615385, 0.75531915, 0.95578231])), (4, array([0.80310881, 0.84168865, 0.72679045, 0.91851852, 0.96943231,\n",
            "       0.92622951, 0.65644172, 0.83538084, 0.67826087, 0.96258503])), (5, array([0.68134172, 0.88767123, 0.62061404, 0.98245614, 0.99280576,\n",
            "       1.        , 0.57361963, 0.8630491 , 0.50955414, 0.9825784 ])), (6, array([0.82085561, 0.89166667, 0.78323699, 0.92248062, 0.93014706,\n",
            "       0.9       , 0.6746988 , 0.925     , 0.63471503, 0.96563574])), (7, array([0.89942529, 0.9047619 , 0.83727811, 0.8974359 , 0.94464945,\n",
            "       0.87192118, 0.72477064, 0.89361702, 0.82214765, 0.9825784 ])), (8, array([0.90462428, 0.93103448, 0.85043988, 0.92039801, 0.97014925,\n",
            "       0.88383838, 0.74018127, 0.89005236, 0.83848797, 0.97959184])), (9, array([0.93712575, 0.90304709, 0.84195402, 0.91164659, 0.97416974,\n",
            "       0.90673575, 0.78501629, 0.92411924, 0.89298893, 0.97979798])), (10, array([0.89044944, 0.90807799, 0.7398568 , 0.96103896, 0.99570815,\n",
            "       0.94776119, 0.71428571, 0.87855297, 0.76363636, 0.99657534]))], 'recalls': [(0, array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.09615385, 0.        , 0.86046512, 0.        , 0.        ])), (1, array([0.1035503 , 0.08181818, 0.24705882, 0.33443709, 0.29787234,\n",
            "       0.08173077, 0.01086957, 0.99127907, 0.45454545, 0.8852459 ])), (2, array([0.92307692, 0.91515152, 0.6       , 0.18211921, 0.63829787,\n",
            "       0.21634615, 0.72101449, 0.99418605, 0.84      , 0.89836066])), (3, array([0.92011834, 0.96060606, 0.74705882, 0.50993377, 0.86170213,\n",
            "       0.63461538, 0.79347826, 0.99127907, 0.77454545, 0.92131148])), (4, array([0.91715976, 0.96666667, 0.80588235, 0.41059603, 0.78723404,\n",
            "       0.54326923, 0.77536232, 0.98837209, 0.85090909, 0.92786885])), (5, array([0.96153846, 0.98181818, 0.83235294, 0.18543046, 0.4893617 ,\n",
            "       0.16826923, 0.67753623, 0.97093023, 0.87272727, 0.92459016])), (6, array([0.90828402, 0.97272727, 0.79705882, 0.39403974, 0.89716312,\n",
            "       0.64903846, 0.8115942 , 0.96802326, 0.89090909, 0.92131148])), (7, array([0.9260355 , 0.97878788, 0.83235294, 0.5794702 , 0.90780142,\n",
            "       0.85096154, 0.85869565, 0.97674419, 0.89090909, 0.92459016])), (8, array([0.9260355 , 0.98181818, 0.85294118, 0.61258278, 0.92198582,\n",
            "       0.84134615, 0.88768116, 0.98837209, 0.88727273, 0.9442623 ])), (9, array([0.9260355 , 0.98787879, 0.86176471, 0.75165563, 0.93617021,\n",
            "       0.84134615, 0.87318841, 0.99127907, 0.88      , 0.95409836])), (10, array([0.93786982, 0.98787879, 0.91176471, 0.49006623, 0.82269504,\n",
            "       0.61057692, 0.86956522, 0.98837209, 0.91636364, 0.95409836]))], 'class proportions': [(0, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (1, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (2, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (3, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (4, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (5, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (6, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (7, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (8, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (9, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (10, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667]))]}\n",
            "\u001b[0m\u001b[2m\u001b[36m(launch_and_evaluate pid=12071)\u001b[0m Client 0: evaluation on 675 examples: loss=0.0163, accuracy=0.7363\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=17056)\u001b[0m Client 4: evaluation on 675 examples: loss=0.0197, accuracy=0.7319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yTybQExdtD5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Experiment\n",
        "\n",
        "1. Changing iid-alpha from 0.2, 2, 10, 1000\n",
        "\n",
        "2. Total Clients: 10\n",
        "\n",
        "3. Random numbers of concurrent clients sampled each round\n",
        "\n",
        "Metrics each round:\n",
        "  - Acc\n",
        "  - Class OvR precisions and recalls\n",
        "  - Loss"
      ],
      "metadata": {
        "id": "P5xnw_7Ie18B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --iid-alpha 0.2 --fraction-fit 0.3 --client-pool-size 8 --num-iterations 1000 --num-rounds 10 --val-ratio 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGhexSGwe2cd",
        "outputId": "7b5d2468-de3e-42b8-ca53-c0487d9adef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class histogram for 0-th partition (alpha=0.2, 10 classes): [   7    0  124   25   12 1066    0  408  344 1389]\n",
            "Data partitioned across 8 clients, with IID alpha = 0.2 and 0.2 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 8 client in the pool.\n",
            "FL round will proceed with 30.0% of clients sampled, at least 2.\n",
            "INFO flower 2024-01-15 23:37:22,412 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-15 23:37:26,015 | app.py:176 | Flower VCE: Ray initialized with resources: {'memory': 7212611175.0, 'CPU': 2.0, 'node:172.28.0.12': 1.0, 'accelerator_type:V100': 1.0, 'GPU': 1.0, 'object_store_memory': 3606305587.0}\n",
            "INFO flower 2024-01-15 23:37:26,016 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-15 23:37:26,016 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-15 23:37:29,038 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-15 23:37:29,038 | server.py:88 | Evaluating initial parameters\n",
            "/content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "  precisions = total_tp / total_pred\n",
            "Evaluation on the server: test_loss=0.0724, test_accuracy=0.0427\n",
            "INFO flower 2024-01-15 23:37:31,427 | server.py:91 | initial parameters (loss, other metrics): 0.07235062257448832, {'accuracy': 0.042666666666666665, 'precisions': array([0.1641791 ,        nan,        nan, 0.01666667, 0.05427088,\n",
            "              nan,        nan,        nan,        nan, 0.00132626]), 'recalls': array([0.03254438, 0.        , 0.        , 0.00331126, 0.40780142,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.00327869]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}\n",
            "INFO flower 2024-01-15 23:37:31,428 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-15 23:37:31,428 | server.py:215 | fit_round 1: strategy sampled 3 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39290)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39294)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39425)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39290)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39425)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39294)\u001b[0m Client 0: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 23:39:43,759 | server.py:229 | fit_round 1 received 3 results and 0 failures\n",
            "WARNING flower 2024-01-15 23:39:43,780 | fedavg.py:234 | No fit_metrics_aggregation_fn provided\n",
            "Evaluation on the server: test_loss=0.0870, test_accuracy=0.3110\n",
            "INFO flower 2024-01-15 23:39:46,481 | server.py:116 | fit progress: (1, 0.08703887395064036, {'accuracy': 0.311, 'precisions': array([       nan,        nan,        nan, 0.18760757, 0.43639291,\n",
            "              nan,        nan,        nan, 0.2260274 , 0.45873016]), 'recalls': array([0.        , 0.        , 0.        , 0.36092715, 0.96099291,\n",
            "       0.        , 0.        , 0.        , 0.96      , 0.94754098]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 135.0533510969999)\n",
            "DEBUG flower 2024-01-15 23:39:46,483 | server.py:165 | evaluate_round 1: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-15 23:39:47,894 | server.py:179 | evaluate_round 1 received 2 results and 0 failures\n",
            "WARNING flower 2024-01-15 23:39:47,894 | fedavg.py:265 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-15 23:39:47,894 | server.py:215 | fit_round 2: strategy sampled 6 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39294)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39294)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39294)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39294)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39294)\u001b[0m Client 3: evaluation on 675 examples: loss=0.0431, accuracy=0.0993\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39425)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39425)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39425)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39425)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39425)\u001b[0m Client 5: evaluation on 675 examples: loss=0.0294, accuracy=0.1748\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39425)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39294)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40095)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40146)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39425)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39425)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39294)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39294)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40146)\u001b[0m Client 2: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=40095)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39425)\u001b[0m Client 0: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 23:44:10,846 | server.py:229 | fit_round 2 received 6 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39294)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0571, test_accuracy=0.4177\n",
            "INFO flower 2024-01-15 23:44:12,864 | server.py:116 | fit progress: (2, 0.05711277894179026, {'accuracy': 0.4176666666666667, 'precisions': array([0.41791045,        nan, 0.21500457, 0.47058824, 0.58525346,\n",
            "              nan, 0.5       , 0.91780822, 0.60091743, 0.44216691]), 'recalls': array([0.08284024, 0.        , 0.69117647, 0.55629139, 0.90070922,\n",
            "       0.        , 0.00362319, 0.38953488, 0.47636364, 0.99016393]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 401.4360203790002)\n",
            "DEBUG flower 2024-01-15 23:44:12,865 | server.py:165 | evaluate_round 2: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-15 23:44:13,723 | server.py:179 | evaluate_round 2 received 2 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-15 23:44:13,723 | server.py:215 | fit_round 3: strategy sampled 4 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39294)\u001b[0m Client 3: evaluation on 675 examples: loss=0.0206, accuracy=0.1852\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=39425)\u001b[0m Client 6: evaluation on 675 examples: loss=0.0199, accuracy=0.3807\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39425)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39294)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41374)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41373)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39425)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=39294)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41374)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 23:47:13,530 | server.py:229 | fit_round 3 received 4 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41373)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0857, test_accuracy=0.3670\n",
            "INFO flower 2024-01-15 23:47:15,596 | server.py:116 | fit progress: (3, 0.08568218199412028, {'accuracy': 0.367, 'precisions': array([0.41441441,        nan, 0.12903226, 0.96153846, 0.88535032,\n",
            "              nan, 0.16770574, 0.95762712, 0.51822917, 0.65168539]), 'recalls': array([0.13609467, 0.        , 0.05882353, 0.08278146, 0.4929078 ,\n",
            "       0.        , 0.97463768, 0.32848837, 0.72363636, 0.95081967]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 584.1687470260003)\n",
            "DEBUG flower 2024-01-15 23:47:15,597 | server.py:165 | evaluate_round 3: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-15 23:47:16,470 | server.py:179 | evaluate_round 3 received 2 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-15 23:47:16,470 | server.py:215 | fit_round 4: strategy sampled 4 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41374)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41374)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41374)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41374)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41374)\u001b[0m Client 0: evaluation on 675 examples: loss=0.0366, accuracy=0.4889\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41373)\u001b[0m Client 1: evaluation on 675 examples: loss=0.0773, accuracy=0.0311\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41373)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41373)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41373)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=41373)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41373)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41374)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42253)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41373)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=41374)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 23:50:23,200 | server.py:229 | fit_round 4 received 4 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42253)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.1234, test_accuracy=0.4397\n",
            "INFO flower 2024-01-15 23:50:25,163 | server.py:116 | fit progress: (4, 0.12340867455800375, {'accuracy': 0.43966666666666665, 'precisions': array([0.72      ,        nan, 0.33333333, 0.6993865 , 0.56646217,\n",
            "              nan, 0.21302251, 0.9858156 , 0.57777778, 0.51652174]), 'recalls': array([0.05325444, 0.        , 0.00294118, 0.37748344, 0.9822695 ,\n",
            "       0.        , 0.96014493, 0.40406977, 0.75636364, 0.97377049]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 773.7354926379994)\n",
            "DEBUG flower 2024-01-15 23:50:25,164 | server.py:165 | evaluate_round 4: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-15 23:50:26,056 | server.py:179 | evaluate_round 4 received 2 results and 0 failures\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-15 23:50:26,056 | server.py:215 | fit_round 5: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42253)\u001b[0m Client 2: evaluation on 675 examples: loss=0.0401, accuracy=0.2785\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42256)\u001b[0m Client 5: evaluation on 675 examples: loss=0.0396, accuracy=0.3126\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42256)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42256)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42256)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42256)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42253)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42253)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42253)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42253)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42253)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42253)\u001b[0m Client 0: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 23:51:48,121 | server.py:229 | fit_round 5 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.2026, test_accuracy=0.3127\n",
            "INFO flower 2024-01-15 23:51:50,206 | server.py:116 | fit progress: (5, 0.20262201484044393, {'accuracy': 0.31266666666666665, 'precisions': array([0.77118644, 1.        , 0.27758007,        nan, 0.5       ,\n",
            "       0.18117229,        nan, 0.71428571, 0.22564612, 0.68627451]), 'recalls': array([0.26923077, 0.15757576, 0.22941176, 0.        , 0.0035461 ,\n",
            "       0.98076923, 0.        , 0.01453488, 0.82545455, 0.91803279]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 858.7780994329987)\n",
            "DEBUG flower 2024-01-15 23:51:50,207 | server.py:165 | evaluate_round 5: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-15 23:51:51,036 | server.py:179 | evaluate_round 5 received 2 results and 0 failures\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-15 23:51:51,036 | server.py:215 | fit_round 6: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42253)\u001b[0m Client 0: evaluation on 675 examples: loss=0.0139, accuracy=0.7896\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42256)\u001b[0m Client 4: evaluation on 675 examples: loss=0.1105, accuracy=0.3837\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42253)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 23:53:13,830 | server.py:229 | fit_round 6 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42253)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.2172, test_accuracy=0.4213\n",
            "INFO flower 2024-01-15 23:53:15,898 | server.py:116 | fit progress: (6, 0.2172349524497986, {'accuracy': 0.42133333333333334, 'precisions': array([       nan,        nan,        nan, 0.78861789, 0.83846154,\n",
            "              nan, 0.15588915, 0.78640777, 0.75423729, 0.74929577]), 'recalls': array([0.        , 0.        , 0.        , 0.32119205, 0.77304965,\n",
            "       0.        , 0.97826087, 0.94186047, 0.32363636, 0.87213115]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 944.4705977880003)\n",
            "DEBUG flower 2024-01-15 23:53:15,899 | server.py:165 | evaluate_round 6: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-15 23:53:16,869 | server.py:179 | evaluate_round 6 received 2 results and 0 failures\n",
            "Configuring round 7\n",
            "DEBUG flower 2024-01-15 23:53:16,870 | server.py:215 | fit_round 7: strategy sampled 5 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42253)\u001b[0m Client 0: evaluation on 675 examples: loss=0.0616, accuracy=0.4815\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42256)\u001b[0m Client 3: evaluation on 675 examples: loss=0.1507, accuracy=0.0400\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42253)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43950)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43949)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42253)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43950)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43949)\u001b[0m Client 2: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-15 23:57:05,106 | server.py:229 | fit_round 7 received 5 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0661, test_accuracy=0.4930\n",
            "INFO flower 2024-01-15 23:57:07,173 | server.py:116 | fit progress: (7, 0.06613967212041219, {'accuracy': 0.493, 'precisions': array([0.71352785, 0.82014388, 0.23930921, 0.95555556, 0.84482759,\n",
            "       0.81818182, 0.36645963, 0.98484848, 0.50707547, 0.67951807]), 'recalls': array([0.79585799, 0.34545455, 0.85588235, 0.14238411, 0.17375887,\n",
            "       0.12980769, 0.21376812, 0.37790698, 0.78181818, 0.92459016]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 1175.7455745899988)\n",
            "DEBUG flower 2024-01-15 23:57:07,174 | server.py:165 | evaluate_round 7: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43949)\u001b[0m E0115 23:57:07.182914706   44014 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42256)\u001b[0m Client 6: evaluation on 675 examples: loss=0.0321, accuracy=0.3156\n",
            "DEBUG flower 2024-01-15 23:57:09,017 | server.py:179 | evaluate_round 7 received 2 results and 0 failures\n",
            "Configuring round 8\n",
            "DEBUG flower 2024-01-15 23:57:09,017 | server.py:215 | fit_round 8: strategy sampled 7 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=43949)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=43949)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=43949)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=43949)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=43949)\u001b[0m Client 7: evaluation on 675 examples: loss=0.0332, accuracy=0.2770\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43949)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45048)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45050)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43949)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43949)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45050)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45048)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45050)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=43949)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-16 00:02:05,845 | server.py:229 | fit_round 8 received 7 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45050)\u001b[0m Client 0: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0460, test_accuracy=0.6383\n",
            "INFO flower 2024-01-16 00:02:07,852 | server.py:116 | fit progress: (8, 0.0460134414434433, {'accuracy': 0.6383333333333333, 'precisions': array([0.7921147 , 0.89552239, 0.51781473, 0.89393939, 0.70967742,\n",
            "       0.97183099, 0.52131148, 0.93286219, 0.43062201, 0.61945032]), 'recalls': array([0.65384615, 0.36363636, 0.64117647, 0.19536424, 0.85815603,\n",
            "       0.33173077, 0.57608696, 0.76744186, 0.98181818, 0.96065574]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 1476.4238455719988)\n",
            "DEBUG flower 2024-01-16 00:02:07,852 | server.py:165 | evaluate_round 8: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45050)\u001b[0m E0116 00:02:07.862062462   45124 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42256)\u001b[0m Client 6: evaluation on 675 examples: loss=0.0241, accuracy=0.4815\n",
            "DEBUG flower 2024-01-16 00:02:09,369 | server.py:179 | evaluate_round 8 received 2 results and 0 failures\n",
            "Configuring round 9\n",
            "DEBUG flower 2024-01-16 00:02:09,370 | server.py:215 | fit_round 9: strategy sampled 7 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=45050)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=45050)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=45050)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=45050)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=45050)\u001b[0m Client 7: evaluation on 675 examples: loss=0.0102, accuracy=0.7170\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45050)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46461)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46463)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45050)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45050)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46461)\u001b[0m Client 0: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46463)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46461)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=45050)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-16 00:07:05,453 | server.py:229 | fit_round 9 received 7 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46461)\u001b[0m Client 2: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0400, test_accuracy=0.6823\n",
            "INFO flower 2024-01-16 00:07:07,388 | server.py:116 | fit progress: (9, 0.03998630162080129, {'accuracy': 0.6823333333333333, 'precisions': array([0.90045249, 0.85333333, 0.54320988, 0.70909091, 0.75366569,\n",
            "       0.9125    , 0.53958944, 0.93687708, 0.59004739, 0.5761079 ]), 'recalls': array([0.5887574 , 0.38787879, 0.64705882, 0.51655629, 0.91134752,\n",
            "       0.35096154, 0.66666667, 0.81976744, 0.90545455, 0.98032787]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 1775.9604378539989)\n",
            "DEBUG flower 2024-01-16 00:07:07,389 | server.py:165 | evaluate_round 9: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-16 00:07:08,202 | server.py:179 | evaluate_round 9 received 2 results and 0 failures\n",
            "Configuring round 10\n",
            "DEBUG flower 2024-01-16 00:07:08,203 | server.py:215 | fit_round 10: strategy sampled 5 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42256)\u001b[0m Client 5: evaluation on 675 examples: loss=0.0147, accuracy=0.6207\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=46461)\u001b[0m Client 1: evaluation on 675 examples: loss=0.0356, accuracy=0.3822\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=46461)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=46461)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=46461)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=46461)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46461)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=47862)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=47863)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=46461)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=47863)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=47862)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-16 00:10:47,282 | server.py:229 | fit_round 10 received 5 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=42256)\u001b[0m Client 2: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0532, test_accuracy=0.6323\n",
            "INFO flower 2024-01-16 00:10:49,240 | server.py:116 | fit progress: (10, 0.05318653500080109, {'accuracy': 0.6323333333333333, 'precisions': array([0.75919732, 0.79646018, 0.38721805, 0.68979592, 0.91791045,\n",
            "              nan, 0.38461538, 0.90415335, 0.77327935, 0.70935961]), 'recalls': array([0.67159763, 0.54545455, 0.60588235, 0.55960265, 0.43617021,\n",
            "       0.        , 0.83333333, 0.82267442, 0.69454545, 0.9442623 ]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 1997.8121299939994)\n",
            "DEBUG flower 2024-01-16 00:10:49,241 | server.py:165 | evaluate_round 10: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=47862)\u001b[0m E0116 00:10:49.249984485   47914 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=42256)\u001b[0m Client 2: evaluation on 675 examples: loss=0.0172, accuracy=0.6000\n",
            "DEBUG flower 2024-01-16 00:10:50,810 | server.py:179 | evaluate_round 10 received 2 results and 0 failures\n",
            "INFO flower 2024-01-16 00:10:50,810 | server.py:144 | FL finished in 1999.3827702589988\n",
            "INFO flower 2024-01-16 00:10:50,811 | app.py:180 | app_fit: losses_distributed [(1, 0.036246921398021555), (2, 0.02023681225600066), (3, 0.05694291432698568), (4, 0.0398564698961046), (5, 0.06221452947016116), (6, 0.1061297568568477), (7, 0.0326766734653049), (8, 0.017137275448551884), (9, 0.025138437747955322), (10, 0.015231847498151992)]\n",
            "INFO flower 2024-01-16 00:10:50,811 | app.py:181 | app_fit: metrics_distributed {}\n",
            "INFO flower 2024-01-16 00:10:50,811 | app.py:182 | app_fit: losses_centralized [(0, 0.07235062257448832), (1, 0.08703887395064036), (2, 0.05711277894179026), (3, 0.08568218199412028), (4, 0.12340867455800375), (5, 0.20262201484044393), (6, 0.2172349524497986), (7, 0.06613967212041219), (8, 0.0460134414434433), (9, 0.03998630162080129), (10, 0.05318653500080109)]\n",
            "INFO flower 2024-01-16 00:10:50,816 | app.py:183 | app_fit: metrics_centralized {'accuracy': [(0, 0.042666666666666665), (1, 0.311), (2, 0.4176666666666667), (3, 0.367), (4, 0.43966666666666665), (5, 0.31266666666666665), (6, 0.42133333333333334), (7, 0.493), (8, 0.6383333333333333), (9, 0.6823333333333333), (10, 0.6323333333333333)], 'precisions': [(0, array([0.1641791 ,        nan,        nan, 0.01666667, 0.05427088,\n",
            "              nan,        nan,        nan,        nan, 0.00132626])), (1, array([       nan,        nan,        nan, 0.18760757, 0.43639291,\n",
            "              nan,        nan,        nan, 0.2260274 , 0.45873016])), (2, array([0.41791045,        nan, 0.21500457, 0.47058824, 0.58525346,\n",
            "              nan, 0.5       , 0.91780822, 0.60091743, 0.44216691])), (3, array([0.41441441,        nan, 0.12903226, 0.96153846, 0.88535032,\n",
            "              nan, 0.16770574, 0.95762712, 0.51822917, 0.65168539])), (4, array([0.72      ,        nan, 0.33333333, 0.6993865 , 0.56646217,\n",
            "              nan, 0.21302251, 0.9858156 , 0.57777778, 0.51652174])), (5, array([0.77118644, 1.        , 0.27758007,        nan, 0.5       ,\n",
            "       0.18117229,        nan, 0.71428571, 0.22564612, 0.68627451])), (6, array([       nan,        nan,        nan, 0.78861789, 0.83846154,\n",
            "              nan, 0.15588915, 0.78640777, 0.75423729, 0.74929577])), (7, array([0.71352785, 0.82014388, 0.23930921, 0.95555556, 0.84482759,\n",
            "       0.81818182, 0.36645963, 0.98484848, 0.50707547, 0.67951807])), (8, array([0.7921147 , 0.89552239, 0.51781473, 0.89393939, 0.70967742,\n",
            "       0.97183099, 0.52131148, 0.93286219, 0.43062201, 0.61945032])), (9, array([0.90045249, 0.85333333, 0.54320988, 0.70909091, 0.75366569,\n",
            "       0.9125    , 0.53958944, 0.93687708, 0.59004739, 0.5761079 ])), (10, array([0.75919732, 0.79646018, 0.38721805, 0.68979592, 0.91791045,\n",
            "              nan, 0.38461538, 0.90415335, 0.77327935, 0.70935961]))], 'recalls': [(0, array([0.03254438, 0.        , 0.        , 0.00331126, 0.40780142,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.00327869])), (1, array([0.        , 0.        , 0.        , 0.36092715, 0.96099291,\n",
            "       0.        , 0.        , 0.        , 0.96      , 0.94754098])), (2, array([0.08284024, 0.        , 0.69117647, 0.55629139, 0.90070922,\n",
            "       0.        , 0.00362319, 0.38953488, 0.47636364, 0.99016393])), (3, array([0.13609467, 0.        , 0.05882353, 0.08278146, 0.4929078 ,\n",
            "       0.        , 0.97463768, 0.32848837, 0.72363636, 0.95081967])), (4, array([0.05325444, 0.        , 0.00294118, 0.37748344, 0.9822695 ,\n",
            "       0.        , 0.96014493, 0.40406977, 0.75636364, 0.97377049])), (5, array([0.26923077, 0.15757576, 0.22941176, 0.        , 0.0035461 ,\n",
            "       0.98076923, 0.        , 0.01453488, 0.82545455, 0.91803279])), (6, array([0.        , 0.        , 0.        , 0.32119205, 0.77304965,\n",
            "       0.        , 0.97826087, 0.94186047, 0.32363636, 0.87213115])), (7, array([0.79585799, 0.34545455, 0.85588235, 0.14238411, 0.17375887,\n",
            "       0.12980769, 0.21376812, 0.37790698, 0.78181818, 0.92459016])), (8, array([0.65384615, 0.36363636, 0.64117647, 0.19536424, 0.85815603,\n",
            "       0.33173077, 0.57608696, 0.76744186, 0.98181818, 0.96065574])), (9, array([0.5887574 , 0.38787879, 0.64705882, 0.51655629, 0.91134752,\n",
            "       0.35096154, 0.66666667, 0.81976744, 0.90545455, 0.98032787])), (10, array([0.67159763, 0.54545455, 0.60588235, 0.55960265, 0.43617021,\n",
            "       0.        , 0.83333333, 0.82267442, 0.69454545, 0.9442623 ]))], 'class proportions': [(0, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (1, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (2, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (3, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (4, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (5, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (6, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (7, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (8, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (9, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (10, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667]))]}\n",
            "History (loss, distributed):\n",
            "\tround 1: 0.036246921398021555\n",
            "\tround 2: 0.02023681225600066\n",
            "\tround 3: 0.05694291432698568\n",
            "\tround 4: 0.0398564698961046\n",
            "\tround 5: 0.06221452947016116\n",
            "\tround 6: 0.1061297568568477\n",
            "\tround 7: 0.0326766734653049\n",
            "\tround 8: 0.017137275448551884\n",
            "\tround 9: 0.025138437747955322\n",
            "\tround 10: 0.015231847498151992\n",
            "History (loss, centralized):\n",
            "\tround 0: 0.07235062257448832\n",
            "\tround 1: 0.08703887395064036\n",
            "\tround 2: 0.05711277894179026\n",
            "\tround 3: 0.08568218199412028\n",
            "\tround 4: 0.12340867455800375\n",
            "\tround 5: 0.20262201484044393\n",
            "\tround 6: 0.2172349524497986\n",
            "\tround 7: 0.06613967212041219\n",
            "\tround 8: 0.0460134414434433\n",
            "\tround 9: 0.03998630162080129\n",
            "\tround 10: 0.05318653500080109\n",
            "History (metrics, centralized):\n",
            "{'accuracy': [(0, 0.042666666666666665), (1, 0.311), (2, 0.4176666666666667), (3, 0.367), (4, 0.43966666666666665), (5, 0.31266666666666665), (6, 0.42133333333333334), (7, 0.493), (8, 0.6383333333333333), (9, 0.6823333333333333), (10, 0.6323333333333333)], 'precisions': [(0, array([0.1641791 ,        nan,        nan, 0.01666667, 0.05427088,\n",
            "              nan,        nan,        nan,        nan, 0.00132626])), (1, array([       nan,        nan,        nan, 0.18760757, 0.43639291,\n",
            "              nan,        nan,        nan, 0.2260274 , 0.45873016])), (2, array([0.41791045,        nan, 0.21500457, 0.47058824, 0.58525346,\n",
            "              nan, 0.5       , 0.91780822, 0.60091743, 0.44216691])), (3, array([0.41441441,        nan, 0.12903226, 0.96153846, 0.88535032,\n",
            "              nan, 0.16770574, 0.95762712, 0.51822917, 0.65168539])), (4, array([0.72      ,        nan, 0.33333333, 0.6993865 , 0.56646217,\n",
            "              nan, 0.21302251, 0.9858156 , 0.57777778, 0.51652174])), (5, array([0.77118644, 1.        , 0.27758007,        nan, 0.5       ,\n",
            "       0.18117229,        nan, 0.71428571, 0.22564612, 0.68627451])), (6, array([       nan,        nan,        nan, 0.78861789, 0.83846154,\n",
            "              nan, 0.15588915, 0.78640777, 0.75423729, 0.74929577])), (7, array([0.71352785, 0.82014388, 0.23930921, 0.95555556, 0.84482759,\n",
            "       0.81818182, 0.36645963, 0.98484848, 0.50707547, 0.67951807])), (8, array([0.7921147 , 0.89552239, 0.51781473, 0.89393939, 0.70967742,\n",
            "       0.97183099, 0.52131148, 0.93286219, 0.43062201, 0.61945032])), (9, array([0.90045249, 0.85333333, 0.54320988, 0.70909091, 0.75366569,\n",
            "       0.9125    , 0.53958944, 0.93687708, 0.59004739, 0.5761079 ])), (10, array([0.75919732, 0.79646018, 0.38721805, 0.68979592, 0.91791045,\n",
            "              nan, 0.38461538, 0.90415335, 0.77327935, 0.70935961]))], 'recalls': [(0, array([0.03254438, 0.        , 0.        , 0.00331126, 0.40780142,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.00327869])), (1, array([0.        , 0.        , 0.        , 0.36092715, 0.96099291,\n",
            "       0.        , 0.        , 0.        , 0.96      , 0.94754098])), (2, array([0.08284024, 0.        , 0.69117647, 0.55629139, 0.90070922,\n",
            "       0.        , 0.00362319, 0.38953488, 0.47636364, 0.99016393])), (3, array([0.13609467, 0.        , 0.05882353, 0.08278146, 0.4929078 ,\n",
            "       0.        , 0.97463768, 0.32848837, 0.72363636, 0.95081967])), (4, array([0.05325444, 0.        , 0.00294118, 0.37748344, 0.9822695 ,\n",
            "       0.        , 0.96014493, 0.40406977, 0.75636364, 0.97377049])), (5, array([0.26923077, 0.15757576, 0.22941176, 0.        , 0.0035461 ,\n",
            "       0.98076923, 0.        , 0.01453488, 0.82545455, 0.91803279])), (6, array([0.        , 0.        , 0.        , 0.32119205, 0.77304965,\n",
            "       0.        , 0.97826087, 0.94186047, 0.32363636, 0.87213115])), (7, array([0.79585799, 0.34545455, 0.85588235, 0.14238411, 0.17375887,\n",
            "       0.12980769, 0.21376812, 0.37790698, 0.78181818, 0.92459016])), (8, array([0.65384615, 0.36363636, 0.64117647, 0.19536424, 0.85815603,\n",
            "       0.33173077, 0.57608696, 0.76744186, 0.98181818, 0.96065574])), (9, array([0.5887574 , 0.38787879, 0.64705882, 0.51655629, 0.91134752,\n",
            "       0.35096154, 0.66666667, 0.81976744, 0.90545455, 0.98032787])), (10, array([0.67159763, 0.54545455, 0.60588235, 0.55960265, 0.43617021,\n",
            "       0.        , 0.83333333, 0.82267442, 0.69454545, 0.9442623 ]))], 'class proportions': [(0, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (1, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (2, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (3, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (4, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (5, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (6, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (7, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (8, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (9, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])), (10, array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667]))]}\n",
            "\u001b[0m\u001b[2m\u001b[36m(launch_and_evaluate pid=47862)\u001b[0m Client 7: evaluation on 675 examples: loss=0.0132, accuracy=0.6963\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=47862)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=47862)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=47862)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=47862)\u001b[0m   recalls = total_tp / total_true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --iid-alpha 0.5 --fraction-fit 0.3 --client-pool-size 8 --num-iterations 1000 --num-rounds 10 --val-ratio 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls7rWcsie2xX",
        "outputId": "bcfe4a11-8636-4aec-ad9d-a2b618623cf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class histogram for 0-th partition (alpha=0.5, 10 classes): [215 414 910  37  22 270   4 364 710 429]\n",
            "Data partitioned across 8 clients, with IID alpha = 0.5 and 0.2 of local dataset reserved for validation.\n",
            "FL experiment configured for 10 rounds with 8 client in the pool.\n",
            "FL round will proceed with 30.0% of clients sampled, at least 2.\n",
            "INFO flower 2024-01-16 00:11:23,149 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO flower 2024-01-16 00:11:26,762 | app.py:176 | Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'object_store_memory': 3627212390.0, 'node:172.28.0.12': 1.0, 'accelerator_type:V100': 1.0, 'GPU': 1.0, 'memory': 7254424782.0}\n",
            "INFO flower 2024-01-16 00:11:26,763 | server.py:86 | Initializing global parameters\n",
            "INFO flower 2024-01-16 00:11:26,763 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO flower 2024-01-16 00:11:29,626 | server.py:274 | Received initial parameters from one random client\n",
            "INFO flower 2024-01-16 00:11:29,626 | server.py:88 | Evaluating initial parameters\n",
            "/content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "  precisions = total_tp / total_pred\n",
            "Evaluation on the server: test_loss=0.0724, test_accuracy=0.0347\n",
            "INFO flower 2024-01-16 00:11:31,981 | server.py:91 | initial parameters (loss, other metrics): 0.07237443486849467, {'accuracy': 0.034666666666666665, 'precisions': array([0.        ,        nan, 0.        ,        nan, 0.01761879,\n",
            "       0.        , 0.        ,        nan, 0.06543779,        nan]), 'recalls': array([0.        , 0.        , 0.        , 0.        , 0.11702128,\n",
            "       0.        , 0.        , 0.        , 0.25818182, 0.        ]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}\n",
            "INFO flower 2024-01-16 00:11:31,982 | server.py:101 | FL starting\n",
            "Configuring round 1\n",
            "DEBUG flower 2024-01-16 00:11:31,982 | server.py:215 | fit_round 1: strategy sampled 4 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49161)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49160)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49292)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49291)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49161)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49160)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49291)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-16 00:14:25,360 | server.py:229 | fit_round 1 received 4 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49292)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "WARNING flower 2024-01-16 00:14:25,384 | fedavg.py:234 | No fit_metrics_aggregation_fn provided\n",
            "Evaluation on the server: test_loss=0.0828, test_accuracy=0.2427\n",
            "INFO flower 2024-01-16 00:14:27,597 | server.py:116 | fit progress: (1, 0.08278789993127188, {'accuracy': 0.24266666666666667, 'precisions': array([       nan,        nan, 0.        ,        nan, 0.63987138,\n",
            "              nan, 0.12094118,        nan,        nan, 0.595186  ]), 'recalls': array([0.        , 0.        , 0.        , 0.        , 0.70567376,\n",
            "       0.        , 0.93115942, 0.        , 0.        , 0.89180328]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 175.61452909000036)\n",
            "DEBUG flower 2024-01-16 00:14:27,598 | server.py:165 | evaluate_round 1: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-16 00:14:28,485 | server.py:179 | evaluate_round 1 received 2 results and 0 failures\n",
            "WARNING flower 2024-01-16 00:14:28,485 | fedavg.py:265 | No evaluate_metrics_aggregation_fn provided\n",
            "Configuring round 2\n",
            "DEBUG flower 2024-01-16 00:14:28,485 | server.py:215 | fit_round 2: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=49291)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=49291)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=49291)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=49291)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=49291)\u001b[0m Client 4: evaluation on 675 examples: loss=0.0368, accuracy=0.1541\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=49292)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=49292)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=49292)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=49292)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=49292)\u001b[0m Client 6: evaluation on 675 examples: loss=0.0258, accuracy=0.1126\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49291)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49292)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49291)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-16 00:15:44,737 | server.py:229 | fit_round 2 received 2 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49292)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0740, test_accuracy=0.3970\n",
            "INFO flower 2024-01-16 00:15:46,716 | server.py:116 | fit progress: (2, 0.0740268625418345, {'accuracy': 0.397, 'precisions': array([0.54054054,        nan, 0.6       , 0.33510638, 0.6840796 ,\n",
            "              nan, 0.21819646, 0.87795276, 1.        , 0.36721728]), 'recalls': array([0.17751479, 0.        , 0.02647059, 0.20860927, 0.9751773 ,\n",
            "       0.        , 0.98188406, 0.64825581, 0.00363636, 0.94754098]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 254.73379982699953)\n",
            "DEBUG flower 2024-01-16 00:15:46,717 | server.py:165 | evaluate_round 2: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-16 00:15:47,531 | server.py:179 | evaluate_round 2 received 2 results and 0 failures\n",
            "Configuring round 3\n",
            "DEBUG flower 2024-01-16 00:15:47,532 | server.py:215 | fit_round 3: strategy sampled 3 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=49291)\u001b[0m Client 3: evaluation on 675 examples: loss=0.0110, accuracy=0.7452\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=49292)\u001b[0m Client 7: evaluation on 675 examples: loss=0.0220, accuracy=0.4578\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49291)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49292)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50504)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49291)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49292)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-16 00:17:51,850 | server.py:229 | fit_round 3 received 3 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50504)\u001b[0m Client 7: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.1198, test_accuracy=0.4767\n",
            "INFO flower 2024-01-16 00:17:53,715 | server.py:116 | fit progress: (3, 0.11980028617382049, {'accuracy': 0.4766666666666667, 'precisions': array([0.49525617,        nan, 0.43981481, 1.        , 0.71801567,\n",
            "              nan, 0.28335171, 0.96721311,        nan, 0.41922006]), 'recalls': array([0.77218935, 0.        , 0.27941176, 0.01655629, 0.9751773 ,\n",
            "       0.        , 0.93115942, 0.68604651, 0.        , 0.98688525]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 381.7331335529998)\n",
            "DEBUG flower 2024-01-16 00:17:53,716 | server.py:165 | evaluate_round 3: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-16 00:17:54,537 | server.py:179 | evaluate_round 3 received 2 results and 0 failures\n",
            "Configuring round 4\n",
            "DEBUG flower 2024-01-16 00:17:54,538 | server.py:215 | fit_round 4: strategy sampled 4 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=49292)\u001b[0m Client 7: evaluation on 675 examples: loss=0.0093, accuracy=0.7674\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50504)\u001b[0m Client 3: evaluation on 675 examples: loss=0.0188, accuracy=0.7748\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50504)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50504)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50504)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50504)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49292)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50504)\u001b[0m Client 5: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51135)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51186)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=49292)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50504)\u001b[0m Client 5: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51186)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51135)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-16 00:20:43,558 | server.py:229 | fit_round 4 received 4 results and 0 failures\n",
            "Evaluation on the server: test_loss=0.0633, test_accuracy=0.6490\n",
            "INFO flower 2024-01-16 00:20:46,117 | server.py:116 | fit progress: (4, 0.06328368121385575, {'accuracy': 0.649, 'precisions': array([0.81972789, 0.79272727, 0.76027397, 0.38034865, 0.83900929,\n",
            "              nan, 0.43315508, 0.96308725, 0.75      , 0.70673077]), 'recalls': array([0.71301775, 0.66060606, 0.32647059, 0.79470199, 0.96099291,\n",
            "       0.        , 0.88043478, 0.83430233, 0.15272727, 0.96393443]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 554.1346710389989)\n",
            "DEBUG flower 2024-01-16 00:20:46,118 | server.py:165 | evaluate_round 4: strategy sampled 2 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=51186)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=51186)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=51186)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=51186)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=51186)\u001b[0m Client 7: evaluation on 675 examples: loss=0.0116, accuracy=0.7185\n",
            "DEBUG flower 2024-01-16 00:20:47,224 | server.py:179 | evaluate_round 4 received 2 results and 0 failures\n",
            "Configuring round 5\n",
            "DEBUG flower 2024-01-16 00:20:47,224 | server.py:215 | fit_round 5: strategy sampled 6 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=51135)\u001b[0m /content/simple_cnn.py:142: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=51135)\u001b[0m   precisions = total_tp / total_pred\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=51135)\u001b[0m /content/simple_cnn.py:143: RuntimeWarning: invalid value encountered in divide\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=51135)\u001b[0m   recalls = total_tp / total_true\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=51135)\u001b[0m Client 0: evaluation on 675 examples: loss=0.0313, accuracy=0.4667\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51186)\u001b[0m Client 0: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51135)\u001b[0m Client 2: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=52003)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=52049)\u001b[0m Client 6: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51186)\u001b[0m Client 0: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51186)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51135)\u001b[0m Client 2: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51135)\u001b[0m Client 3: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=52003)\u001b[0m Client 1: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=52049)\u001b[0m Client 6: training round complete, 31780 examples processed\n",
            "DEBUG flower 2024-01-16 00:24:53,293 | server.py:229 | fit_round 5 received 6 results and 0 failures\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51135)\u001b[0m Client 3: training round complete, 31780 examples processed\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51186)\u001b[0m Client 4: training round complete, 31780 examples processed\n",
            "Evaluation on the server: test_loss=0.0385, test_accuracy=0.7270\n",
            "INFO flower 2024-01-16 00:24:55,239 | server.py:116 | fit progress: (5, 0.038517940272887546, {'accuracy': 0.727, 'precisions': array([0.74418605, 0.78470255, 0.73931624, 0.5738255 , 0.70558376,\n",
            "              nan, 0.56545961, 0.90985915, 0.71428571, 0.7826087 ]), 'recalls': array([0.85207101, 0.83939394, 0.50882353, 0.56622517, 0.9858156 ,\n",
            "       0.        , 0.73550725, 0.93895349, 0.65454545, 0.9442623 ]), 'class proportions': array([0.11266667, 0.11      , 0.11333333, 0.10066667, 0.094     ,\n",
            "       0.06933333, 0.092     , 0.11466667, 0.09166667, 0.10166667])}, 803.2565151899998)\n",
            "DEBUG flower 2024-01-16 00:24:55,240 | server.py:165 | evaluate_round 5: strategy sampled 2 clients (out of 8)\n",
            "DEBUG flower 2024-01-16 00:24:56,057 | server.py:179 | evaluate_round 5 received 2 results and 0 failures\n",
            "Configuring round 6\n",
            "DEBUG flower 2024-01-16 00:24:56,057 | server.py:215 | fit_round 6: strategy sampled 4 clients (out of 8)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=51135)\u001b[0m Client 7: evaluation on 675 examples: loss=0.0081, accuracy=0.7837\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=51186)\u001b[0m Client 1: evaluation on 675 examples: loss=0.0444, accuracy=0.4622\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51135)\u001b[0m Client 7: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=51186)\u001b[0m Client 1: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53207)\u001b[0m Client 4: training for 1000 iterations/updates\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=53206)\u001b[0m Client 3: training for 1000 iterations/updates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --iid-alpha 2 --fraction-fit 0.3 --client-pool-size 8 --num-iterations 1000 --num-rounds 10 --val-ratio 0.2"
      ],
      "metadata": {
        "id": "hJCgpt_fe23R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --iid-alpha 5 --fraction-fit 0.3 --client-pool-size 8 --num-iterations 1000 --num-rounds 10 --val-ratio 0.2"
      ],
      "metadata": {
        "id": "KlEYAGOue26J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --iid-alpha 10 --fraction-fit 0.3 --client-pool-size 8 --num-iterations 1000 --num-rounds 10 --val-ratio 0.2"
      ],
      "metadata": {
        "id": "ixaqQ7KLe--N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --iid-alpha 100 --fraction-fit 0.3 --client-pool-size 8 --num-iterations 1000 --num-rounds 10 --val-ratio 0.2"
      ],
      "metadata": {
        "id": "FY_xZW6HfCBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --iid-alpha 10 --fraction-fit 0.3 --client-pool-size 8 --num-iterations 1000 --num-rounds 10 --val-ratio 0.2"
      ],
      "metadata": {
        "id": "gm9wHuzRfCf9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}